[
    {
        "author": "shitfuck27",
        "category": "Testing",
        "parent": "",
        "content": "what kind of behavior can one expect during non-finality? Neither besu or geth seem to be doing anything, and Lighthouse seems to be acknowledging that there's a moving head but can't sync further than slot 179702\n\n  `Jan 10 17:39:54.000 INFO Syncing                                 est_time: --, distance: 1072 slots (3 hrs 34 mins), peers: 60, service: slot_notifier`\n  `Jan 10 17:39:54.000 WARN Syncing eth1 block cache                est_blocks_remaining: 3816, service: slot_notifier`",
        "created_at": "2022-01-10T15:47:50.874000+00:00",
        "attachments": null
    },
    {
        "author": "ohraemez",
        "category": "Testing",
        "parent": "",
        "content": "you still should be able to sync up to head. the problem is that during non-finality there are a lot forks which the node needs to process. therefore high cpu load and high ram consumption is expected.\nsomething similar happened to me earlier, teku was not able to sync and was falling behind. all 8 cpu threads were maxed.",
        "created_at": "2022-01-10T16:25:55.435000+00:00",
        "attachments": null
    },
    {
        "author": "gaming_in_rust",
        "category": "Testing",
        "parent": "",
        "content": "Is it expected that the chain starts finalizing again by itself?",
        "created_at": "2022-01-10T17:02:42.410000+00:00",
        "attachments": null
    },
    {
        "author": "parithosh",
        "category": "Testing",
        "parent": "",
        "content": "Nope, we're leaving it in its current state until some bugs are figured out. The chain will finalize again after we bring the validators back to the same fork, with some updates and resyncing.",
        "created_at": "2022-01-10T17:06:51.102000+00:00",
        "attachments": null
    },
    {
        "author": "eysteinh_nbx_anp",
        "category": "Testing",
        "parent": "",
        "content": "Appriciate both of you guys sharing knowledge ðŸ™‚",
        "created_at": "2022-01-10T18:03:46.270000+00:00",
        "attachments": null
    },
    {
        "author": "ajsutton",
        "category": "Testing",
        "parent": "",
        "content": "I was able to sync kintsugi from scratch yesterday and didn't see massive CPU usage.  The biggest delays were when sync had to search for a common ancestor with a chain - it often wasn't able to find anything close so had to request and download a lot of blocks it wound up already having so didn't make any visible progress for quite a while (plus a lot of peers were failing to return blocks within the 5 second timeout which made it even slower).",
        "created_at": "2022-01-10T20:52:16.396000+00:00",
        "attachments": null
    },
    {
        "author": "ajsutton",
        "category": "Testing",
        "parent": "",
        "content": "Once you're in sync CPU usage can wind up being higher because the gossip is all over the place but sync shouldn't be too bad.",
        "created_at": "2022-01-10T20:52:47.024000+00:00",
        "attachments": null
    },
    {
        "author": "ohraemez",
        "category": "Testing",
        "parent": "",
        "content": "thank you for explaining what is going on internally. that was basically what i was seeing. teku synced within about 100 slots of chain tip, 8 threads were maxed and teku seemed to fall further and further behind.\ni tried syncing on my desktop machine which has a 16 thread and it had no problems syncing. but all 16 threads were maxed while nearing the chain tip. and like you said as soon as teku was synced cpu load relatively low on teku.",
        "created_at": "2022-01-10T21:14:47.250000+00:00",
        "attachments": null
    },
    {
        "author": "ohraemez",
        "category": "Testing",
        "parent": "",
        "content": "lighthouse is the other way around seems to sync quicker but then has stretches where it maxes the cpu out",
        "created_at": "2022-01-10T21:16:35.990000+00:00",
        "attachments": null
    }
]