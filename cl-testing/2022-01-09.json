[
    {
        "author": "ohraemez",
        "category": "Testing",
        "parent": "",
        "content": "which EL client are you using (e.g. geth, nethermind)?",
        "created_at": "2022-01-09T08:53:07.081000+00:00",
        "attachments": []
    },
    {
        "author": "ohraemez",
        "category": "Testing",
        "parent": "",
        "content": "i made a backup of the datadir before doing a fresh sync yesterday. tried again today with this datadir on the wrong fork and lighthouse actually reorged itself to the correct fork. so the non-hacky way also works ðŸ˜†",
        "created_at": "2022-01-09T10:15:01.900000+00:00",
        "attachments": []
    },
    {
        "author": "eysteinh_nbx_anp",
        "category": "Testing",
        "parent": "",
        "content": "geth",
        "created_at": "2022-01-09T12:56:29.983000+00:00",
        "attachments": []
    },
    {
        "author": "eysteinh_nbx_anp",
        "category": "Testing",
        "parent": "",
        "content": "geth client looks fine",
        "created_at": "2022-01-09T12:56:37.381000+00:00",
        "attachments": []
    },
    {
        "author": "eysteinh_nbx_anp",
        "category": "Testing",
        "parent": "",
        "content": "And thanks for responding ðŸ™‚",
        "created_at": "2022-01-09T12:56:43.999000+00:00",
        "attachments": []
    },
    {
        "author": "eysteinh_nbx_anp",
        "category": "Testing",
        "parent": "",
        "content": "deleted db of geth and restarted it just in case.",
        "created_at": "2022-01-09T13:13:20.150000+00:00",
        "attachments": []
    },
    {
        "author": "eysteinh_nbx_anp",
        "category": "Testing",
        "parent": "",
        "content": "hmm head of geth is 145819 while on transcaction explorer it is 145771",
        "created_at": "2022-01-09T13:21:20.208000+00:00",
        "attachments": []
    },
    {
        "author": "ohraemez",
        "category": "Testing",
        "parent": "",
        "content": "if you were using geth you should be good. the problem is that the network split and there are to many empty slots at the moment. after a certain number of sequential empty slots lighthouse seems to trigger the `EndpointError(FarBehind)` error that you are seeing.",
        "created_at": "2022-01-09T13:23:51.950000+00:00",
        "attachments": []
    },
    {
        "author": "ohraemez",
        "category": "Testing",
        "parent": "",
        "content": "as long as you are seeing ` exec_hash: xxxxâ€¦xxxx (verified)` in lighthouse everything works correctly.",
        "created_at": "2022-01-09T13:24:59.342000+00:00",
        "attachments": []
    },
    {
        "author": "eysteinh_nbx_anp",
        "category": "Testing",
        "parent": "",
        "content": "Thanks. I am recieving like for example this in lighthouse \"ed_epoch: 4828, finalized_root: 0x635dâ€¦27a3, exec_hash: 0x3b20â€¦14c4 (verified), peers: 27, service: slot_notifier\"",
        "created_at": "2022-01-09T13:58:27.113000+00:00",
        "attachments": []
    },
    {
        "author": "eysteinh_nbx_anp",
        "category": "Testing",
        "parent": "",
        "content": "but also these: \"WARN Previous epoch attestation(s) failed to match head, validators: [\"72457\"], epoch: 5405, service: val_mon\"",
        "created_at": "2022-01-09T13:58:41.875000+00:00",
        "attachments": []
    },
    {
        "author": "eysteinh_nbx_anp",
        "category": "Testing",
        "parent": "",
        "content": "my balance is slowly draining from 32.17 to 32.07 today",
        "created_at": "2022-01-09T13:59:28.425000+00:00",
        "attachments": []
    },
    {
        "author": "eysteinh_nbx_anp",
        "category": "Testing",
        "parent": "",
        "content": "\"slashed\": false still so wierd.",
        "created_at": "2022-01-09T13:59:57.422000+00:00",
        "attachments": []
    },
    {
        "author": "eysteinh_nbx_anp",
        "category": "Testing",
        "parent": "",
        "content": "also \" WARN Invalid parent chain                    last_peer: 16Uiu2HAmTExquFQuCTKNANAbZAoD3rCCxQNYDbgSFRoJbEySdbFS, outcome: ExecutionPayloadError(RejectedByExecutionEngine), score_adjustment: Mid Tolerance Error, service: sync\"",
        "created_at": "2022-01-09T14:26:54.977000+00:00",
        "attachments": []
    },
    {
        "author": "ohraemez",
        "category": "Testing",
        "parent": "",
        "content": "it is normal that the balance is going down during non-finality. \ni have not seen your warnings on my system. maybe try asking in the lighthouse discord?",
        "created_at": "2022-01-09T15:09:42.391000+00:00",
        "attachments": []
    },
    {
        "author": "eysteinh_nbx_anp",
        "category": "Testing",
        "parent": "",
        "content": "thats a good idea",
        "created_at": "2022-01-09T15:15:59.463000+00:00",
        "attachments": []
    },
    {
        "author": "eysteinh_nbx_anp",
        "category": "Testing",
        "parent": "",
        "content": "Thanks",
        "created_at": "2022-01-09T15:16:03.870000+00:00",
        "attachments": []
    },
    {
        "author": "parithosh",
        "category": "Testing",
        "parent": "",
        "content": "During non-finality, if we have a fork, you're technically \"missing\" on the other fork. So you'd be inactivity leaking there on atleast 1 of the forks. It depends if you're loosing funds or not depending on what the resulting \"correct\" fork everyone joins back. The loss should be minimal, the fork started ~2 days ago, so your loss would be the same as if you turned off your machine for two days (not that much eth).",
        "created_at": "2022-01-09T15:22:02.101000+00:00",
        "attachments": []
    },
    {
        "author": "ohraemez",
        "category": "Testing",
        "parent": "",
        "content": "btw according to the exec hash it looks like you are on the same fork as the block explorer and all my clients https://beaconchain.kintsugi.themerge.dev/block/173061 ðŸ˜ƒ",
        "created_at": "2022-01-09T15:25:56.688000+00:00",
        "attachments": []
    },
    {
        "author": "eysteinh_nbx_anp",
        "category": "Testing",
        "parent": "",
        "content": "Thanks for the feedback OhraeMez!",
        "created_at": "2022-01-09T16:19:22.258000+00:00",
        "attachments": []
    },
    {
        "author": "eysteinh_nbx_anp",
        "category": "Testing",
        "parent": "",
        "content": "So I guess I am atleast in the right fork ðŸ™‚",
        "created_at": "2022-01-09T16:19:29.617000+00:00",
        "attachments": []
    },
    {
        "author": "eysteinh_nbx_anp",
        "category": "Testing",
        "parent": "",
        "content": "Resynching now and chain head is 145448 while explorer (https://explorer.kintsugi.themerge.dev/) shows 146034",
        "created_at": "2022-01-09T16:21:45.176000+00:00",
        "attachments": []
    },
    {
        "author": "eysteinh_nbx_anp",
        "category": "Testing",
        "parent": "",
        "content": "(the geth 1.0 network)",
        "created_at": "2022-01-09T16:22:23.462000+00:00",
        "attachments": []
    },
    {
        "author": "eysteinh_nbx_anp",
        "category": "Testing",
        "parent": "",
        "content": "Interesting now I restarted geth again with genesis from testnet it seems to synch up correctly to 146... and ligthouse now is not complaining errors either",
        "created_at": "2022-01-09T16:27:36.123000+00:00",
        "attachments": []
    },
    {
        "author": "seamonkey82",
        "category": "Testing",
        "parent": "",
        "content": "kintsugi-nimbus-geth\ngeth told me to file an issue, so I did.\nhttps://github.com/ethereum/go-ethereum/issues/24217",
        "created_at": "2022-01-09T18:32:28.016000+00:00",
        "attachments": []
    },
    {
        "author": "seamonkey82",
        "category": "Testing",
        "parent": "",
        "content": "Some guidance on what to look for in each client to verify we are on the correct fork, and how to proceed if we are not, would be appreciated. ðŸ™‚",
        "created_at": "2022-01-09T18:42:23.562000+00:00",
        "attachments": []
    },
    {
        "author": "eysteinh_nbx_anp",
        "category": "Testing",
        "parent": "",
        "content": "hmm yeah https://beaconchain.kintsugi.themerge.dev/ shows epoch 5455 but my lighthouse shows 5458",
        "created_at": "2022-01-09T19:18:59.465000+00:00",
        "attachments": []
    },
    {
        "author": "eysteinh_nbx_anp",
        "category": "Testing",
        "parent": "",
        "content": "I guess the 3 forks are the cause and not much I can do? I wish I knew how to connect to a snapshot of a peer with correct epoch",
        "created_at": "2022-01-09T20:17:34.973000+00:00",
        "attachments": []
    },
    {
        "author": "ohraemez",
        "category": "Testing",
        "parent": "",
        "content": "the problem is that the beacon explorer shows data which is 20 mins too old. that is why you are seeing a smaller epoch number on the block explorer. you can make sure that you are on the same fork by opening a proposed block e.g https://beaconchain.kintsugi.themerge.dev/block/175227\nand then calling the following command:\n`curl http://localhost:5052/eth/v1/beacon/headers?slot=175227 | jq`\nand you should see the same block root hash as on the explorer.",
        "created_at": "2022-01-09T21:33:41.656000+00:00",
        "attachments": []
    },
    {
        "author": "parithosh",
        "category": "Testing",
        "parent": "",
        "content": "Beacon explorer is on the right fork last i checked, its just lagging a bit since its on the same machine as the beacon node. Beacon node is using a lot of ram/cpu due to non-finality and causing the delay. Besides that, \u003c@!612776905380200459\u003e's comment is spot on ðŸ™‚",
        "created_at": "2022-01-09T21:36:44.718000+00:00",
        "attachments": []
    }
]