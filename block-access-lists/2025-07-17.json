[
    {
        "author": "nero_eth",
        "category": "Execution Layer",
        "parent": "",
        "content": "An idea that came up in discussions with \u003c@415548822983278593\u003e: how much could parallelization benefit if builders attached a gas_used value to each transaction?\n\nThe naive way to distribute transactions across cores is to use a greedy algorithm based on each transaction's **gas limit**.\nA better approach is to use the **BAL size**, since it tends to correlate more closely with the actual computational work of a transaction.\nThe best case would be if builders could directly attach the gas_used value for each transaction.\n\nInterestingly, clients might be able to **infer gas_used from the balance diffs of accounts**. This isnâ€™t always accurate, for example, an account might spend 0.001 eth and get back 0.0005 ETH in the same transaction, which could make it appear that only 0.0005 gas was used instead of 0.001 but such cases should be relatively rare.",
        "created_at": "2025-07-17T13:30:56.507000+00:00",
        "attachments": null
    },
    {
        "author": "_shemnon",
        "category": "Execution Layer",
        "parent": "",
        "content": "How much real value would it provide?\n(a) other TXes don't need to know the gas consumed before they executed, they only see the block max and their current remaining.\n(b) gas burnt is an imperfect signal for effort. For example: deploying a contract has a code deposit cost that is mostly indended to pay for long-term code storage (it's not enough). So it can be hit and miss for work distribution",
        "created_at": "2025-07-17T20:52:32.311000+00:00",
        "attachments": null
    }
]