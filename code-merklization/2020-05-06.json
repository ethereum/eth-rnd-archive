[
    {
        "author": "_drinkcoffee",
        "category": "Channel Graveyard",
        "parent": "",
        "content": "An area for investigation (\u003c@!461762841641484302\u003e ) is to determine whether whole data contracts are read in with the extcodecopy, or just parts of the contract. If the whole contract is read in, then I don't think it would make sense to split it up.",
        "created_at": "2020-05-06T02:39:00.083000+00:00",
        "attachments": null
    },
    {
        "author": "_drinkcoffee",
        "category": "Channel Graveyard",
        "parent": "",
        "content": "\u003e new IR generator \n\u003c@!425279588009246720\u003e   is there a link to information about the new IR generator?",
        "created_at": "2020-05-06T02:39:54.189000+00:00",
        "attachments": null
    },
    {
        "author": "axic3354",
        "category": "Channel Graveyard",
        "parent": "",
        "content": "Not really, but can use `solc --ir \u003cfile\u003e` and `solc --ir-optimized \u003cfile\u003e` to get the yul output. That then needs to be manually assembled via `solc --strict-assembly \u003cfile\u003e`. This is intentionally cumbersome so users wont use this experimental feature in production :)",
        "created_at": "2020-05-06T07:11:53.284000+00:00",
        "attachments": null
    },
    {
        "author": "gm1251",
        "category": "Channel Graveyard",
        "parent": "",
        "content": "Hi everybody, I'm a graduate student interested in researching code merklization. I have read this medium post https://medium.com/ewasm/evm-bytecode-merklization-2a8366ab0c90 and am somewhat familiar with the EVM. I am particularly interested in researching program/bytecode analysis techniques to guide merklization towards optimal encodings. I would love to talk to/meet with people to understand the current state of this research and figure out how to make a useful contribution. Thanks in advance!",
        "created_at": "2020-05-06T17:58:49.636000+00:00",
        "attachments": null
    },
    {
        "author": "pipermerriam",
        "category": "Channel Graveyard",
        "parent": "",
        "content": "\u003c@!707221546330095667\u003e connect with \u003c@!187490121698770945\u003e to ensure you get an invite to the next call where we'll discuss this among other topics.",
        "created_at": "2020-05-06T18:00:02.296000+00:00",
        "attachments": null
    },
    {
        "author": "pipermerriam",
        "category": "Channel Graveyard",
        "parent": "",
        "content": "The primary experiment in this area that I know of is the one that Sina did in that blog post.  If you're feeling ambitious, then replicating Sina's experimeent on a larger data set and using a mercklization scheme with a fixed chunk size would be very useful data.",
        "created_at": "2020-05-06T18:01:45.155000+00:00",
        "attachments": null
    },
    {
        "author": "pipermerriam",
        "category": "Channel Graveyard",
        "parent": "",
        "content": "Also, welcome!",
        "created_at": "2020-05-06T18:02:31.522000+00:00",
        "attachments": null
    },
    {
        "author": "s1na",
        "category": "Channel Graveyard",
        "parent": "",
        "content": "Hey \u003c@!227960531053576202\u003e , I also had a \"where to go from here\" section where I highlighted some further experiments (which I haven't gotten to yet). If by optimal encoding you're referring to the proof format, you should also check out https://github.com/ethereum/stateless-ethereum-specs/blob/master/witness.md",
        "created_at": "2020-05-06T18:05:09.510000+00:00",
        "attachments": null
    },
    {
        "author": "s1na",
        "category": "Channel Graveyard",
        "parent": "",
        "content": "Brian collected some data too: https://ethresear.ch/t/some-quick-numbers-on-code-merkelization/7260/3",
        "created_at": "2020-05-06T18:07:44.942000+00:00",
        "attachments": null
    },
    {
        "author": "pipermerriam",
        "category": "Channel Graveyard",
        "parent": "",
        "content": "Ah yes, I forgot about brian's data, thnx sina",
        "created_at": "2020-05-06T18:08:54.232000+00:00",
        "attachments": null
    },
    {
        "author": "gm1251",
        "category": "Channel Graveyard",
        "parent": "",
        "content": "Thanks for these links, I will look into them! Based on the \"where to go\" section from your post \u003c@!259648573401071617\u003e, I guess my interests lie in leveraging bytecode/ast analysis for better chunking strategies. You mentioned a few people had ideas along those lines. I wonder if it's possible to do better than a simple fixed chunking strategy",
        "created_at": "2020-05-06T18:18:02.243000+00:00",
        "attachments": null
    },
    {
        "author": "axic3354",
        "category": "Channel Graveyard",
        "parent": "",
        "content": "There is also an upcoming feature of EVM (subroutines) to which this post proposes merklization-aiding changes: https://ethereum-magicians.org/t/eip-2315-simple-subroutines-for-the-evm-analysis/4229/26",
        "created_at": "2020-05-06T18:19:31.056000+00:00",
        "attachments": null
    },
    {
        "author": "s1na",
        "category": "Channel Graveyard",
        "parent": "",
        "content": "For AST analysis you can talk to \u003c@!273818081439121408\u003e and \u003c@!425279588009246720\u003e",
        "created_at": "2020-05-06T18:24:33.170000+00:00",
        "attachments": null
    },
    {
        "author": "madeof_tin7509",
        "category": "Channel Graveyard",
        "parent": "",
        "content": "\u003c@364458974906548225\u003e \u003c@227960531053576202\u003e DM‚Äôed about adding to the call list üëç",
        "created_at": "2020-05-06T23:15:01.169000+00:00",
        "attachments": null
    },
    {
        "author": "_drinkcoffee",
        "category": "Channel Graveyard",
        "parent": "",
        "content": "\u003c@!227960531053576202\u003e , I am experimenting with another code merklization technique. I will have a write-up in a few days - probably next week. My thought is that perhaps there could be space savings if a happy path for a function call could map to one digest. It would mean overlap of the digest, and extra pieces of code would need to be delivered for negative cases.    If this doesn't make sense, please just wait for the write up next week.",
        "created_at": "2020-05-06T23:33:05.352000+00:00",
        "attachments": null
    },
    {
        "author": "madeof_tin7509",
        "category": "Channel Graveyard",
        "parent": "",
        "content": "If it feels like the group is ready for a code-merklization call for this working group. Not saying it is, just reminding of the possibility.",
        "created_at": "2020-05-06T23:56:32.244000+00:00",
        "attachments": null
    },
    {
        "author": "madeof_tin7509",
        "category": "Channel Graveyard",
        "parent": "",
        "content": "Once a group gets enough traction at some point adding a call may help.",
        "created_at": "2020-05-06T23:57:17.662000+00:00",
        "attachments": null
    }
]