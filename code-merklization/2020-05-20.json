[
    {
        "author": "s1na",
        "category": "Channel Graveyard",
        "parent": "",
        "content": "\u003e For the \"split by jumpdest approach\", or the \"split code into fixed size chunks approach\", am I correct in saying that the EVM will need to keep a track of what code is used?\n\u003c@!636680106630316033\u003e Yeah the miner has to track which chunks are touched during the tx execution and generate a proof at the end. Is it any different in your approach?",
        "created_at": "2020-05-20T11:41:51.701000+00:00",
        "attachments": null
    },
    {
        "author": "_drinkcoffee",
        "category": "Channel Graveyard",
        "parent": "",
        "content": "\u003e \u003c@!636680106630316033\u003e Yeah the miner has to track which chunks are touched during the tx execution and generate a proof at the end. Is it any different in your approach?\n\u003c@!259648573401071617\u003e yes. With my approach, the miner will look at the transaction payload, and extract the 32 bit function id. For each function in the contract, there will be a leaf which will contain the information needed for the function: the start offset program counter and length of each code chunk that the transaction will be able to reach. Additionally, the leaf will contain a message digest of the parts of the code that can be reached by the function. The information sent to the stateless node would be the leaf, plus the parts of the code that could be reached by the function call. My hope is that this should result in less opcodes and less proofs being needed to communicated than a fixed length approach. Tests will prove / disprove this.",
        "created_at": "2020-05-20T21:23:39.196000+00:00",
        "attachments": null
    }
]