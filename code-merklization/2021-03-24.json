[
    {
        "author": "pipermerriam",
        "category": "Channel Graveyard",
        "parent": "",
        "content": "This channel seems like it could be archived since development has shifted towards Verkle stuff.",
        "created_at": "2021-03-24T17:19:05.950000+00:00",
        "attachments": null
    },
    {
        "author": ".vbuterin",
        "category": "Channel Graveyard",
        "parent": "",
        "content": "Sounds good to me!",
        "created_at": "2021-03-24T21:44:04.270000+00:00",
        "attachments": null
    },
    {
        "author": ".vbuterin",
        "category": "Channel Graveyard",
        "parent": "",
        "content": "BTW we should have a more active discussion in how storage and code and account objects should be converted into Verkle tree keys",
        "created_at": "2021-03-24T21:44:21.133000+00:00",
        "attachments": null
    },
    {
        "author": ".vbuterin",
        "category": "Channel Graveyard",
        "parent": "",
        "content": "I'm strongly in favor of mapping everything into a single tree if at all possible, or if we have to have a two-layer structure, have just a two-layer structure, don't have this weird \"header in the middle\"",
        "created_at": "2021-03-24T21:45:11.579000+00:00",
        "attachments": null
    },
    {
        "author": "pipermerriam",
        "category": "Channel Graveyard",
        "parent": "",
        "content": "Agreed, unifying it *all* into a single layer structure sounds ideal, especially from my vantage point looking at things from a distributed storage network angle.",
        "created_at": "2021-03-24T21:45:58.725000+00:00",
        "attachments": null
    },
    {
        "author": "pipermerriam",
        "category": "Channel Graveyard",
        "parent": "",
        "content": "By all I mean accounts, storage, and *maybe* the code trie.",
        "created_at": "2021-03-24T21:46:29.798000+00:00",
        "attachments": null
    },
    {
        "author": ".vbuterin",
        "category": "Channel Graveyard",
        "parent": "",
        "content": "I say *definitely* the code trie",
        "created_at": "2021-03-24T21:46:38.254000+00:00",
        "attachments": null
    },
    {
        "author": "pipermerriam",
        "category": "Channel Graveyard",
        "parent": "",
        "content": "I only say maybe because I haven't thought about it much so I was assuming there might be dragons hiding there.",
        "created_at": "2021-03-24T21:46:59.374000+00:00",
        "attachments": null
    },
    {
        "author": ".vbuterin",
        "category": "Channel Graveyard",
        "parent": "",
        "content": "hmm the only dragon I can think of is that if we use the wrong map-to-key function then witnesses for N code chunks might be like 96 * N + 48 instead of just 48",
        "created_at": "2021-03-24T21:47:40.041000+00:00",
        "attachments": null
    },
    {
        "author": ".vbuterin",
        "category": "Channel Graveyard",
        "parent": "",
        "content": "But that's easy to avoid",
        "created_at": "2021-03-24T21:47:43.183000+00:00",
        "attachments": null
    },
    {
        "author": ".vbuterin",
        "category": "Channel Graveyard",
        "parent": "",
        "content": "The main sacrifice with a single layer that I see is that it would require either generalized branch nodes (like the current hexary tree has), or a restricted version of branch node that goes up to multiples of 32 bytes",
        "created_at": "2021-03-24T21:48:28.732000+00:00",
        "attachments": null
    },
    {
        "author": "pipermerriam",
        "category": "Channel Graveyard",
        "parent": "",
        "content": "Yeah, code chunks should be able to be normalized/compressed using high level understanding of what the data represents, rather than naive 1:1 mapping of the trie keys/data",
        "created_at": "2021-03-24T21:48:35.070000+00:00",
        "attachments": null
    },
    {
        "author": ".vbuterin",
        "category": "Channel Graveyard",
        "parent": "",
        "content": "Oh I don't even mean that; I think a naive `chunks[i] = code[31*i: 31*(i+1)]`  is totally fine",
        "created_at": "2021-03-24T21:49:20.904000+00:00",
        "attachments": null
    },
    {
        "author": ".vbuterin",
        "category": "Channel Graveyard",
        "parent": "",
        "content": "We just want to avoid `chunks[hash(i)] = code[31*i: 31*(i+1)]`",
        "created_at": "2021-03-24T21:49:33.725000+00:00",
        "attachments": null
    },
    {
        "author": ".vbuterin",
        "category": "Channel Graveyard",
        "parent": "",
        "content": "Oh sorry, add in 5 bits for \"where does the pushdata end\"",
        "created_at": "2021-03-24T21:50:01.576000+00:00",
        "attachments": null
    },
    {
        "author": "pipermerriam",
        "category": "Channel Graveyard",
        "parent": "",
        "content": "a key scheme that allows for code chunks to be stored contiguously in the trie?",
        "created_at": "2021-03-24T21:50:09.531000+00:00",
        "attachments": null
    },
    {
        "author": ".vbuterin",
        "category": "Channel Graveyard",
        "parent": "",
        "content": "right",
        "created_at": "2021-03-24T21:50:13.909000+00:00",
        "attachments": null
    },
    {
        "author": ".vbuterin",
        "category": "Channel Graveyard",
        "parent": "",
        "content": "Basically, the desiderata for a key scheme are:\n\n* Unexploitability for accounts (can't force an account to have a length-N branch without 256**N work)\n* Unexploitability for storage keys\n* Contiguous code storage",
        "created_at": "2021-03-24T21:51:27.038000+00:00",
        "attachments": null
    },
    {
        "author": ".vbuterin",
        "category": "Channel Graveyard",
        "parent": "",
        "content": "And I think we can have all that....",
        "created_at": "2021-03-24T21:51:39.492000+00:00",
        "attachments": null
    },
    {
        "author": "pipermerriam",
        "category": "Channel Graveyard",
        "parent": "",
        "content": "so something like the first chunk being at `hash(epoch | account | \"code\")` and subsequent chunks being at `hash(epoch | account | \"code\") + i`?",
        "created_at": "2021-03-24T21:51:44.973000+00:00",
        "attachments": null
    },
    {
        "author": "pipermerriam",
        "category": "Channel Graveyard",
        "parent": "",
        "content": "maybe less confusing, first chunk is at `hash(\u003csomething-that-gives-us-a-random-unique-starting-point\u003e)` and subsequent chunks being at `\u003cfirst-chunk-key\u003e + i`",
        "created_at": "2021-03-24T21:52:53.671000+00:00",
        "attachments": null
    },
    {
        "author": ".vbuterin",
        "category": "Channel Graveyard",
        "parent": "",
        "content": "yeah I think that can work",
        "created_at": "2021-03-24T21:53:15.572000+00:00",
        "attachments": null
    },
    {
        "author": "pipermerriam",
        "category": "Channel Graveyard",
        "parent": "",
        "content": "My intuition is that total number of chunks is limited enough that it allows for that contiguous address space without any meaningful increase in collision likelihood",
        "created_at": "2021-03-24T21:54:11.714000+00:00",
        "attachments": null
    }
]