[
    {
        "author": "hangleang.eth",
        "category": "Testing",
        "parent": "",
        "content": "\u003c@412614104222531604\u003e I wonder why some grandine full-node act as super-node even the `csc` field in enr only the custody requirement. is that because of decoding inconsistency?",
        "created_at": "2024-09-25T01:50:56.252000+00:00",
        "attachments": null
    },
    {
        "author": "barnabasbusa",
        "category": "Testing",
        "parent": "",
        "content": "which node?",
        "created_at": "2024-09-25T05:41:49.131000+00:00",
        "attachments": null
    },
    {
        "author": "hangleang.eth",
        "category": "Testing",
        "parent": "",
        "content": "`grandine-geth-4` and `grandine-geth-6`",
        "created_at": "2024-09-25T06:00:57.827000+00:00",
        "attachments": null
    },
    {
        "author": "barnabasbusa",
        "category": "Testing",
        "parent": "",
        "content": "do you recalculate your enr between restarts?",
        "created_at": "2024-09-25T06:35:19.049000+00:00",
        "attachments": null
    },
    {
        "author": "barnabasbusa",
        "category": "Testing",
        "parent": "",
        "content": "I have removed the flag but didnâ€™t remove the db.",
        "created_at": "2024-09-25T06:35:29.642000+00:00",
        "attachments": null
    },
    {
        "author": "barnabasbusa",
        "category": "Testing",
        "parent": "",
        "content": "I assume you keep the old enr records without recalculating your csc based on whether or not the supernode flag is set",
        "created_at": "2024-09-25T06:35:52.208000+00:00",
        "attachments": null
    },
    {
        "author": "barnabasbusa",
        "category": "Testing",
        "parent": "",
        "content": "this seems to be the recurring issue for teku as well",
        "created_at": "2024-09-25T06:36:05.002000+00:00",
        "attachments": null
    },
    {
        "author": "barnabasbusa",
        "category": "Testing",
        "parent": "",
        "content": "\u003c@425907307621122049\u003e ^",
        "created_at": "2024-09-25T06:37:30.970000+00:00",
        "attachments": null
    },
    {
        "author": "hangleang.eth",
        "category": "Testing",
        "parent": "",
        "content": "not sure about that, I need to double check",
        "created_at": "2024-09-25T06:42:58.006000+00:00",
        "attachments": null
    },
    {
        "author": "agnxsh",
        "category": "Testing",
        "parent": "",
        "content": "If this was a decoding inconsistency then someone would have kept on disconnecting from you/thrown error/downscored during discovery, I believe, and you would have missed/forked by now atleast once given that we are now in 160th ish epoch",
        "created_at": "2024-09-25T08:19:45.043000+00:00",
        "attachments": null
    },
    {
        "author": "agnxsh",
        "category": "Testing",
        "parent": "",
        "content": "Or if someone wouldâ€™ve assumed custody requirement for grandine",
        "created_at": "2024-09-25T08:20:13.430000+00:00",
        "attachments": null
    },
    {
        "author": "barnabasbusa",
        "category": "Testing",
        "parent": "",
        "content": "Any update from prysm \u003c@476250636548308992\u003e \u003c@531934490826768418\u003e ?",
        "created_at": "2024-09-25T10:23:41.974000+00:00",
        "attachments": null
    },
    {
        "author": "barnabasbusa",
        "category": "Testing",
        "parent": "",
        "content": "\u003c@425907307621122049\u003e \u003c@498331483732312075\u003e I think my report was false report.",
        "created_at": "2024-09-25T10:29:33.467000+00:00",
        "attachments": null
    },
    {
        "author": "barnabasbusa",
        "category": "Testing",
        "parent": "",
        "content": "\u003c@498331483732312075\u003e btw are you OOO? I don't wanna ping you if you are not working sorry about that",
        "created_at": "2024-09-25T10:29:51.776000+00:00",
        "attachments": null
    },
    {
        "author": "barnabasbusa",
        "category": "Testing",
        "parent": "",
        "content": "it seems like Dora page view is not refreshing, the enr is refreshing but the csc value didn't.",
        "created_at": "2024-09-25T10:30:17.450000+00:00",
        "attachments": null
    },
    {
        "author": "nishant0",
        "category": "Testing",
        "parent": "",
        "content": "we have a suspicion on the root cause, manu is working on validating it",
        "created_at": "2024-09-25T10:35:10.303000+00:00",
        "attachments": null
    },
    {
        "author": "g11tech",
        "category": "Testing",
        "parent": "",
        "content": "\u003c@412614104222531604\u003e the inventory enr need to be updated: https://config.peerdas-devnet-2.ethpandaops.io/api/v1/nodes/inventory",
        "created_at": "2024-09-25T11:40:22.115000+00:00",
        "attachments": null
    },
    {
        "author": "g11tech",
        "category": "Testing",
        "parent": "",
        "content": "they carry wrong info about csc for e.g. lodestar-geth-6 csc in their is 0x80, while in reality is 0x4 (may be because you put all nodes to supernodes earlier?)",
        "created_at": "2024-09-25T11:41:21.198000+00:00",
        "attachments": null
    },
    {
        "author": "g11tech",
        "category": "Testing",
        "parent": "",
        "content": "possibly why grandine is asking for an index it doesn't custody",
        "created_at": "2024-09-25T11:45:28.717000+00:00",
        "attachments": null
    },
    {
        "author": "g11tech",
        "category": "Testing",
        "parent": "",
        "content": "also you didn't put this flag `--persistNetworkIdentity` in lodestar nodes and your restart made then change their custody",
        "created_at": "2024-09-25T11:45:58.838000+00:00",
        "attachments": null
    },
    {
        "author": "barnabasbusa",
        "category": "Testing",
        "parent": "",
        "content": "is that a problem that they chagne their custody?",
        "created_at": "2024-09-25T11:53:13.315000+00:00",
        "attachments": null
    },
    {
        "author": "g11tech",
        "category": "Testing",
        "parent": "",
        "content": "yes, because for old blocks if it gets requests for it advertises to custody now, the requests would fail",
        "created_at": "2024-09-25T12:28:25.847000+00:00",
        "attachments": null
    },
    {
        "author": "g11tech",
        "category": "Testing",
        "parent": "",
        "content": "but once that moves out of the pruning window it would be irrelevant since nodes aren't supposed to sync pre pruning window",
        "created_at": "2024-09-25T12:29:02.343000+00:00",
        "attachments": null
    },
    {
        "author": "g11tech",
        "category": "Testing",
        "parent": "",
        "content": "this been updated?",
        "created_at": "2024-09-25T12:31:00.802000+00:00",
        "attachments": null
    },
    {
        "author": "g11tech",
        "category": "Testing",
        "parent": "",
        "content": "but you should add the flag in your ansible and restart lodestar nodes so their custody is not messedup next time you restart",
        "created_at": "2024-09-25T12:32:11.644000+00:00",
        "attachments": null
    },
    {
        "author": "g11tech",
        "category": "Testing",
        "parent": "",
        "content": "or i can default the flag to true, so you might just update to new image once i am done",
        "created_at": "2024-09-25T12:33:01.539000+00:00",
        "attachments": null
    },
    {
        "author": "barnabasbusa",
        "category": "Testing",
        "parent": "",
        "content": "is everyone else have this set to true?",
        "created_at": "2024-09-25T12:43:51.330000+00:00",
        "attachments": null
    },
    {
        "author": "barnabasbusa",
        "category": "Testing",
        "parent": "",
        "content": "I think if its a \"breaking change\" if the user is not setting it true, then it should be defaulted to true",
        "created_at": "2024-09-25T13:01:11.761000+00:00",
        "attachments": null
    },
    {
        "author": "barnabasbusa",
        "category": "Testing",
        "parent": "",
        "content": "yes",
        "created_at": "2024-09-25T13:05:20.845000+00:00",
        "attachments": null
    },
    {
        "author": "hangleang.eth",
        "category": "Testing",
        "parent": "",
        "content": "Ahh, I put just for fun, lol. but, today, I really out of home actually, eth Belgrade community organizer visit us during their road to Devcon trip in the region, so sorry for missed the chat",
        "created_at": "2024-09-25T13:41:15.737000+00:00",
        "attachments": null
    },
    {
        "author": "hangleang.eth",
        "category": "Testing",
        "parent": "",
        "content": "I gonna change the display, this would confuse everyone",
        "created_at": "2024-09-25T13:42:32.757000+00:00",
        "attachments": null
    },
    {
        "author": "agnxsh",
        "category": "Testing",
        "parent": "",
        "content": "EOL meant End of LIfe :)))",
        "created_at": "2024-09-25T13:57:02.336000+00:00",
        "attachments": null
    },
    {
        "author": "agnxsh",
        "category": "Testing",
        "parent": "",
        "content": "oh just informing, i am off today and tomorrow, for some urgent matter",
        "created_at": "2024-09-25T13:57:22.195000+00:00",
        "attachments": null
    },
    {
        "author": "manunlp",
        "category": "Testing",
        "parent": "",
        "content": "Is it possible to retrieve logs from the start of the container?\n\nWhat I tried:\n```\nssh devops@prysm-geth-5.peerdas-devnet-2.ethpandaops.io\ndocker logs beacon\n```\n\nWhat I got:\n\n```\ntime=\"2024-09-25 01:54:49.55\" level=debug msg=\"Initiate peer disconnection\" direction=Inbound error=\"is bad peer no lock: bad responses scorer: peer exceeded bad responses threshold: got 5, threshold 5\" multiaddr=\"/ip4/159.223.6.231/tcp/9000/p2p/16Uiu2HAm5opVzT6qyAVoas6bVJzbuRyvWG7XKSFt9xdYzXoMZmrH\" prefix=p2p remainingActivePeers=6\ntime=\"2024-09-25 01:54:49.70\" level=debug msg=\"Initiate peer disconnection\" direction=Inbound error=\"is bad peer no lock: gossip scorer: gossip score below threshold: got -532.345990 - threshold -100.000000\" multiaddr=\"/ip4/167.71.217.176/tcp/34532/p2p/16Uiu2HAkxE8AzQ35SJV4LeMe9SaVhJyR1sE8CA6JsTV3vicXhoJh\" prefix=p2p remainingActivePeers=6\n...\n```\n\n==\u003e First log is at `2024-09-25 01:54:49.55` several hours after the container start.\n(cc \u003c@412614104222531604\u003e )",
        "created_at": "2024-09-25T14:27:25.707000+00:00",
        "attachments": null
    },
    {
        "author": "barnabasbusa",
        "category": "Testing",
        "parent": "",
        "content": "hm might have been log rotated",
        "created_at": "2024-09-25T14:36:22.515000+00:00",
        "attachments": null
    },
    {
        "author": "manunlp",
        "category": "Testing",
        "parent": "",
        "content": "Sad. Is it possible to increase to rotation period to at least 1 full day? (Or more if possible.)",
        "created_at": "2024-09-25T14:37:09.093000+00:00",
        "attachments": null
    },
    {
        "author": "barnabasbusa",
        "category": "Testing",
        "parent": "",
        "content": "\u003c@131476523050860545\u003e ^",
        "created_at": "2024-09-25T14:40:42.407000+00:00",
        "attachments": null
    },
    {
        "author": "skylenet",
        "category": "Testing",
        "parent": "",
        "content": "\u003c@412614104222531604\u003e https://github.com/ethpandaops/peerdas-devnets/blob/master/ansible/group_vars/all/defaults.yaml#L54 you need to change this if more logs are wanted.",
        "created_at": "2024-09-25T14:47:05.646000+00:00",
        "attachments": null
    },
    {
        "author": "skylenet",
        "category": "Testing",
        "parent": "",
        "content": "currently it's just at 2x250MB. You can also bump it just for specific containers. But we would need to adjust our ansible roles to allow setting those specific log options at the container level.",
        "created_at": "2024-09-25T14:49:53.204000+00:00",
        "attachments": null
    },
    {
        "author": "barnabasbusa",
        "category": "Testing",
        "parent": "",
        "content": "do we wanna increase per container or globally?",
        "created_at": "2024-09-25T14:51:28.844000+00:00",
        "attachments": null
    },
    {
        "author": "skylenet",
        "category": "Testing",
        "parent": "",
        "content": "I think it's fine to increase globally. Just verify available disk space across all nodes and see how much of that you think makes sense to allocate for those logs. I think 2-3GB should be fine.",
        "created_at": "2024-09-25T14:54:04.776000+00:00",
        "attachments": null
    },
    {
        "author": "skylenet",
        "category": "Testing",
        "parent": "",
        "content": "Otherwise let me know if you want me to add the specific log opts to our ansible roles.",
        "created_at": "2024-09-25T14:54:40.761000+00:00",
        "attachments": null
    },
    {
        "author": "hangleang.eth",
        "category": "Testing",
        "parent": "",
        "content": "Exactly, ðŸ˜‚",
        "created_at": "2024-09-25T15:13:26.842000+00:00",
        "attachments": null
    },
    {
        "author": "barnabasbusa",
        "category": "Testing",
        "parent": "",
        "content": "looks like some lodestar nodes have stopped syncing",
        "created_at": "2024-09-25T18:19:39.237000+00:00",
        "attachments": null
    },
    {
        "author": "barnabasbusa",
        "category": "Testing",
        "parent": "",
        "content": "and we are now not finalizing",
        "created_at": "2024-09-25T18:19:46.520000+00:00",
        "attachments": null
    },
    {
        "author": "agnxsh",
        "category": "Testing",
        "parent": "",
        "content": "i can see a grandine",
        "created_at": "2024-09-25T18:36:09.298000+00:00",
        "attachments": null
    },
    {
        "author": "agnxsh",
        "category": "Testing",
        "parent": "",
        "content": "missing",
        "created_at": "2024-09-25T18:37:34.766000+00:00",
        "attachments": null
    },
    {
        "author": "agnxsh",
        "category": "Testing",
        "parent": "",
        "content": "and sometimes lh as well",
        "created_at": "2024-09-25T18:37:52.131000+00:00",
        "attachments": null
    },
    {
        "author": "agnxsh",
        "category": "Testing",
        "parent": "",
        "content": "i have identified a probable columns by range issue in nimbus, going to resolve by Friday, ooo atm",
        "created_at": "2024-09-25T18:58:59.621000+00:00",
        "attachments": null
    },
    {
        "author": "manunlp",
        "category": "Testing",
        "parent": "",
        "content": "This is the (or at least one) cause why Prysm is totally down on `peerdas-devnet-2` actually.\nFor some reason, if Grandine proposes a block with no blob, Prysm will have this error.\n(cc \u003c@412614104222531604\u003e \u003c@476250636548308992\u003e )\n\nUnfortunatly I did not had time to test Grandine\u003c-\u003ePrysm on a local devnet. So I did not see this issue myself...",
        "created_at": "2024-09-25T20:24:51.792000+00:00",
        "attachments": null
    },
    {
        "author": "manunlp",
        "category": "Testing",
        "parent": "",
        "content": "I reproduced locally. ==\u003e Prysm rejects messages from grandine. On prysm super nodes, prysm rejects 128 messages likes this. As a consequence, Prysm bans the grandine peer.\n\n\u003c@498331483732312075\u003e are you sure you don't send `/data_column_sidecar_\u003cnn\u003e` gossip messages when you propose a block with no blob?",
        "created_at": "2024-09-25T20:40:09.682000+00:00",
        "attachments": null
    },
    {
        "author": "manunlp",
        "category": "Testing",
        "parent": "",
        "content": "\u003c@412614104222531604\u003e out of curiosity, in your `pre-devnet-2` which last at least 20H did you had Grandine in the mix?\n(What I see is, for some reason, Prysm gets completely crazy when Grandine is in the mix on my local devnet. So if in your `pre-devnet-2` you did not had Grandine, it could explain why Prysm did not had any issue here. If you had Grandine, the mystery is more mysterious...)",
        "created_at": "2024-09-25T20:57:58.073000+00:00",
        "attachments": null
    },
    {
        "author": "manunlp",
        "category": "Testing",
        "parent": "",
        "content": "Looks like both Grandine and Prysm are totally erratic when they are in contact each other:",
        "created_at": "2024-09-25T21:07:30.235000+00:00",
        "attachments": [
            {
                "type": "image/png",
                "origin_name": "image.png",
                "content": "b0508f34f9a1b6a32761cda27b161debc2dcd8d2163dd7d04bc1ed43e82b1878"
            }
        ]
    },
    {
        "author": "barnabasbusa",
        "category": "Testing",
        "parent": "",
        "content": "had there in minority. 1-1 node out of 32",
        "created_at": "2024-09-25T21:46:25.898000+00:00",
        "attachments": null
    },
    {
        "author": "hangleang.eth",
        "category": "Testing",
        "parent": "",
        "content": "I have to double check on that, I will run a local devnet without grandine, thank you for the report",
        "created_at": "2024-09-25T23:22:42.625000+00:00",
        "attachments": null
    }
]