[
    {
        "author": "jimmygchen",
        "category": "Testing",
        "parent": "",
        "content": "It feels like we're pretty much ready to interop, and this is the main issue that we want to figure out right?\n\nI've looked at logs you posted, but can't really find much with `INFO` level logs ðŸ˜¦",
        "created_at": "2024-09-11T01:35:11.765000+00:00",
        "attachments": null
    },
    {
        "author": "jimmygchen",
        "category": "Testing",
        "parent": "",
        "content": "Given that both Teku and Lighthouse perform a byRoot query on columns missed via gossip, this should be a recoverable scenario if `1-geth-prysm` is able to serve the by root requests",
        "created_at": "2024-09-11T01:38:29.250000+00:00",
        "attachments": null
    },
    {
        "author": "jimmygchen",
        "category": "Testing",
        "parent": "",
        "content": "I don't see any data_column_by_roots requests from either Teku/LH supernodes in the Prysm supernode `1-geth-prysm`  logs though ðŸ¤” (for slot 321)",
        "created_at": "2024-09-11T01:56:12.414000+00:00",
        "attachments": null
    },
    {
        "author": "jimmygchen",
        "category": "Testing",
        "parent": "",
        "content": "Maybe Teku does it, I'm not sure\nIt does seem like Teku was able to get some columns from peers but didn't get all. There is enough to reconstruct though, has this been implemented?\n```\n2024-09-08 13:59:20.882 INFO  - Starting data availability check for slot 321\n2024-09-08 13:59:20.882 INFO  - Requested checkDataAvailability for 0xb39c4749a8ac25486835bd1cc102177184c589aafdd2f96c6af63b6f9e553428(321)\n2024-09-08 13:59:20.894 INFO  - [nyota] DataColumnSidecarDB.addSidecar: new slot: 321, prevSlot count: 128, total added: 40451, finalizedSlot: 287\n2024-09-08 13:59:20.917 INFO  - [nyota] DataColumnSidecarsByRootMessageHandler: REQUEST(#326) 3 data column sidecars from 16Uiu2HAmAjP6h3WE58m8bicRUmSpkzPYF2KtCjrxyB24SXeGL5uH\n2024-09-08 13:59:21.151 INFO  - [nyota] DataColumnSidecarsByRootMessageHandler: REQUEST(#327) 109 data column sidecars from 16Uiu2HAmBsUeED7FebAnsywHUAnigcKZ8v8R9L79uDn9wrhaWXBN\n2024-09-08 13:59:24.002 INFO  - Slot Event  *** Slot: 321, Block:                                                        ... empty, Justified: 9, Finalized: 8, Peers: 5\n```",
        "created_at": "2024-09-11T02:02:06.944000+00:00",
        "attachments": null
    },
    {
        "author": "jimmygchen",
        "category": "Testing",
        "parent": "",
        "content": "oh never mind, I was reading it wrong - the 109 here is the by root request from Lighthouse supernode to Teku, and Teku responded with 16 columns.\nSo i wonder why the by root requests didn't go from Teku / LH to the Prysm supernode. I'll try reproducing this locally.",
        "created_at": "2024-09-11T02:07:18.377000+00:00",
        "attachments": null
    },
    {
        "author": "hangleang.eth",
        "category": "Testing",
        "parent": "",
        "content": "Hi all, I'm looking into the [subnet sampling spec](https://github.com/ethereum/consensus-specs/blob/v1.5.0-alpha.5/specs/_features/eip7594/das-core.md#subnet-sampling), I would like to clarify on `subnet_sampling_size` on below scenario:\n- if a node is super-node, it would be the `DATA_COLUMN_SIDECAR_SUBNET_COUNT`\n- but if a node is normal node, would it be the `SAMPLES_PER_SLOT` or `CUSTODY_REQUIREMENT`?",
        "created_at": "2024-09-11T04:55:50.162000+00:00",
        "attachments": null
    },
    {
        "author": "g11tech",
        "category": "Testing",
        "parent": "",
        "content": "lodestar interop went good till 71 epochs but post that peering issue happened i guess",
        "created_at": "2024-09-11T07:08:38.311000+00:00",
        "attachments": null
    },
    {
        "author": "g11tech",
        "category": "Testing",
        "parent": "",
        "content": "made a few fixes on lodestar side to make things stable",
        "created_at": "2024-09-11T07:09:08.380000+00:00",
        "attachments": null
    },
    {
        "author": "g11tech",
        "category": "Testing",
        "parent": "",
        "content": "started interop with prsym, things seem to be going fine, will report back how long the interop goes",
        "created_at": "2024-09-11T07:10:59.297000+00:00",
        "attachments": null
    },
    {
        "author": "dmitriishmatko",
        "category": "Testing",
        "parent": "",
        "content": "nice catch\nit's SAMPLES_PER_SLOT per spec, which is bigger than CUSTODY_REQUIREMENT in current config.  I thought we want it to be CUSTODY_REQUIREMENT",
        "created_at": "2024-09-11T08:31:01.802000+00:00",
        "attachments": null
    },
    {
        "author": "dmitriishmatko",
        "category": "Testing",
        "parent": "",
        "content": "In Teku we sample CUSTODY_REQUIREMENT in full node",
        "created_at": "2024-09-11T08:34:56.514000+00:00",
        "attachments": null
    },
    {
        "author": "agnxsh",
        "category": "Testing",
        "parent": "",
        "content": "same in Nimbus",
        "created_at": "2024-09-11T08:52:14.032000+00:00",
        "attachments": null
    },
    {
        "author": "manunlp",
        "category": "Testing",
        "parent": "",
        "content": "same in Prysm",
        "created_at": "2024-09-11T08:52:22.276000+00:00",
        "attachments": null
    },
    {
        "author": "jimmygchen",
        "category": "Testing",
        "parent": "",
        "content": "Same in LH",
        "created_at": "2024-09-11T08:54:16.661000+00:00",
        "attachments": null
    },
    {
        "author": "manunlp",
        "category": "Testing",
        "parent": "",
        "content": "New local devnet failure analysis: https://hackmd.io/@6-HLeMXARN2tdFLKKcqrxw/S1A0GRAhC\n\nSome issues detected on Teku super node and Prysm full node (no issues detected on LH both super and full node.)\n\u003c@425907307621122049\u003e , about issue `3.`, I'm curious to know if you have an idea why `3-geth-teku` disconnected `1-geth-prysm`.",
        "created_at": "2024-09-11T10:08:47.107000+00:00",
        "attachments": null
    },
    {
        "author": "g11tech",
        "category": "Testing",
        "parent": "",
        "content": "lodestar seems to be interoping good with prsym, could you check against lodestar as well",
        "created_at": "2024-09-11T10:09:56.831000+00:00",
        "attachments": null
    },
    {
        "author": "g11tech",
        "category": "Testing",
        "parent": "",
        "content": "what do the other clients respond if i add  datacolumns which it doesn't custody, do they just filter out those data columns in response or do they error?",
        "created_at": "2024-09-11T10:11:53.148000+00:00",
        "attachments": null
    },
    {
        "author": "g11tech",
        "category": "Testing",
        "parent": "",
        "content": "^^^^ data columns by range /root req/resp",
        "created_at": "2024-09-11T10:12:47.483000+00:00",
        "attachments": null
    },
    {
        "author": "manunlp",
        "category": "Testing",
        "parent": "",
        "content": "I'm not sure to understand the question.\nIf your question is: \"what does a node do if a peer requests a data column the node does not custody\", in this case, Prysm will downscore the requesting peer.\n(And so, if such a request is repeated too often, Prysm will disconnect the peer.)",
        "created_at": "2024-09-11T10:14:18.374000+00:00",
        "attachments": null
    },
    {
        "author": "g11tech",
        "category": "Testing",
        "parent": "",
        "content": "yes, but we should not do so in data columns by root request especially for the latest slot because a non supernode who proposed it has all the columns and could probably respond",
        "created_at": "2024-09-11T10:19:09.159000+00:00",
        "attachments": null
    },
    {
        "author": "g11tech",
        "category": "Testing",
        "parent": "",
        "content": "also what does prsym respond if i add a column in request not custodied by you? will you filter it out in response or will you error the api",
        "created_at": "2024-09-11T10:20:30.551000+00:00",
        "attachments": null
    },
    {
        "author": "g11tech",
        "category": "Testing",
        "parent": "",
        "content": "then this can be used as a strategy to even poll peers for the latest slot who don't have the columns custodied",
        "created_at": "2024-09-11T10:21:35.553000+00:00",
        "attachments": null
    },
    {
        "author": "manunlp",
        "category": "Testing",
        "parent": "",
        "content": "This can be discussed, but, for Prysm, if a full node do propose a block, it stores only in its DB data columns it should custody (even if it had, in order to propose the block, to build all columns). ==\u003e So if you request a prysm full node for some columns it does not custody, even for a block it proposed, then it won't be able to respond. (And it will downscore therequesting peer.)",
        "created_at": "2024-09-11T10:22:20.265000+00:00",
        "attachments": null
    },
    {
        "author": "g11tech",
        "category": "Testing",
        "parent": "",
        "content": "another Q: if you are not a supernode, do you not subscribe to subnets which you don't custody",
        "created_at": "2024-09-11T10:22:26.888000+00:00",
        "attachments": null
    },
    {
        "author": "g11tech",
        "category": "Testing",
        "parent": "",
        "content": "hmmm, lodestar stores and can respond to all columns on its proposed block",
        "created_at": "2024-09-11T10:23:38.695000+00:00",
        "attachments": null
    },
    {
        "author": "manunlp",
        "category": "Testing",
        "parent": "",
        "content": "If a prysm full node custodies columns `a`, `b` and `c`, and if a peer requests column by root `d`, then Prysm will respond with `invalid column index requested` for all the request (and will downscore the requesting peer).",
        "created_at": "2024-09-11T10:27:12.778000+00:00",
        "attachments": null
    },
    {
        "author": "manunlp",
        "category": "Testing",
        "parent": "",
        "content": "Yes I see, it could make sense. (But it is not implemented right now in Prysm.)",
        "created_at": "2024-09-11T10:27:45.482000+00:00",
        "attachments": null
    },
    {
        "author": "manunlp",
        "category": "Testing",
        "parent": "",
        "content": "Yes. (Actually we might have a bug in Prysm where a full node does subscribe to subnets it does not custody. But in this case it is a bug and it has to be fixed.)",
        "created_at": "2024-09-11T10:28:42.874000+00:00",
        "attachments": null
    },
    {
        "author": "manunlp",
        "category": "Testing",
        "parent": "",
        "content": "OK, after internal discussion, we will do that as well.",
        "created_at": "2024-09-11T10:39:42.086000+00:00",
        "attachments": null
    },
    {
        "author": "g11tech",
        "category": "Testing",
        "parent": "",
        "content": "lodestar looks quite stable with prsym, trying with lighthouse now",
        "created_at": "2024-09-11T11:59:21.669000+00:00",
        "attachments": null
    },
    {
        "author": "g11tech",
        "category": "Testing",
        "parent": "",
        "content": "seems good with lighthouse as well",
        "created_at": "2024-09-11T12:33:34.666000+00:00",
        "attachments": null
    },
    {
        "author": "jimmygchen",
        "category": "Testing",
        "parent": "",
        "content": "I'm running all 4 clients and see the Prysm full node configured with columns withheld seeing orhpaned blocks - i suspect this is caused by supernodes not allocated enough CPUs to do reconstruction quickly (seeing 1-2.5s on LH) - will increase the `cl_max_cpu` and see if this improves",
        "created_at": "2024-09-11T12:43:03.112000+00:00",
        "attachments": null
    },
    {
        "author": "jimmygchen",
        "category": "Testing",
        "parent": "",
        "content": "I suspect some issues in our data column by root lookups, so we weren't able to recover in this case -  i ran out of time to try this today, but I'll try triggering block lookup from Teku and Lighthouse to Prysm tomorrow",
        "created_at": "2024-09-11T12:52:11.363000+00:00",
        "attachments": null
    },
    {
        "author": "dmitriishmatko",
        "category": "Testing",
        "parent": "",
        "content": "Btw we have merged PR in Teku (already in ethpandaops image) decreasing DEBUG noise 3-4 times. So Teku should be less struggle in DEBUG now",
        "created_at": "2024-09-11T13:30:27.865000+00:00",
        "attachments": null
    },
    {
        "author": "parithosh",
        "category": "Testing",
        "parent": "",
        "content": "soz i havent followed the last ~day of discussions here. Does someone have a summary for me? And are 4 clients interoping well now? Should i trigger a longer test on kurtosis and then subsequently launch peerDAS-devnet-2? Or are there still active debug topics?",
        "created_at": "2024-09-11T13:44:41.354000+00:00",
        "attachments": null
    },
    {
        "author": "agnxsh",
        "category": "Testing",
        "parent": "",
        "content": "i need some more monitoring and fixing time for the nimbus full node, nimbus supernode interops well in a Prysm, LH, Lodestar supernode + full node environment last time i checked, the full node needs a closer view on what it custodies and just req/resp domain overall",
        "created_at": "2024-09-11T13:47:00.423000+00:00",
        "attachments": null
    },
    {
        "author": "dmitriishmatko",
        "category": "Testing",
        "parent": "",
        "content": "thanks for analysis\ni'm working on fixing reconstruction at the moment\nlooks like it would be helpful there",
        "created_at": "2024-09-11T13:51:17.064000+00:00",
        "attachments": null
    },
    {
        "author": "dmitriishmatko",
        "category": "Testing",
        "parent": "",
        "content": "just skip those not available, not cancelling whole request, no downscoring or whatever",
        "created_at": "2024-09-11T13:52:42.369000+00:00",
        "attachments": null
    },
    {
        "author": "dmitriishmatko",
        "category": "Testing",
        "parent": "",
        "content": "Teku doesn't store proposed columns on full node too. Publish and forget",
        "created_at": "2024-09-11T13:54:13.877000+00:00",
        "attachments": null
    },
    {
        "author": "dmitriishmatko",
        "category": "Testing",
        "parent": "",
        "content": "Teku subscribes only to custodied subnets",
        "created_at": "2024-09-11T13:55:20.333000+00:00",
        "attachments": null
    },
    {
        "author": "agnxsh",
        "category": "Testing",
        "parent": "",
        "content": "+1 for Nimbus, propose, check which ones are custody, store those, forget the rest",
        "created_at": "2024-09-11T13:55:21.230000+00:00",
        "attachments": null
    },
    {
        "author": "g11tech",
        "category": "Testing",
        "parent": "",
        "content": "yes that seems to be the best option as such",
        "created_at": "2024-09-11T14:22:33.426000+00:00",
        "attachments": null
    },
    {
        "author": "fradamt",
        "category": "Testing",
        "parent": "",
        "content": "Itâ€™s SAMPLES_PER_SLOT for a full node (which doesnâ€™t set a higher than minimum custody count). The reason is that SAMPLES_PER_SLOT defines our security requirements (for full nodes, the most relevant thing is that we want only a small minority to be able to be tricked into accepting an unavailable chain), while the CUSTODY_REQUIREMENT is just about having a backbone for subnets. The reason for not just setting a higher CUSTODY_REQUIREMENT is that we agreed with \u003c@476250636548308992\u003e that it would make it easier to eventually substitute the subnet sampling with peer sampling, were we to want to do that, because you could just stop doing the extra subnet subscriptions (samples per slot - custody) without your peers caring about it",
        "created_at": "2024-09-11T18:17:10.124000+00:00",
        "attachments": null
    },
    {
        "author": "dmitriishmatko",
        "category": "Testing",
        "parent": "",
        "content": "could we set same numbers at least for devnet2?",
        "created_at": "2024-09-11T20:03:47.427000+00:00",
        "attachments": null
    },
    {
        "author": "fradamt",
        "category": "Testing",
        "parent": "",
        "content": "Can you maybe set custody requirement to 8 then? It would be more realistic that way",
        "created_at": "2024-09-11T20:04:44.967000+00:00",
        "attachments": null
    },
    {
        "author": "dmitriishmatko",
        "category": "Testing",
        "parent": "",
        "content": "so extra columns (compared to custody requirement) should be not random, calculated with get_custody_columns, right?",
        "created_at": "2024-09-11T20:06:05.877000+00:00",
        "attachments": null
    },
    {
        "author": "fradamt",
        "category": "Testing",
        "parent": "",
        "content": "Yes. It all works just the same as custody, only not advertised and not enforced by peers (but it wouldn't make much of a difference here)",
        "created_at": "2024-09-11T20:06:57.102000+00:00",
        "attachments": null
    },
    {
        "author": "dmitriishmatko",
        "category": "Testing",
        "parent": "",
        "content": "Ok, I will check first, how difficult it will be to extend it to custody_requirements in our code",
        "created_at": "2024-09-11T20:11:07.939000+00:00",
        "attachments": null
    },
    {
        "author": "manunlp",
        "category": "Testing",
        "parent": "",
        "content": "My understanding was neither peer sampling nor this extended custody requirement were in the scope of `peerdas-devnet-2`.",
        "created_at": "2024-09-11T20:30:45.737000+00:00",
        "attachments": null
    },
    {
        "author": "jimmygchen",
        "category": "Testing",
        "parent": "",
        "content": "It might be easier to just bump the custody requirement, since samples per slot is known and computable by the network anyways - so like you said it doesnâ€™t make much difference. Currently subscribed custody subnets are tied to custody count in meta data and ENR in the code, and will require extra changes to make this happen and revert later when we have peer sampling.",
        "created_at": "2024-09-11T20:36:43.294000+00:00",
        "attachments": null
    },
    {
        "author": "jimmygchen",
        "category": "Testing",
        "parent": "",
        "content": "I guess we all assumed the PR just drops peer sampling ðŸ˜‚ I did read through it but missed that section.",
        "created_at": "2024-09-11T20:38:35.677000+00:00",
        "attachments": null
    },
    {
        "author": "manunlp",
        "category": "Testing",
        "parent": "",
        "content": "Yes, mass hallucination ðŸ˜‚ \nhttps://notes.ethereum.org/@ethpandaops/peerdas-devnet-2. It is definitely included.",
        "created_at": "2024-09-11T20:45:26.234000+00:00",
        "attachments": null
    },
    {
        "author": "dmitriishmatko",
        "category": "Testing",
        "parent": "",
        "content": "what is called `spec without peer sampling` is curent spec sampling, which we discovered is wider than custody",
        "created_at": "2024-09-11T20:49:28.771000+00:00",
        "attachments": null
    },
    {
        "author": "dmitriishmatko",
        "category": "Testing",
        "parent": "",
        "content": "it's just not random",
        "created_at": "2024-09-11T20:49:37.368000+00:00",
        "attachments": null
    },
    {
        "author": "fradamt",
        "category": "Testing",
        "parent": "",
        "content": "It's without peer sampling, just not without sampling",
        "created_at": "2024-09-11T20:57:06.907000+00:00",
        "attachments": null
    },
    {
        "author": "fradamt",
        "category": "Testing",
        "parent": "",
        "content": "The reason the spec is the way it is now is through discussion with \u003c@476250636548308992\u003e. He suggested it would be harder to later lower the custody requirement",
        "created_at": "2024-09-11T20:57:56.381000+00:00",
        "attachments": null
    },
    {
        "author": "nishant0",
        "category": "Testing",
        "parent": "",
        "content": "Yeah, we want the ability to drop subnet participation without being penalized by peers",
        "created_at": "2024-09-11T23:59:25.673000+00:00",
        "attachments": null
    }
]