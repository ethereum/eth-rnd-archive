[
    {
        "author": "fradamt",
        "category": "Testing",
        "parent": "",
        "content": "I don't think PeerDAS not being in Pectra should be a reason to make big architectural changes. It was needed yesterday and so far we don't have something working. Moreover, what would we actually get out of 2D that moves the needle in a first version? Things to consider:\n- Are we going to not have subnet sampling at all and just shoot for peer sampling *in the critical path of attesting*? Imo there's 0 evidence that we are successfully going to ship a robust version of this next year, and I would't say that there is even a super clear idea of how this would be made robust enough in theory.\n- If we are not going for peer sampling in the critical path, then 2D does not improve things at all *for validators*, at least not from a scalability perspective, because you would still need to get a few columns and/or rows to attest. It can allow for lighter full nodes that even today, but I don't think that meaningfully helps us to scale blob counts in a world where solo stakers exist and they are expected to attest.\n- If we are going for peer sampling in the critical path, then even the current construction gets a very large scalability boost, because sampling loses the amplification factor. At that point, the bottlenecks to scaling blob count are elsewhere, e.g., data dissemination, EL mempool, distributed block building\n- For distributed reconstruction, we would need row subnets and gossiping/requesting individual cells. By adding these, we could also get distributed reconstruction *in 1D* (in the current version), because you'd just be able to do reconstruction in the row subnets. The only difference is that there wouldn't be any vertical redundancy, so a failure of any single row subnet prevents reconstruction (see here https://ethresear.ch/t/subnetdas-an-intermediate-das-approach/17169/7?u=fradamt and here https://ethresear.ch/t/from-4844-to-danksharding-a-path-to-scaling-ethereum-da/18046#stages-at-a-glance-1). I think we can live with that, certainly for now.",
        "created_at": "2024-11-20T03:56:47.327000+00:00",
        "attachments": null
    },
    {
        "author": "fradamt",
        "category": "Testing",
        "parent": "",
        "content": "To summarize, imho 2D gives us two things: more robust distributed reconstruction (while it is *not* necessary for it) and cheaper sampling *for full nodes*. It could give us more (cheaper sampling for nodes with few validators), but to me betting on that seems like the wrong kind of ambitious. High risk of just delaying the whole thing for a while more, very low potential reward: let's even say we ship it, are we going to do so with 128 blobs? I really doubt we would, and the current 1D construction should be able to comfortably scale to 32 or even 64 blobs imho. Plus, getting cheaper sampling for validators means we have satisfactorily solved the problem of doing peer sampling in the critical path, at which point even 1D sampling would be much cheaper and the extra savings of 2D sampling don't really move the needle",
        "created_at": "2024-11-20T03:56:49.120000+00:00",
        "attachments": null
    },
    {
        "author": ".asanso",
        "category": "Testing",
        "parent": "",
        "content": "Having a timeline of PQ  Ethereum seems to be a really controversial topic right now and we are really far away to reach any consensus in the Research team (let alone if we open the discussion in the ACD calls :)).",
        "created_at": "2024-11-20T09:43:03.447000+00:00",
        "attachments": null
    }
]