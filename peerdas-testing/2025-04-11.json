[
    {
        "author": "mininny",
        "category": "Testing",
        "parent": "",
        "content": "Hello \u003c@498331483732312075\u003e, i'm working on spinning up devnet-6 and I reset a few grandine nodes to sync from genesis. I've been getting this error: `[2025-04-11T01:34:06.107+00:00] [ERROR] [eth2_libp2p::rpc::self_limiter] [peers: 35/100] Self rate limiting error for a batch that will never fit. Sending request anyway. Check configuration parameters., service: libp2p_rpc, service: libp2p, protocol: blob_sidecars_by_range`. It seems to be the same configuration issue from [lighthouse](https://discord.com/channels/595666850260713488/1351554405891051561/1353706089526329354) since it probably uses the same module, but I couldn't find `--disable-self-limiter` and `--disable-inbound-rate-limiter` flags from grandine. How could I resolved this to sync nodes from genesis?",
        "created_at": "2025-04-11T04:19:31.246000+00:00",
        "attachments": null
    },
    {
        "author": "hangleang.eth",
        "category": "Testing",
        "parent": "",
        "content": "Yes, Grandine share the module (eth2_libp2p) with LH.\n\nMay I know what is the max blobs per block in this network?",
        "created_at": "2025-04-11T04:33:26.313000+00:00",
        "attachments": null
    },
    {
        "author": "mininny",
        "category": "Testing",
        "parent": "",
        "content": "It's set up 72, but I haven't sent any blob txs into the network yet, which seems kind of weird too. I can give you the grafana / node access if you'd like",
        "created_at": "2025-04-11T04:34:40.354000+00:00",
        "attachments": null
    },
    {
        "author": "hangleang.eth",
        "category": "Testing",
        "parent": "",
        "content": "same as LH, we restrict to 896 per 10s",
        "created_at": "2025-04-11T04:37:40.602000+00:00",
        "attachments": null
    },
    {
        "author": "hangleang.eth",
        "category": "Testing",
        "parent": "",
        "content": "Yes, that would be helpful",
        "created_at": "2025-04-11T04:37:58.445000+00:00",
        "attachments": null
    },
    {
        "author": "mininny",
        "category": "Testing",
        "parent": "",
        "content": "Grandine rate limit",
        "created_at": "2025-04-11T04:53:44.484000+00:00",
        "attachments": null
    },
    {
        "author": "jimmygchen",
        "category": "Testing",
        "parent": "",
        "content": "\u003c@564345498471759890\u003e do we have column gossip verification metric for lodestar, nimbus and teku? I think it would be useful to capture these, as the gossip verification time would impact data column propagation, because clients verify the messages before forwarding to its peers. \n\nI think this *may* become a bottleneck at higher blob count, and would be worth optimising for. Lighthouse takes around 10-50ms with the current blob count on devnet-6, but I'm seeing 250-500ms+ on high blob count locally (max 64) - \nthis means each hop could be delayed quite a bit, and it adds up as the hop count increases. We may need to rely on distributed publishing more or find some other ways to reduce the number of hops. (cc \u003c@520034910149410861\u003e @csaba \u003c@478543974156730369\u003e )",
        "created_at": "2025-04-11T05:02:37.156000+00:00",
        "attachments": null
    },
    {
        "author": "jimmygchen",
        "category": "Testing",
        "parent": "",
        "content": "@Katya do we have column gossip",
        "created_at": "2025-04-11T06:23:32.482000+00:00",
        "attachments": null
    },
    {
        "author": "barnabasbusa",
        "category": "Testing",
        "parent": "",
        "content": "does anyone still actively workong on devnet 5? Otherwise we could yeet it by EOD. \u003c@785811170387951616\u003e",
        "created_at": "2025-04-11T07:10:22.258000+00:00",
        "attachments": null
    },
    {
        "author": "agnxsh",
        "category": "Testing",
        "parent": "",
        "content": "Can we keep it till Monday?",
        "created_at": "2025-04-11T07:24:17.351000+00:00",
        "attachments": null
    },
    {
        "author": "agnxsh",
        "category": "Testing",
        "parent": "",
        "content": "I have some more debugging to do with the syncer, and devnet 5 has gone long enough to do these tests, plus full node supernode distribution is also very ideal",
        "created_at": "2025-04-11T07:25:31.722000+00:00",
        "attachments": null
    },
    {
        "author": "barnabasbusa",
        "category": "Testing",
        "parent": "",
        "content": "Okay then devnet 5 is expected to go down on monday end of the day",
        "created_at": "2025-04-11T07:38:46.073000+00:00",
        "attachments": null
    },
    {
        "author": "sibkatya",
        "category": "Testing",
        "parent": "",
        "content": "Teku also has gossip verification metric. But I've noticed that Teku's metrics are missing on the dashboard. Will tag Teku team. Nimbus - WIP, Lodestar - not yet, waiting for their refactoring.",
        "created_at": "2025-04-11T08:47:04.922000+00:00",
        "attachments": null
    },
    {
        "author": "agnxsh",
        "category": "Testing",
        "parent": "",
        "content": "couple of issues found on nimbus because of the race done by gossip blob validation and getBlobsV2 in applying the block first, this should be a necessary fix `getBlobsV2-339866e`",
        "created_at": "2025-04-11T12:25:03.910000+00:00",
        "attachments": null
    },
    {
        "author": "agnxsh",
        "category": "Testing",
        "parent": "",
        "content": "cc \u003c@412614104222531604\u003e",
        "created_at": "2025-04-11T12:25:10.008000+00:00",
        "attachments": null
    },
    {
        "author": "manunlp",
        "category": "Testing",
        "parent": "",
        "content": "\u003c@412614104222531604\u003e I don't see any blobs for the few lasts epochs on `peerdas-devnet-6`. Is is expected?",
        "created_at": "2025-04-11T14:08:07.789000+00:00",
        "attachments": null
    },
    {
        "author": "manunlp",
        "category": "Testing",
        "parent": "",
        "content": "(Same issue than with spamoor in Kurtosis?)",
        "created_at": "2025-04-11T14:08:16.655000+00:00",
        "attachments": null
    },
    {
        "author": "barnabasbusa",
        "category": "Testing",
        "parent": "",
        "content": "cc \u003c@808969530608451584\u003e",
        "created_at": "2025-04-11T14:12:21.332000+00:00",
        "attachments": null
    },
    {
        "author": "manunlp",
        "category": "Testing",
        "parent": "",
        "content": "seems back",
        "created_at": "2025-04-11T14:16:44.614000+00:00",
        "attachments": null
    },
    {
        "author": "pk910",
        "category": "Testing",
        "parent": "",
        "content": "yea, I've restarted the spammer.\nIt got stuck for some reason..  looking into it ðŸ™‚",
        "created_at": "2025-04-11T14:17:15.741000+00:00",
        "attachments": null
    },
    {
        "author": "manunlp",
        "category": "Testing",
        "parent": "",
        "content": "I don't remember what was decided about `peerdas-denvet-5`, but from my point of view it's OK to nuke it now.",
        "created_at": "2025-04-11T14:32:42.013000+00:00",
        "attachments": null
    },
    {
        "author": "barnabasbusa",
        "category": "Testing",
        "parent": "",
        "content": "https://discord.com/channels/595666850260713488/1252403418941624532/1360157112315023360",
        "created_at": "2025-04-11T14:36:41.549000+00:00",
        "attachments": null
    },
    {
        "author": "manunlp",
        "category": "Testing",
        "parent": "",
        "content": "Lol this one was not far away ðŸ˜‚",
        "created_at": "2025-04-11T14:48:43.065000+00:00",
        "attachments": null
    },
    {
        "author": "jtraglia",
        "category": "Testing",
        "parent": "",
        "content": "Hi all, I'd like to discuss how to configure blob schedules in clients for BPO forks.",
        "created_at": "2025-04-11T14:57:11.414000+00:00",
        "attachments": null
    },
    {
        "author": "jtraglia",
        "category": "Testing",
        "parent": "",
        "content": "I'll make another thread for the CL.",
        "created_at": "2025-04-11T16:38:00.409000+00:00",
        "attachments": null
    },
    {
        "author": "ben_a_adams",
        "category": "Testing",
        "parent": "",
        "content": "Yes, because uncapped tx blob counts prevent scaling",
        "created_at": "2025-04-11T17:48:45.313000+00:00",
        "attachments": null
    },
    {
        "author": "tersec",
        "category": "Testing",
        "parent": "",
        "content": "I thought you were proposing adding a max per-tx gas limit, nothing relating to blob counts?",
        "created_at": "2025-04-11T17:50:14.347000+00:00",
        "attachments": null
    },
    {
        "author": "ben_a_adams",
        "category": "Testing",
        "parent": "",
        "content": "Different EIP",
        "created_at": "2025-04-11T17:50:34.052000+00:00",
        "attachments": null
    },
    {
        "author": "ben_a_adams",
        "category": "Testing",
        "parent": "",
        "content": "This is just max blob count per tx",
        "created_at": "2025-04-11T17:51:03.414000+00:00",
        "attachments": null
    },
    {
        "author": "tersec",
        "category": "Testing",
        "parent": "",
        "content": "`\"maxGasPerTx\": 786432` as part of BPOs is this specific proposal here",
        "created_at": "2025-04-11T17:51:22.959000+00:00",
        "attachments": null
    },
    {
        "author": "tersec",
        "category": "Testing",
        "parent": "",
        "content": "from https://discord.com/channels/595666850260713488/1252403418941624532/1359871726133182514",
        "created_at": "2025-04-11T17:51:56.769000+00:00",
        "attachments": null
    },
    {
        "author": "ben_a_adams",
        "category": "Testing",
        "parent": "",
        "content": "maxPerTx https://github.com/ethereum/EIPs/pull/9623/files",
        "created_at": "2025-04-11T17:53:27.132000+00:00",
        "attachments": null
    },
    {
        "author": "tersec",
        "category": "Testing",
        "parent": "",
        "content": "ok, that's a different thing, yeah",
        "created_at": "2025-04-11T17:54:11.788000+00:00",
        "attachments": null
    },
    {
        "author": "ben_a_adams",
        "category": "Testing",
        "parent": "",
        "content": "EIP-7825 the tx cap was CFI'd for Fuska; but is irrelvent for peerDAS",
        "created_at": "2025-04-11T17:54:26.073000+00:00",
        "attachments": null
    },
    {
        "author": "ben_a_adams",
        "category": "Testing",
        "parent": "",
        "content": "But you can't optimally fill blocks if both the block has a blob cap and the tx is uncapped, as two large blob txs won't fit together causing it to be underfilled and unoptimal blob packing",
        "created_at": "2025-04-11T17:56:08.995000+00:00",
        "attachments": null
    },
    {
        "author": "ben_a_adams",
        "category": "Testing",
        "parent": "",
        "content": "Will have the issue in Pectra and already have it now; but Pectra at 9 blobs, two 5 blob txs will mean only 5 blobs get filled (as both would make 10 blobs, which can't fit); so are underfilled by 4 with no cap; even though the demand is there",
        "created_at": "2025-04-11T17:59:01.074000+00:00",
        "attachments": null
    },
    {
        "author": "ben_a_adams",
        "category": "Testing",
        "parent": "",
        "content": "Similar issue with unbounded tx gas; but bounded block gas",
        "created_at": "2025-04-11T18:00:06.258000+00:00",
        "attachments": null
    },
    {
        "author": "ben_a_adams",
        "category": "Testing",
        "parent": "",
        "content": "So then might reject both 5 blobs txs (1 fee); and take a 4 blob, and two 3 blob txs instead for 3 priority fees; unless the 5 blob is paying priorty fees for 9 blobs to get inclusion against the oppertunity cost",
        "created_at": "2025-04-11T18:05:52.507000+00:00",
        "attachments": null
    },
    {
        "author": "ben_a_adams",
        "category": "Testing",
        "parent": "",
        "content": "Wheras it would be better if the EL wasn't making these weird NP packing choices; by capping max per tx and achieving maximal fill rather than underfill; which goes against the point of scaling",
        "created_at": "2025-04-11T18:06:45.763000+00:00",
        "attachments": null
    },
    {
        "author": "tersec",
        "category": "Testing",
        "parent": "",
        "content": "Yeah, the general question I'd have is more, do all these other parameters benefit much from riding along on this BPO rather than being specified in a more usual way",
        "created_at": "2025-04-11T18:07:43.829000+00:00",
        "attachments": null
    },
    {
        "author": "ben_a_adams",
        "category": "Testing",
        "parent": "",
        "content": "Optimal MaxBlobPerTx can change based on max per block; as the block max gets bigger so can the max per tx. If you don't want to have that option and just have it capped for an entire main hard fork ðŸ¤·",
        "created_at": "2025-04-11T18:09:54.753000+00:00",
        "attachments": null
    },
    {
        "author": "ben_a_adams",
        "category": "Testing",
        "parent": "",
        "content": "Doesn't need to be changed; but leaves the door open for it to be changd",
        "created_at": "2025-04-11T18:10:34.866000+00:00",
        "attachments": null
    },
    {
        "author": "ben_a_adams",
        "category": "Testing",
        "parent": "",
        "content": "Example now; a higher paying 3 blob tx should kick out a lower paying 6 blob tx; leaving the blobs underfilled and blob demand pricing wrong (on target 3) even though demand is over target (9)",
        "created_at": "2025-04-11T18:16:18.539000+00:00",
        "attachments": [
            {
                "type": "image/png",
                "origin_name": "425368678-a9f2191e-5139-42ba-9184-f5e14dd78a7e.png",
                "content": "53dfecf52e12232e460547a05d323427cafac8e524e813588e78fbc7aa870f04"
            }
        ]
    },
    {
        "author": "ben_a_adams",
        "category": "Testing",
        "parent": "",
        "content": "Or you have 5 blobs in 1 tx that become 4 blobs in 2 txs because that pays more, even though it was possible to fit 6 in the middle; but the optimal priority fee packing is only 4; so 1 above target even though there were 15 that wanted to get in",
        "created_at": "2025-04-11T18:18:57.279000+00:00",
        "attachments": [
            {
                "type": "image/png",
                "origin_name": "425227318-34dc1eed-04f5-406a-ae40-f14092b4da0c.png",
                "content": "c4850fea23a622086eabb620502997d296962e2c994c3907f9e05dcc8a55161b"
            }
        ]
    },
    {
        "author": "ben_a_adams",
        "category": "Testing",
        "parent": "",
        "content": "Which messes with the blob fee market as it isn't properly measuring demand; due to the txs not being able to be packed together as the tx blob counts are too high",
        "created_at": "2025-04-11T18:19:51.658000+00:00",
        "attachments": null
    }
]