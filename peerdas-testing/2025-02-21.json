[
    {
        "author": "jimmygchen",
        "category": "Testing",
        "parent": "",
        "content": "Just thinking out loud - does it make sense to have some minimum requirement on distributed blob publishing under PeerDAS? Under the current spec (https://github.com/ethereum/consensus-specs/pull/3864/files), clients are required to publish all blobs upon successful retrieval from the EL.\n\nWe discussed this earlier and agreed to leave it up to the client teams, but  I wonder if some more predictable behaviour (e.g. prioritise publishing the node's custody columns) would help making sure columns are evenly published? \n\nRight now Lighthouse uses a gradual publication mechanism to avoid excessive bandwidth on the publishing node, and we divide the columns into 4 batches randomly, and publish them out in intervals. (so first batch we send out 32 columns to 6-8 peers)\nBut i guess it may be very useful to have clients publish columns with a different strategy, say 50% of all columns, each to 2 mesh peers, or all columns, each to 1 mesh peer.\n\nNow after typing this, i feel like it may make sense sense to have different impls - would love to hear thoughts on this though!",
        "created_at": "2025-02-21T01:00:04.473000+00:00",
        "attachments": null
    },
    {
        "author": "skylenet",
        "category": "Testing",
        "parent": "",
        "content": "I'm doing some changes on devnet-5 regarding lodestars validators. Splitting them across more nodes. Should be done in a couple of minutes. Some participation drop is expected.",
        "created_at": "2025-02-21T08:31:39.040000+00:00",
        "attachments": null
    },
    {
        "author": "hangleang.eth",
        "category": "Testing",
        "parent": "",
        "content": "thanks \u003c@531934490826768418\u003e for reporting this, there are some failed spec test on fulu, the team is working on it now",
        "created_at": "2025-02-21T09:38:55.028000+00:00",
        "attachments": null
    },
    {
        "author": "arnetheduck",
        "category": "Testing",
        "parent": "",
        "content": "I haven't followed for a bit - has there been any progress on the supernode issue in peerdas? ie evaluating peerdas without supernodes?",
        "created_at": "2025-02-21T11:10:27.713000+00:00",
        "attachments": null
    },
    {
        "author": "manunlp",
        "category": "Testing",
        "parent": "",
        "content": "What's the \"supernode issue\" you are referring to?\n\nClients are currently implementing validator custody, which will make nodes managing enough ETH via connected validators clients by default supernodes.",
        "created_at": "2025-02-21T13:04:20.611000+00:00",
        "attachments": null
    },
    {
        "author": "manunlp",
        "category": "Testing",
        "parent": "",
        "content": "",
        "created_at": "2025-02-21T13:04:39.231000+00:00",
        "attachments": [
            {
                "type": "image/png",
                "origin_name": "image.png",
                "content": "edfe9bdd5aa0673c86ca17f300477a25d6257b1bda3a35411fe990d21d58839f"
            }
        ]
    },
    {
        "author": "sauliusgrigaitis",
        "category": "Testing",
        "parent": "",
        "content": "But this is not enforced by protocol? I mean a large validator can patch the client and avoid validator custody without on-chain penalty?",
        "created_at": "2025-02-21T14:32:26.266000+00:00",
        "attachments": null
    },
    {
        "author": "matthewkeil",
        "category": "Testing",
        "parent": "",
        "content": "Looks like we are fully up and running \u003c@131476523050860545\u003e.  Thanks again for the help with that!!  I got the keys on our hosted nodes setup correctly and those indices (2080-2099) are attesting/proposing fine now",
        "created_at": "2025-02-21T14:37:44.297000+00:00",
        "attachments": null
    },
    {
        "author": "skylenet",
        "category": "Testing",
        "parent": "",
        "content": "and... devnet-4 is gone \u003c:rip:847932976212738048\u003e",
        "created_at": "2025-02-21T14:38:43.888000+00:00",
        "attachments": null
    },
    {
        "author": "manunlp",
        "category": "Testing",
        "parent": "",
        "content": "Yes. There is no accountability.",
        "created_at": "2025-02-21T14:39:49.625000+00:00",
        "attachments": null
    },
    {
        "author": "fradamt",
        "category": "Testing",
        "parent": "",
        "content": "All they would gain by doing that is save a bit of bandwidth. I imagine operators with billions of stake would not want to maintain a patched client just to not use more of the Gbit connection they anyway most likely already have",
        "created_at": "2025-02-21T14:46:38.960000+00:00",
        "attachments": null
    },
    {
        "author": "fradamt",
        "category": "Testing",
        "parent": "",
        "content": "If that turns out to be a problem we can always add accountability, and in the future we anyway might want to do that. But for the time being I wouldn't worry about it not being effective, I think there's almost no chance that any meaningful amount of the stake disables it",
        "created_at": "2025-02-21T14:48:55.641000+00:00",
        "attachments": null
    },
    {
        "author": "sauliusgrigaitis",
        "category": "Testing",
        "parent": "",
        "content": "The interesting outcome of such non-accountable duties is that often the correctness of implementation is accidentally (or maybe even intentionally) overlooked. For example, when we compared Grandine's aggregation duties with other clients we found that some other clients actually underperform for aggregation. The funny thing is that such underperforming client actually uses fewer resources so users prefer it because it utilizes fewer resources to get the same validator rewards. I mean there is simply no motivation to even correctly implement this non-accountable functionality  in the client because the client becomes less attractive compared to a more broken client that gives the same rewards and uses less resources compared to a correctly working client.\n\nSo I would strongly suggest designing a solution that has on-chain penalties.",
        "created_at": "2025-02-21T15:20:49.545000+00:00",
        "attachments": null
    },
    {
        "author": "dapplion",
        "category": "Testing",
        "parent": "",
        "content": "Your specific example about the aggregation bug got the dedicated attention of our engineers until we fixed it. I also believe that the chance of forked clients for minor bandwidth savings is very low. Therefore we only need  (1) monitoring / testing of clients (2) get client teams to fix issues. Seems easier than implementing on-chain penalties",
        "created_at": "2025-02-21T17:17:42.276000+00:00",
        "attachments": null
    },
    {
        "author": "sauliusgrigaitis",
        "category": "Testing",
        "parent": "",
        "content": "Bandwidth and computing resources required for correct aggregation on a node with a large number of validators is very large, it's not minor.",
        "created_at": "2025-02-21T17:21:43.683000+00:00",
        "attachments": null
    },
    {
        "author": "sauliusgrigaitis",
        "category": "Testing",
        "parent": "",
        "content": "While I prefer on-chain penalties I also agree that often it's hard or even impossible to design a great on-chain penalties system.",
        "created_at": "2025-02-21T17:22:54.704000+00:00",
        "attachments": null
    },
    {
        "author": "sauliusgrigaitis",
        "category": "Testing",
        "parent": "",
        "content": "So I'm just trying to say that obviously if there is no hard motivation (on-chain penalties) - we can't rely that nodes will perform as these duties as good as other duties with on-chain penalties. I personally think that duties without on-chain penalties are protocol's flaws. So if we see an elegant on-chain penalty design for new duties, then I think we must include it.",
        "created_at": "2025-02-21T17:29:02.744000+00:00",
        "attachments": null
    },
    {
        "author": "dapplion",
        "category": "Testing",
        "parent": "",
        "content": "\u003c@131476523050860545\u003e I'm running a LH node using this dir as `--testnet-dir` but all discv5 queries come empty https://github.com/ethpandaops/peerdas-devnets/tree/master/network-configs/devnet-5/metadata are these the correct bootnodes?",
        "created_at": "2025-02-21T17:54:52.607000+00:00",
        "attachments": null
    },
    {
        "author": "skylenet",
        "category": "Testing",
        "parent": "",
        "content": "Should be correct if it matches the ENRs in here https://config.peerdas-devnet-5.ethpandaops.io/api/v1/nodes/inventory . Iâ€™m AFK rn, so itâ€™s hard for me to compare and check.",
        "created_at": "2025-02-21T18:21:44.361000+00:00",
        "attachments": null
    },
    {
        "author": "skylenet",
        "category": "Testing",
        "parent": "",
        "content": "You could also SSH into one of the lighthouse VMs and compare your config with one there.",
        "created_at": "2025-02-21T18:24:46.585000+00:00",
        "attachments": null
    },
    {
        "author": "arnetheduck",
        "category": "Testing",
        "parent": "",
        "content": "yeah, this is what I was referring to - ie it's no longer a p2p network at that point, but rather a supernode network with two categories of nodes - basically, it means that these nodes become high-value targets for disruption and our \"decentralisation\" is only as good as the amount of these nodes",
        "created_at": "2025-02-21T19:02:20.697000+00:00",
        "attachments": null
    },
    {
        "author": "arnetheduck",
        "category": "Testing",
        "parent": "",
        "content": "altruistic or no is a bit of a different matter - as long as each node on the network more or less performs the same function, we can deal with a few stragglers not doing it (ie bugs, etc), because the overwhelming majority of nodes can cover for them - when there are special nodes, they become the weak link",
        "created_at": "2025-02-21T19:03:52.640000+00:00",
        "attachments": null
    },
    {
        "author": "arnetheduck",
        "category": "Testing",
        "parent": "",
        "content": "I kind of agree that operators will not switch it off just like that, to save a bit of bandwidth - but also, if the supply of such nodes is small, that's a problem in and of itself",
        "created_at": "2025-02-21T19:05:40.779000+00:00",
        "attachments": null
    },
    {
        "author": "arnetheduck",
        "category": "Testing",
        "parent": "",
        "content": "just like we've handed over block building responsibilities to mev relays, which have been the source of most \"outages\" or at least instabilities on eth2, so will these nodes become a focal point for disruption",
        "created_at": "2025-02-21T19:07:09.820000+00:00",
        "attachments": null
    },
    {
        "author": "jtraglia",
        "category": "Testing",
        "parent": "",
        "content": "What would you consider to be a small supply?",
        "created_at": "2025-02-21T19:08:14.629000+00:00",
        "attachments": null
    },
    {
        "author": "arnetheduck",
        "category": "Testing",
        "parent": "",
        "content": "lol, you tell me ðŸ˜‰ we tend to think of ethereum as having about 3-5k nodes participating on a \"mostly equal\" basis - this is one layer in its resilience against censorship etc - let's say we bring it down to .. 30 .. that's probably a number we can agree would be .. dissatisfactory.",
        "created_at": "2025-02-21T19:11:04.164000+00:00",
        "attachments": null
    },
    {
        "author": "arnetheduck",
        "category": "Testing",
        "parent": "",
        "content": "30 is something you can fairly easily put out of service if you put your mind (and money to it) .. 3k, less so. so what's the real number? no idea - which is why I'm asking the question",
        "created_at": "2025-02-21T19:12:49.011000+00:00",
        "attachments": null
    },
    {
        "author": "jtraglia",
        "category": "Testing",
        "parent": "",
        "content": "I believe there will be more than 30 supernodes, probably 100+. I imagine lots of staking providers will be supernodes \u0026 some individuals (like myself) will do it altruistically. But yeah, I have no idea either.",
        "created_at": "2025-02-21T19:23:00.058000+00:00",
        "attachments": null
    },
    {
        "author": "jtraglia",
        "category": "Testing",
        "parent": "",
        "content": "According to this dune dashboard (https://dune.com/hildobby/eth2-staking), there are ~80 known entities with 2048+ ETH. But we don't know the validator/node breakdown of their setups. Like I mentioned before, we could use relay registrations (which are publicly available) to get a rough number of validators per node. It's possible to group validators by registration timestamp.",
        "created_at": "2025-02-21T19:23:13.241000+00:00",
        "attachments": null
    },
    {
        "author": "jtraglia",
        "category": "Testing",
        "parent": "",
        "content": "\u003c@792404665068158998\u003e is this something you'd be interested in doing? Or do you have any other ideas?",
        "created_at": "2025-02-21T19:24:58.250000+00:00",
        "attachments": null
    }
]