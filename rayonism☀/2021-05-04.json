[
    {
        "author": "potuz",
        "category": "Channel Graveyard",
        "parent": "",
        "content": "After fixing a timing issue on prysm I am seeing some very weird problems of catalyst forking the eth1 chain here, since this is completely out of my depth, probably better to ask here, is there something inherently wrong in trying to interop Teku + Prysm with the same eth1 endpoint? I don't mind adding Nethermind or Besu here, just wanted to have the simplest setup possible.",
        "created_at": "2021-05-04T16:57:09.160000+00:00",
        "attachments": []
    },
    {
        "author": "protolambda",
        "category": "Channel Graveyard",
        "parent": "",
        "content": "There is an assumption that the block insertions and head changes are one after the other. I think concurrent usage should still work, but this is definitely unstable territory",
        "created_at": "2021-05-04T17:05:41.684000+00:00",
        "attachments": []
    },
    {
        "author": "potuz",
        "category": "Channel Graveyard",
        "parent": "",
        "content": "ok, so I may be hitting this problem then... I'll see if I can run two different endpoints as well",
        "created_at": "2021-05-04T17:08:20.476000+00:00",
        "attachments": []
    },
    {
        "author": "protolambda",
        "category": "Channel Graveyard",
        "parent": "",
        "content": "Also note that when you share an eth1 node, the latency in information is going down a lot, and you end up triggering some types of forks more easily, due to the way reorgs are, and the way legacy chain difficulty logic may affect these short forks on the catalyst side (cc \u003c@!353136597522448385\u003e \u003c@!425572898787426305\u003e )",
        "created_at": "2021-05-04T17:08:33.036000+00:00",
        "attachments": []
    },
    {
        "author": "potuz",
        "category": "Channel Graveyard",
        "parent": "",
        "content": "in short: without changes in prysm, whenever I insert a transaction, Teku is always first to propose with it, prysm does not accept the block and the connection is severed. Prysm tries to insert the transaction several blocks after this. If I \"fix\"  prysm to insert the transaction as soon as it sees it, then prysm does insert the transaction at the right time, but Teku doesn't like any of prysm blocks, and moreover, as soon as prysm inserts the transaction both nodes start forking, with both eth2 nodes trying to propose the same block and the eth1 node producing blocks nearly at the same time... I say \"fix\"  in quotes because this may be no fix at all afterall if the problem was caused by a shared eth1 endpoint ðŸ˜¦",
        "created_at": "2021-05-04T17:12:32.960000+00:00",
        "attachments": []
    },
    {
        "author": "protolambda",
        "category": "Channel Graveyard",
        "parent": "",
        "content": "\u003c@!363800010518822915\u003e may be able to help with Prysm here",
        "created_at": "2021-05-04T17:14:27.207000+00:00",
        "attachments": []
    },
    {
        "author": "terence0083",
        "category": "Channel Graveyard",
        "parent": "",
        "content": "Im curious whether this work if they each have their own eth1 end point. Have you tried it? Im happy to try here as well after im done with my current task",
        "created_at": "2021-05-04T17:20:25.392000+00:00",
        "attachments": []
    },
    {
        "author": "protolambda",
        "category": "Channel Graveyard",
        "parent": "",
        "content": "There is this PR in geth to implement more complete consensus work for eth2, and hopefully fix reorg related forking problems: https://github.com/ethereum/go-ethereum/pull/22639",
        "created_at": "2021-05-04T17:33:39.812000+00:00",
        "attachments": []
    },
    {
        "author": "potuz",
        "category": "Channel Graveyard",
        "parent": "",
        "content": "Oh I was about to confirm \u003c@!203220829473996800\u003e's observation: running with independent nodes the forks dissapear, and the dangling transactions in the mempool being picked with long delays by both clients also disappear. For anyone trying to interop different clients, hope this saves you some time, run with independent eth1 endpoints or you will see lots of false problems which are horrible to debug. I don't know how Infura and the such will be serving execution blocks to the consensus engine, but that's a different story",
        "created_at": "2021-05-04T18:28:32.365000+00:00",
        "attachments": []
    },
    {
        "author": "schone_wizard",
        "category": "Channel Graveyard",
        "parent": "",
        "content": "Curious to hear more about the problem infura and such might face?",
        "created_at": "2021-05-04T21:49:52.787000+00:00",
        "attachments": []
    },
    {
        "author": "ryanleeschneider",
        "category": "Channel Graveyard",
        "parent": "",
        "content": "my guess is that for the merge itself we'll end up running 1:1 eth1/eth2 nodes, just so we're running a similar topology as everyone else in case things go wrong.  longer term we're hoping we can make a proxy to sit between N beacon and M application nodes to ease our hardware footprint.  I've been swamped with other stuff so haven't been able to participate in the hackathon unfortunately.  Our ideal footprint is a small number of beacon nodes (\u003e1 for HA) serving as a consensus layer for a large number of application nodes (where large is roughly in the double digit order or magnitude).",
        "created_at": "2021-05-04T22:11:43.474000+00:00",
        "attachments": []
    }
]