[
    {
        "author": "yiannisbot",
        "category": "general",
        "parent": "",
        "content": "Hi folks, we've recently completed a measurement study on node bandwidth availability - very relevant to the discussion last week on blob count increase. The ethresear.ch post is here: https://ethresear.ch/t/bandwidth-availability-in-ethereum-regional-differences-and-network-impacts/21138",
        "created_at": "2024-12-03T13:20:57.986000+00:00",
        "attachments": null
    },
    {
        "author": "arnetheduck",
        "category": "general",
        "parent": "",
        "content": "\u003e saturate the node‚Äôs uplink and as a result find out how much bandwidth it‚Äôs got available\n\nI'm curious about this aspect of the study - ie basically RPC calls are rate-limited by clients and the rate is not a function of \"available bandwidth\" but rather a propperty of the rate limiter and other aspects such as hard drive (how long does it take to fetch data from disk etc) and priorities within the client (does it treat gossip traffic preferentially vs RPC). It seems like this might introduce a lot of noise into the assumption about the RPC rate being a good indicator of \"available bandwidth\" (if this wasn't the case, this would be an easy way to disrupt a client, because at the end of the day, RPC calls are altruistic best-effort affairs while gossip is given priority)\n\nThese effects largely explain why larger requests look like \"node supports more bandwidth\" simply because they lower round-trip latency, allow batch reads from disk etc. When measuring, how did you account for these things?",
        "created_at": "2024-12-03T13:50:55.342000+00:00",
        "attachments": null
    },
    {
        "author": "popef",
        "category": "general",
        "parent": "",
        "content": "Yeah, I'm reading this post and thought about the priority stuff as well. I think it's the main reason that the measured available bandwidth can go wrong.\n\nFor example, let's say some node has a bandwidth of 50Mbps and the clients use it all, and then you send the RPC call and the node instead reduces the client bandwidth to 40Mbps and give you another 10Mbps to serve the RPC call.\n\nI think we have to make sure that the clients get the highest priority before we can conclude that the measured one is the actual available bandwidth.\n\nOne of the demonstration is let's try to saturate your laptop bandwidth maybe by downloading big files and then browse the websites, I think you can browse the websites but maybe a bit slower than usual.\n\nBut I haven't finished reading, maybe I missed something",
        "created_at": "2024-12-03T13:58:51.240000+00:00",
        "attachments": null
    },
    {
        "author": "popef",
        "category": "general",
        "parent": "",
        "content": "TBH, I cannot think of a reliable way to measure available bandwidth. I think it's a good idea to do such measurement method, but it's too early to make a conclusion.",
        "created_at": "2024-12-03T14:57:47.931000+00:00",
        "attachments": null
    },
    {
        "author": "yiannisbot",
        "category": "general",
        "parent": "",
        "content": "Yup, I don't disagree with you or with \u003c@964433541813375036\u003e 's thinking, but in both cases, this means that we're measuring the worst case scenario, i.e., the node has at least `x` Mbps even after serving client traffic that has higher priority.\n\n\u003e When measuring, how did you account for these things?\n\nWe didn't really, because there's no easy way to do so, but knowing that what we're seeing is the worst case helps understand where we stand ü§∑‚Äç‚ôÇÔ∏è",
        "created_at": "2024-12-03T16:12:48.563000+00:00",
        "attachments": null
    },
    {
        "author": "popef",
        "category": "general",
        "parent": "",
        "content": "\u003e the node has at least x Mbps even after serving client traffic that has higher priority.\n\nYou cannot know `x`, right?\n\nLet's take the example I mentioned, let's say the node has 50Mbps and the client processes use all of it, when you send the RPC, it's likely that the node will split some bandwidth to serve your RPC call. (let's say 10Mbps to serve your call and 40Mbps to be used by client processes)\n\n`x` is obviously zero, but what you measured is 10Mbps.",
        "created_at": "2024-12-03T16:17:41.340000+00:00",
        "attachments": null
    },
    {
        "author": "yiannisbot",
        "category": "general",
        "parent": "",
        "content": "Hmm, well, if the node can spare those 10Mbps to the RPCs because it can delay serving some of the client requests (e.g., they're not time-sensitive), then I'd say `x=10Mbps` in this case.",
        "created_at": "2024-12-03T16:21:48.375000+00:00",
        "attachments": null
    },
    {
        "author": "popef",
        "category": "general",
        "parent": "",
        "content": "But in the normal time, the clients use 50Mbps and you have 50Mbps. So there is no bandwidth available.",
        "created_at": "2024-12-03T16:24:16.741000+00:00",
        "attachments": null
    },
    {
        "author": "yiannisbot",
        "category": "general",
        "parent": "",
        "content": "I'd say that rate limiting seems to kick in when the success rate in this plot goes down: https://ethresear.ch/t/bandwidth-availability-in-ethereum-regional-differences-and-network-impacts/21138#p-51501-setting-rpc-retries-5",
        "created_at": "2024-12-03T16:24:23.875000+00:00",
        "attachments": null
    },
    {
        "author": "popef",
        "category": "general",
        "parent": "",
        "content": "In fact, the machine cannot split the bandwidth by itself. The bandwidth sharing happens in the wire before the router.",
        "created_at": "2024-12-03T16:26:45.615000+00:00",
        "attachments": null
    },
    {
        "author": "yiannisbot",
        "category": "general",
        "parent": "",
        "content": "I won't disagree, but the thing is that there's no good way to have more detailed insights on this. Unless we could measure things on a testnet until things break, i.e., blocks don't get delivered in time. But again, not sure how accurate this will be üòÖ",
        "created_at": "2024-12-03T16:27:37.629000+00:00",
        "attachments": null
    },
    {
        "author": "popef",
        "category": "general",
        "parent": "",
        "content": "Yeah, that's why I said it's a good idea to do it, but it's way too early to make a conclusion about available bandwidth that is left for us to use.",
        "created_at": "2024-12-03T16:28:35.564000+00:00",
        "attachments": null
    },
    {
        "author": "popef",
        "category": "general",
        "parent": "",
        "content": "Since the split can happen in any ratio (0/50, 10/40, 20/30, 25/25, 30/20), I think we don't have any insight of the available bandwidth from the measurement yet.\n\nOne thing that we get from the measurement is the lower bound of the actual bandwidth, but the measured number is like 20Mbps which is so low that I think every node already has more bandwidth than that.",
        "created_at": "2024-12-03T16:34:25.468000+00:00",
        "attachments": null
    },
    {
        "author": "popef",
        "category": "general",
        "parent": "",
        "content": "If the bandwidth of some node is like 1Gbps but it uses only 100Mbps for clients, you would know that because the RPC call will be real fast. But from the numbers you measured, it seems there is no (or very few) such node.",
        "created_at": "2024-12-03T16:37:13.857000+00:00",
        "attachments": null
    },
    {
        "author": "yiannisbot",
        "category": "general",
        "parent": "",
        "content": "\u003e One thing that we get from the measurement is the lower bound of the actual bandwidth\nExactly. That's what I meant further up by \"worst case scenario\".",
        "created_at": "2024-12-03T16:37:15+00:00",
        "attachments": null
    },
    {
        "author": "yiannisbot",
        "category": "general",
        "parent": "",
        "content": "Another way to look at this (perhaps, thinking out loud) is that if there was less bandwidth than we measured available, then our probes would have disrupted the network (slightly) and we would see an increase in the block arrival time. Which is not the case if you look at this plot: https://probelab.io/ethereum/block_arrival/2024-48/#message_arrivals_max_min_on_1536s_window_on_topic_mainnet_beacon_block-plot (our study was from the 23rd to 28th Nov).",
        "created_at": "2024-12-03T16:40:53.364000+00:00",
        "attachments": null
    },
    {
        "author": "popef",
        "category": "general",
        "parent": "",
        "content": "That's unlikely.\nIn order to disrupt the network, you would need so much bandwidth that you can almost attack the entire mainnet, which I guess you don't have.\nIt's like if you can significantly delay the propagatime time of the entire mainnet, it means you can almost reorg the chain, which is a kind of attack.\nSo, if you can see the increase, you have that much bandwidth (which I think too much), if not, you don't, but it doesn't mean there was more bandwidth than you measured.",
        "created_at": "2024-12-03T16:49:55.845000+00:00",
        "attachments": null
    },
    {
        "author": "popef",
        "category": "general",
        "parent": "",
        "content": "And to do the measurement like what you did, you need only higher bandwidth than most of each individual node which is not much.",
        "created_at": "2024-12-03T16:56:04.642000+00:00",
        "attachments": null
    },
    {
        "author": "yiannisbot",
        "category": "general",
        "parent": "",
        "content": "Yup, now that I think about it, we also didn't do the probing all at once to all of the nodes, of course.",
        "created_at": "2024-12-03T16:58:12.531000+00:00",
        "attachments": null
    }
]