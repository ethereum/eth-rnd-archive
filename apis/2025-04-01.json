[
    {
        "author": "nflaig",
        "category": "Consensus Layer",
        "parent": "",
        "content": "\u003e It would be good to see validator clients and beacon nodes enable compression; this can significantly bring down the size of transmissions.\n\u003c@144468805697929216\u003e since this seems a bit off topic I am rather asking it here, would the idea be to add a new content type like `Content-Type: application/x-snappy-framed` or would it rather be `Content-Encoding: snappy`, and the client uses `Accept-Encoding` to signal support for it. I tend to lean towards the later since it could be rolled out pretty seamlessly in a backward compatible way.",
        "created_at": "2025-04-01T09:44:37.233000+00:00",
        "attachments": null
    },
    {
        "author": "jgm",
        "category": "Consensus Layer",
        "parent": "",
        "content": "If I run a request from `curl` with `--compressed` it sends\n\n```\nAccept-Encoding: deflate, gzip, br, zstd\n```\n\nAnd they seem like reasonable options.  Servers can pick whichever ones they want to support, and if someone wants to support `snappy` as well on the server side no reason why not (if we're after a reduction in bandwidth I believe that `zstd` compresses better than `snappy`, although I haven't looked at this for a while) as long as the relevant client and server libraries support it.\n\nIt seems like a very cheap option to obtain a speedup if people are bandwidth-limited, and pretty painless to implement.",
        "created_at": "2025-04-01T09:51:25.717000+00:00",
        "attachments": null
    },
    {
        "author": "nflaig",
        "category": "Consensus Layer",
        "parent": "",
        "content": "yeah I think this is the right way to go about it, I haven't really looked at benchmarks for this either, but compression seemed unnecessary so far since usually VC\u003c\u003eBN are connected over a loopback connection. But assuming blobs have a lot of 0 bytes if not fully used maybe compression gives us a lot of payload size decrease, especially if we have 72 or more blobs.",
        "created_at": "2025-04-01T09:55:56.860000+00:00",
        "attachments": null
    },
    {
        "author": "jgm",
        "category": "Consensus Layer",
        "parent": "",
        "content": "It may not be the ultimate solution, but it seems like it's very much low hanging fruit in terms of an immediate tweak to clients and servers that should reduce bandwidth usage.  And no co-ordination required, it can be added on each side whenever people get around to it and the benefit will show up as both sides find agreement.",
        "created_at": "2025-04-01T09:58:32.764000+00:00",
        "attachments": null
    },
    {
        "author": "nflaig",
        "category": "Consensus Layer",
        "parent": "",
        "content": "also cc \u003c@737740104281489531\u003e since you have asked this before, I think for Vero (and I guess Vouch also) it might be more interesting since to get the most out of multi-node redundancy it is favorable to have nodes external to the validator client, so compression seems more valuable here",
        "created_at": "2025-04-01T10:03:09.687000+00:00",
        "attachments": null
    },
    {
        "author": "serenita_io",
        "category": "Consensus Layer",
        "parent": "",
        "content": "I welcome every idea that reduces the slight disadvantage of an externally located VC ðŸ™‚ and yes, I agree people running Vouch/Vero will likely be running them on a separate machine, not loopback.\n\nI like the idea of SSZ+snappy since the exact same thing already happens on the libp2p layer",
        "created_at": "2025-04-01T10:17:45.440000+00:00",
        "attachments": null
    }
]