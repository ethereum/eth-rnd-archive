[
    {
        "author": "sproul",
        "category": "Consensus Layer",
        "parent": "",
        "content": "I've just posted a PR to make randao verification optional on the block production endpoint. I'd mainly like this PR to be adopted by \u003c@\u0026595681804422479873\u003e Nimbus, but it may be of interest to others (maybe \u003c@144468805697929216\u003e, who likes standards \u0026 benchmarking).\n\nhttps://github.com/ethereum/beacon-APIs/pull/222",
        "created_at": "2022-07-04T04:36:45.293000+00:00",
        "attachments": []
    },
    {
        "author": "arnetheduck",
        "category": "Consensus Layer",
        "parent": "",
        "content": "all the blocks \u0026 1 state / day from genesis as snappy-ssz: https://beacon.tennisbowling.com/eras/ - code to read the format: https://github.com/status-im/nimbus-eth2/blob/unstable/ncli/e2store.py",
        "created_at": "2022-07-04T05:20:20.238000+00:00",
        "attachments": []
    },
    {
        "author": "arnetheduck",
        "category": "Consensus Layer",
        "parent": "",
        "content": "I've been thinking about your deposits feedback, would probably make sense to throw it in there as well, regardless",
        "created_at": "2022-07-04T05:20:44.033000+00:00",
        "attachments": []
    },
    {
        "author": "arnetheduck",
        "category": "Consensus Layer",
        "parent": "",
        "content": "cc \u003c@833706406699073536\u003e ^ tar has lots of features we don't need, and it lacks useful features we could make good use iof - one thing in particular: it doesn't support random access meaning you can't serve beaconblocksbyrange requests straight from them, but have to unpack first",
        "created_at": "2022-07-04T05:22:58.479000+00:00",
        "attachments": []
    },
    {
        "author": "__kasey__",
        "category": "Consensus Layer",
        "parent": "",
        "content": "regarding random access, an http client can efficient interact with a remote tar resource like this:\n- download resource bytes until header has been read (sentinel value of 2 sequential 512 byte chunks - kind of like the 2 newlines that complete an http/1.1 request)\n- header contains size + byte offset for each file. these can be used to make http requests with `Range` headers (which are supported by any worthwhile caching/cdn/cloud storage frontend)",
        "created_at": "2022-07-04T17:44:26.852000+00:00",
        "attachments": []
    },
    {
        "author": "arnetheduck",
        "category": "Consensus Layer",
        "parent": "",
        "content": "afair, each file in a tarball has a separate header (ie there's no header at the beginning of the file that outlines _all_ files - the order of files within a tarball is also not specified)",
        "created_at": "2022-07-04T17:49:40.303000+00:00",
        "attachments": []
    },
    {
        "author": "__kasey__",
        "category": "Consensus Layer",
        "parent": "",
        "content": "yeah you might be right, it's been a few years since i implemented something along these lines and i may be misremembering - maybe you need to skip ahead one header at a time. given we're discussing tars with 2 files that might be fine?",
        "created_at": "2022-07-04T17:50:48.764000+00:00",
        "attachments": []
    },
    {
        "author": "__kasey__",
        "category": "Consensus Layer",
        "parent": "",
        "content": "interaction with compression does seem messy though. but a compressed ssz file is also not going to have good random seek characteristics.",
        "created_at": "2022-07-04T17:52:26.804000+00:00",
        "attachments": []
    },
    {
        "author": "arnetheduck",
        "category": "Consensus Layer",
        "parent": "",
        "content": "3 files at least (block, state, deposits) - and the point here is that we generally want a format that is convenient to _read_ above all, because then it can serve as an archival format (for caching, cold storage and so on) - tar is difficult to read in general, so you need to use a complex library with many dependencies usually, just to read a state - tar is not used anywhere else in ethereum, so it's a significant (audit) cost",
        "created_at": "2022-07-04T17:53:02.062000+00:00",
        "attachments": []
    },
    {
        "author": "arnetheduck",
        "category": "Consensus Layer",
        "parent": "",
        "content": "era files compress each section separately (much like a zip file, but not like a tar.gz)",
        "created_at": "2022-07-04T17:53:27.006000+00:00",
        "attachments": []
    },
    {
        "author": "arnetheduck",
        "category": "Consensus Layer",
        "parent": "",
        "content": "above all, ssz and snappy are already in all clients by necessity",
        "created_at": "2022-07-04T17:53:45.608000+00:00",
        "attachments": []
    },
    {
        "author": "__kasey__",
        "category": "Consensus Layer",
        "parent": "",
        "content": "re audit cost, one of the main reasons i suggested it is standard library support in go and rust (not sure about the other implementations)",
        "created_at": "2022-07-04T17:53:59.592000+00:00",
        "attachments": []
    },
    {
        "author": "__kasey__",
        "category": "Consensus Layer",
        "parent": "",
        "content": "what is the era format?",
        "created_at": "2022-07-04T17:54:24.318000+00:00",
        "attachments": []
    },
    {
        "author": "arnetheduck",
        "category": "Consensus Layer",
        "parent": "",
        "content": "a simple TLV format that's being discussed as an option to enable long-term archival of states and blocks, so they can be dropped from the p2p protocol: https://github.com/status-im/nimbus-eth2/blob/unstable/docs/e2store.md#era-files",
        "created_at": "2022-07-04T17:57:41.765000+00:00",
        "attachments": []
    },
    {
        "author": "__kasey__",
        "category": "Consensus Layer",
        "parent": "",
        "content": "gotcha, i will give this a look for sure",
        "created_at": "2022-07-04T17:58:12.426000+00:00",
        "attachments": []
    }
]