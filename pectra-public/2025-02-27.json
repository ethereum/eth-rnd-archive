[
    {
        "author": "protoplanetary",
        "category": "Channel Graveyard",
        "parent": "",
        "content": "Yep. I think on mainnet either we would be forced to canonicalize the bugged fork, or to figure out an amnesty to permit the bugged stake to rejoin the correct chain safely. I just think a flag to censor slashings, without the accompanying research studying the game theory of such a situation, and the intentional decision to plan for an amnesty, would probably be a mistake",
        "created_at": "2025-02-27T00:01:55.845000+00:00",
        "attachments": null
    },
    {
        "author": "ajsutton",
        "category": "Channel Graveyard",
        "parent": "",
        "content": "you don't _need_ the \"slash-risk\" validators to come back online to recover the chain, but it can make it faster. I do think it's really important to ensure that if you attest to a bad chain you get punished and if you attest with a majority that justifies a bad chain you should be punished a _lot_ so slashing 2/3rd of the stake is a critical thing that must happen. It's the whole basis of PoS security.",
        "created_at": "2025-02-27T00:02:10.053000+00:00",
        "attachments": null
    },
    {
        "author": "ajsutton",
        "category": "Channel Graveyard",
        "parent": "",
        "content": "What I think this shows is two-fold:\n1. we probably should significantly increase inactivity leak penalties so offline validators drain out much faster and allow the chain to return to finality without them having to volunteer to get slashed. And possibly need to investigate what options there are to allow validators to exit faster during long non-finality (but there's a lot of details to that around weak subjectivity)\n2. we need to keep investing in ways to have operators detect client bugs and avoid attesting when there's a potential chain split. Admittedly the same bug was in a lot of clients this time, but not all. Particularly for large operators, running multiple clients and only attesting when they agree should be more common (and easier to do).",
        "created_at": "2025-02-27T00:05:12.830000+00:00",
        "attachments": null
    },
    {
        "author": "protoplanetary",
        "category": "Channel Graveyard",
        "parent": "",
        "content": "It looks like \u003c@554799849288105986\u003e is considering the amnesty question in conjunction with the slash-preventing flag proposal. *As part of a carefully considered plan to offer amnesty to honest validators in the case of a supermajority bug*, I think the flag makes sense. Just not as a one-off yolo Holesky hotfix, without any further research/thought about the game theory during a supermajority bug split on mainnet.",
        "created_at": "2025-02-27T00:29:21.443000+00:00",
        "attachments": null
    },
    {
        "author": "yokem55",
        "category": "Channel Graveyard",
        "parent": "",
        "content": "Forgive me if I'm completely off base - but couldn't there be another out for the not-yet-slashed but offline validators from the majority chain by consolidating the offline, majority validator into an online minority one?",
        "created_at": "2025-02-27T03:20:54.204000+00:00",
        "attachments": null
    },
    {
        "author": "yokem55",
        "category": "Channel Graveyard",
        "parent": "",
        "content": "To answer myself - consolidations are subject to the exit queue. So - it's no different then the potentially slashable majority validators just exiting instead of getting slashed.",
        "created_at": "2025-02-27T05:24:08.401000+00:00",
        "attachments": null
    },
    {
        "author": "serenita_io",
        "category": "Channel Graveyard",
        "parent": "",
        "content": "\u003e running multiple clients and only attesting when they agree should be more common (and easier to do).\n\nThis is why I created the Vero validator client, it makes it *very* easy to attest based on combined data from multiple clients. Vouch and DVT also exist and support this usecase, although they're a bit more difficult to get set up. I don't think we're short of options at this point.\n\nHowever, in this specific Holesky case 4 different EL clients exhibited the exact same faulty behavior. Even with an imaginary \"ideal professional\" setup (5 different CL and EL clients), none of the above multi-node solutions would have avoided this bug if you as a staker decided to follow whichever chain most client implementations agreed on.\n\nTherefore, from a staking node operator's point of view, should we really take this to the extreme and stop attesting whenever *even a single client* disagrees about the state of the chain to avoid getting validators slashed?",
        "created_at": "2025-02-27T07:03:57.644000+00:00",
        "attachments": null
    },
    {
        "author": "sproul",
        "category": "Channel Graveyard",
        "parent": "",
        "content": "yes I think stopping attesting when any client indicates a consensus fault is an OK model, albeit difficult to do (from an infra PoV)\n\nsomething else I was considering is whether we try to pause justification/finalization for some period around forks, either by intentionally only attesting with a subset of validators, or by making it part of the protocol (no processing of just/fin for N epochs post fork). This would give us some time to debug issues at fork boundaries while the stakes are lower, and would be even more important with something like SSF where we might only have 12s to detect and mitigate a consensus fault",
        "created_at": "2025-02-27T10:08:14.577000+00:00",
        "attachments": null
    },
    {
        "author": "jgm",
        "category": "Channel Graveyard",
        "parent": "",
        "content": "We commonly see dissenting data, 2 or even 3 way splits with attestation data across 4 nodes.  So a simple \"stop if it's different\" response is likely to result in validators shutting down constantly.\n\nThere could be situations where specific patterns of attestation data being seen would be considered worth halting for, but it's not an approach that could be generalized.",
        "created_at": "2025-02-27T10:12:19.841000+00:00",
        "attachments": null
    },
    {
        "author": "nishant0",
        "category": "Channel Graveyard",
        "parent": "",
        "content": "You could halt for block validity failures /differences between clients rather than attestation data as the latter could be different for many reasons",
        "created_at": "2025-02-27T10:16:14.502000+00:00",
        "attachments": null
    },
    {
        "author": "jgm",
        "category": "Channel Graveyard",
        "parent": "",
        "content": "I don't think that information is exposed by the beacon node, is it?  That could be an interesting event to add to the beacon API.",
        "created_at": "2025-02-27T10:17:49.939000+00:00",
        "attachments": null
    },
    {
        "author": "nishant0",
        "category": "Channel Graveyard",
        "parent": "",
        "content": "Not yet afaik, but I think its worth bringing up. Observing invalid blocks has many useful purposes",
        "created_at": "2025-02-27T10:18:33.279000+00:00",
        "attachments": null
    },
    {
        "author": "jgm",
        "category": "Channel Graveyard",
        "parent": "",
        "content": "Does prysm keep an invalid block around?  If an event was sent out on the events stream for a bad block, could it then be pulled from the beacon node (by root, obviously) or would it have been discarded?",
        "created_at": "2025-02-27T10:19:57.020000+00:00",
        "attachments": null
    },
    {
        "author": "nishant0",
        "category": "Channel Graveyard",
        "parent": "",
        "content": "If you run prysm with `--save-invalid-block-temp` it will save all invalid blocks in the temp directory. However this won't be available via the prysm db,",
        "created_at": "2025-02-27T10:23:19.529000+00:00",
        "attachments": null
    },
    {
        "author": "ajsutton",
        "category": "Channel Graveyard",
        "parent": "",
        "content": "Pausing justification for a period after a hard for is a very interesting idea. It not only gives validators a chance to see the chain stabilise but also means the “safe” and “finalized” heads don’t advance for a period which is a pretty useful policy to naturally push users to wait longer before trusting the state of the chain for things like withdrawals. Exchanges often pause or delay withdrawals anyway but this would put it more in protocol and provide that safety in more situations.",
        "created_at": "2025-02-27T10:57:01.061000+00:00",
        "attachments": null
    },
    {
        "author": "m.kalinin",
        "category": "Channel Graveyard",
        "parent": "",
        "content": "Alternatively, we may increase justification threshold for a number of epochs after HF to ensure that almost all nodes converge on a single chain",
        "created_at": "2025-02-27T11:52:44.965000+00:00",
        "attachments": null
    },
    {
        "author": "serenita_io",
        "category": "Channel Graveyard",
        "parent": "",
        "content": "Sure. But this kind of situation (4-client shared bug) could in theory also happen a month after a hard fork so I don't think it really *solves* it? It only provides some more certainty around hard forks (still good).",
        "created_at": "2025-02-27T12:42:04.254000+00:00",
        "attachments": null
    },
    {
        "author": "kassandra.eth",
        "category": "Channel Graveyard",
        "parent": "",
        "content": "i know there is a lot going on, but just want to mention i have roughly 100 validator deposits i could jeet into fresh holesky validators if that's helpful in any way (i am familiar with running mainnet nodes particularly geth/reth and lighthouse/prysm)",
        "created_at": "2025-02-27T13:25:17.700000+00:00",
        "attachments": null
    },
    {
        "author": "calvix.",
        "category": "Channel Graveyard",
        "parent": "",
        "content": "Is it necessery to have a special EL/CL images for `devnet7` ?",
        "created_at": "2025-02-27T13:58:45.365000+00:00",
        "attachments": null
    },
    {
        "author": "daniellehrner",
        "category": "Channel Graveyard",
        "parent": "",
        "content": "Every little helps at the moment",
        "created_at": "2025-02-27T14:02:52.929000+00:00",
        "attachments": null
    },
    {
        "author": "protoplanetary",
        "category": "Channel Graveyard",
        "parent": "",
        "content": "I'm surprised no one is bringing up the idea of an amnesty at ACDE, as a possible way forward. Testnets are only valuable inasmuch as they simulate reality, and I guarantee we would need to be having that discussion if this happened on mainnet. Fixing Holesky without thinking about any of the game theory of Eth having real value would mean we're kind of wasting this opportunity to test a supermajority bug, IMO",
        "created_at": "2025-02-27T14:37:20.525000+00:00",
        "attachments": null
    },
    {
        "author": "catwith1hat",
        "category": "Channel Graveyard",
        "parent": "",
        "content": "There is nothing extreme about not wanting to lose money. We don't have a socially agreed upon playbook for how a similar mainnet incident would play out. A mass slashing event would be terrible, both financially and reputation wise, but all discussions for a bail out by social consensus is usually quickly surpressed here (I think that's a mistake. Social consensus is the foundation of all consensus).\n\nIf you want my personal answer, I will probably diversify my node setup and tell my Vouch instances to stop attesting in case there is a single dissenter in my node set. That's the most rational stance. I prefer to lose a few attestations till I can get to my terminal before I risk a slashing event.\n\nThe above being the most rational behavior also implies that attestation from professional operators stop in case there is a bug in just a single client. Adding clients in fact reduced reliability because you stop if a single one disagrees, as you have no way of telling which one is the right one. This btw casts doubts on the \"multi-client blockchains are more resilient\" story that is Ethereum lore.\n\n(I will also stop my validators when we transition through the mainnet pectra fork. Absolutely not worth the risk.)",
        "created_at": "2025-02-27T15:03:14.984000+00:00",
        "attachments": null
    },
    {
        "author": "catwith1hat",
        "category": "Channel Graveyard",
        "parent": "",
        "content": "I think that we should test regenesis (practical amnesty, right?) and do it in a way where the first phase of the new chain is held together by a temporarily smaller validator set with keys from ethpandaops, client teams, etc. And after a month or so, switch to the old prefork public validator set. This gives node operators time to upgrade till we get releases out, but also allows us to get the chain going quickly. Because if we want to start with the original validator set, we will be asked to delay the restart for days or weeks, because validators aren't ready, which would just kill Ethereum as a brand. (Fees earned by the small bootstrap validator during the first phase are burned afterwards)\n\nEDIT: Just one more thought. Social consensus extends beyond ACD. If big staking operators get together (Coinbase, Kraken, ..) and decide that amnesty is the way forward, they hire a team,  fork a few CL repos, and label the output \"Ethereum\". What a small group of tech nerds thinks will be irrelevant if exchanges jump on that fork. That failed for Bitcoin with Bitcoin cash, but mass-slashing kinda ups the stakes.",
        "created_at": "2025-02-27T15:09:00.569000+00:00",
        "attachments": null
    }
]