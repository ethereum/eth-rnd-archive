[
    {
        "author": "funnygiulio",
        "category": "Channel Graveyard",
        "parent": "",
        "content": "Am i wrong or did the beacon-chain take 1 day to fully sync?",
        "created_at": "2021-10-25T18:02:42.474000+00:00",
        "attachments": null
    },
    {
        "author": "funnygiulio",
        "category": "Channel Graveyard",
        "parent": "",
        "content": "if that is the case then i think that something is very wrong with it since it is a 8 months old empty chain, you guys may wanna consider change the data model for the beacon-chain or put some requirements for whoever write different beacon chain client",
        "created_at": "2021-10-25T22:02:16.486000+00:00",
        "attachments": null
    },
    {
        "author": "funnygiulio",
        "category": "Channel Graveyard",
        "parent": "",
        "content": "for example, Erigon (Execution Layer) may even end up surpassing the beacon chain which would be ridiculous (i am not boasting because erigon is fast, i believe this is a very big limitation for ANY client)",
        "created_at": "2021-10-25T22:03:17.651000+00:00",
        "attachments": null
    },
    {
        "author": "bridge-bot",
        "category": "Channel Graveyard",
        "parent": "",
        "content": "\u003cdannyryan\u003e The beacon state is small and relatively bound. It is something like 50MB\nSo getting it out of band is incredibly easy\nAlso, weak subjectivity requires having a recent piece of the network  to safely join (e.g. finalzied hash or just the finalzied, small state)\nThus historic block sync requirement is not nearly the same for the beacon chain as it is for the evm state in this paradigm",
        "created_at": "2021-10-25T22:06:38.855000+00:00",
        "attachments": null
    },
    {
        "author": "bridge-bot",
        "category": "Channel Graveyard",
        "parent": "",
        "content": "\u003cdannyryan\u003e Secondly, its not the data model \nAs noted above, the state is tiny",
        "created_at": "2021-10-25T22:06:53.732000+00:00",
        "attachments": null
    },
    {
        "author": "bridge-bot",
        "category": "Channel Graveyard",
        "parent": "",
        "content": "\u003cdannyryan\u003e Its primarily bls signature processing and merklization that is the bottleneck on historic sync",
        "created_at": "2021-10-25T22:07:22.019000+00:00",
        "attachments": null
    },
    {
        "author": "bridge-bot",
        "category": "Channel Graveyard",
        "parent": "",
        "content": "\u003cdannyryan\u003e Historic block sync can likely be further optimized but is not a critical target for the beacon chain. Again because of the different security model (needing a recent state to start) and the state being relatively tiny so easy to get",
        "created_at": "2021-10-25T22:08:17.978000+00:00",
        "attachments": null
    },
    {
        "author": "bridge-bot",
        "category": "Channel Graveyard",
        "parent": "",
        "content": "\u003cdannyryan\u003e Im not certain how long it takes to block sync the various clients from genesis. For reference and curiosity, which client did you use that took 1 day?",
        "created_at": "2021-10-25T22:09:00.203000+00:00",
        "attachments": null
    },
    {
        "author": "funnygiulio",
        "category": "Channel Graveyard",
        "parent": "",
        "content": "prysm",
        "created_at": "2021-10-25T22:55:18.076000+00:00",
        "attachments": null
    },
    {
        "author": "funnygiulio",
        "category": "Channel Graveyard",
        "parent": "",
        "content": "also the beacon chain seems to take 37.5 Gigabytes not 50 Megabytes, which could be a problem if the chain actually gets used (after all it is empty)",
        "created_at": "2021-10-25T23:00:44.155000+00:00",
        "attachments": null
    },
    {
        "author": "funnygiulio",
        "category": "Channel Graveyard",
        "parent": "",
        "content": "i ran du on beaconchaindata in .eth2 to find this number",
        "created_at": "2021-10-25T23:01:41.885000+00:00",
        "attachments": null
    },
    {
        "author": "funnygiulio",
        "category": "Channel Graveyard",
        "parent": "",
        "content": "this all on prysm anyway",
        "created_at": "2021-10-25T23:05:38.220000+00:00",
        "attachments": null
    },
    {
        "author": "bridge-bot",
        "category": "Channel Graveyard",
        "parent": "",
        "content": "\u003cdannyryan\u003e the active stat is ~50MB and bound.\n1. prysm (any other clients) do not utilize simple diff backed historic states for finalized states. Considering most of the state is the vlaidator set and changes *extremely* little epoch-to-epoch, the theoretical size of a freezer storage DB, even when storing a state per epoch, can be very small\n2. due to technical and security requirements of th beacon chain, clients can and should in most cases aggressively prune past the weak subjectivity period (~4 months)\n3. (even beyond just storing diffs on the state in the freezer db) clients can be configured to have a space/time trade-off as described here — https://lighthouse-book.sigmaprime.io/advanced_database.html — note the numbers on this page do not store state diffs and instead store a full state at whatever frequency is requested",
        "created_at": "2021-10-25T23:06:52.212000+00:00",
        "attachments": null
    },
    {
        "author": "bridge-bot",
        "category": "Channel Graveyard",
        "parent": "",
        "content": "\u003cdannyryan\u003e the prysm numbers are at least directionally representative. Each client does have different trade-offs as they stand today",
        "created_at": "2021-10-25T23:07:12.138000+00:00",
        "attachments": null
    },
    {
        "author": "funnygiulio",
        "category": "Channel Graveyard",
        "parent": "",
        "content": "ok",
        "created_at": "2021-10-25T23:12:49.833000+00:00",
        "attachments": null
    },
    {
        "author": "bridge-bot",
        "category": "Channel Graveyard",
        "parent": "",
        "content": "\u003cdannyryan\u003e sorry, don’t mean to pushback so hard. there are very good optimizations to get done here, but due to the different design requirements of the beacon chain layer, the way to contextualize and prioritize it is different than the EVM, it’s execution, and state",
        "created_at": "2021-10-25T23:14:42.968000+00:00",
        "attachments": null
    },
    {
        "author": "funnygiulio",
        "category": "Channel Graveyard",
        "parent": "",
        "content": "i just think that the idea that execution is faster than consensus layer to such an extent makes no sense. it almost sounds like a downgrade and also it logically makes no sense. just my 2 cents, you might be right.",
        "created_at": "2021-10-25T23:17:27.406000+00:00",
        "attachments": null
    },
    {
        "author": "ajsutton",
        "category": "Channel Graveyard",
        "parent": "",
        "content": "For context, Teku can sync the beacon chain using checkpoint sync in under a minute (as can Lodestar and Lighthouse) - Prysm is just yet to implement that.  And in terms of total storage size, Teku now has three choices depending on what information you need.\n* PRUNE mode - if you don't need historic state access (e.g when running a validator or post-merge sending transactions): about 20Gb total disk usage\n* ARCHIVE mode with state snapshots - provides access to historic state access but can be slow. With the default of storing a state snapshot every 2000 slots that uses about 37Gb of disk\n* ARCHIVE mode with tree based state storage - provides consistently fast access to any historic state by storing just the diff between states after every block.  That uses 190Gb of disk.\n\nNearly everyone should run with PRUNE mode because finalized states generally aren't required.  If you occasionally need to access historic state data ARCHIVE with snapshots is a good bet.  If you're Infura or are doing heavy historical analysis ARCHIVE with tree based storage is what you want.  I personally think storing all content from every state in under 200Gb is pretty good and there is quite likely to be further space optimisations that could be done there.",
        "created_at": "2021-10-25T23:40:48.332000+00:00",
        "attachments": null
    }
]