[
    {
        "author": "butta",
        "category": "general",
        "parent": "",
        "content": "Would a third party service that runs all clients and returns the slot/participation rate for each client would be helpful?\nClients could have a failsafe built into the client, and it stops signing attestations if the given slot/participation rate does not match your local nodes data.\n\nThat would at least save us from finalizing a faulty chain?",
        "created_at": "2022-02-06T10:09:36.583000+00:00",
        "attachments": null
    },
    {
        "author": "sky.cactus",
        "category": "general",
        "parent": "",
        "content": "We wouldn't want everyone using one such service, because that server would prevent finality when it was offline.",
        "created_at": "2022-02-06T10:14:28.448000+00:00",
        "attachments": null
    },
    {
        "author": "sky.cactus",
        "category": "general",
        "parent": "",
        "content": "Network latency means we can't have it be an exact match, but we can do fuzzy matching.",
        "created_at": "2022-02-06T10:15:29.227000+00:00",
        "attachments": null
    },
    {
        "author": "yorickdowne",
        "category": "general",
        "parent": "",
        "content": "Is there an MVP that can be built without a ton of effort? I am already running three of the five on main and Prater, not hard to add the other two. Plus an API layer to return these data … if some idea of what that should look like can be put forth, then it’s probably not hard to have something in flask just so there’s a thing to look at and observe with latency and how it behaves when queried from around the world. Would need to limit access with a key so it doesn’t get hugged to death while it’s a PoC",
        "created_at": "2022-02-06T10:20:41.848000+00:00",
        "attachments": null
    },
    {
        "author": "yorickdowne",
        "category": "general",
        "parent": "",
        "content": "High level logic wise, it could be kept narrowly to the thing we are worried about. “If I am about to finalize a block and there isn’t a simple majority of client implementations that agree on this chain view, then don’t finalize it”",
        "created_at": "2022-02-06T10:32:56.540000+00:00",
        "attachments": null
    },
    {
        "author": "yorickdowne",
        "category": "general",
        "parent": "",
        "content": "“This chain view” needs to be fuzzy as you say \u003c@!301186049323958275\u003e , there’s thinking to be done there that I am not well equipped to do.",
        "created_at": "2022-02-06T10:33:51.850000+00:00",
        "attachments": null
    },
    {
        "author": "yorickdowne",
        "category": "general",
        "parent": "",
        "content": "What I am after is that a client that is a) in a position to finalize a block and b) finds that there isn’t a simple majority of client implementations that agree .. so say 3 of 5 or 4 of 6, etc … then out of an abundance of caution it doesn’t finalize until agreement has been reached",
        "created_at": "2022-02-06T10:36:06.470000+00:00",
        "attachments": null
    },
    {
        "author": "yorickdowne",
        "category": "general",
        "parent": "",
        "content": "This could be minimally disruptive while staying away from actual protocol changes",
        "created_at": "2022-02-06T10:37:15.188000+00:00",
        "attachments": null
    },
    {
        "author": "yorickdowne",
        "category": "general",
        "parent": "",
        "content": "If it’s better to say “then out of an abundance of caution it stops processing duties altogether until agreement has been reached”, that’d work too. And it’d be an opt-in behavior.",
        "created_at": "2022-02-06T10:38:03.241000+00:00",
        "attachments": null
    },
    {
        "author": "yorickdowne",
        "category": "general",
        "parent": "",
        "content": "The same way mining pools now check block height. They don’t have to on a protocol level, they do because it helps them to do that",
        "created_at": "2022-02-06T10:38:38.805000+00:00",
        "attachments": null
    },
    {
        "author": "yorickdowne",
        "category": "general",
        "parent": "",
        "content": "If we ever get to the Promised Land with no supermajority clients on CL or EL, then maybe there’s less incentive to opt in, and that’d be fine at that point.",
        "created_at": "2022-02-06T10:44:51.152000+00:00",
        "attachments": null
    },
    {
        "author": "jgm",
        "category": "general",
        "parent": "",
        "content": "Speaking as someone who runs a lot of beacon nodes, you have to be careful about this type of thing potentially causing issues.  Take a simple example of a block being proposed, there are multiple places where even if they all agree eventually it can slow things down:\n  - generation of a 'head' event when a new block is received\n  - generation of a suitable beacon block proposal\n  - validation of a signed proposed beacon block\n\nYou would need to be quite careful to know exactly what you are waiting for, and for how long to wait in the case of no consensus (and different types of no consensus), to have enough information to decide to progress or not.  You would also have to think hard about exactly what situation you are trying to avoid to be sure you were helping rather than hindering your validator (and, ultimately, the chain).",
        "created_at": "2022-02-06T15:36:47.823000+00:00",
        "attachments": null
    },
    {
        "author": "butta",
        "category": "general",
        "parent": "",
        "content": "Yeah it would definitely need more thought but having such feature would also open the door for someone to spin up multiple nodes themselves and not necessarily rely on 3rd party nodes.",
        "created_at": "2022-02-06T15:43:53.734000+00:00",
        "attachments": null
    },
    {
        "author": "tokey1475",
        "category": "general",
        "parent": "",
        "content": "I agree that this is a concern.  I previously brought up delaying finality at the consensus level if \u003e2/3 but less than some upper bound of validators agree, but unfortunately it is probably too late to consider that kind of change.  It feels like there is lack of planning on what would occur if a bug (be it a prysm bug or a kintugi like bug that happened to affect a majority of validators) caused finality of an \"invalid\" chain.   The lack of protection for this sort of scenario at the protocol level along with a lack of clarity on how a 'non-malicious'  split would be handled, may drive validators to use a solution like this (which has obvious flaws like centralization,etc...).  As a validator I would certainly consider using this and risking some downtime vs. possible finalizing a bad chain and getting leaked to exit",
        "created_at": "2022-02-06T17:11:32.960000+00:00",
        "attachments": null
    },
    {
        "author": "bridge-bot",
        "category": "general",
        "parent": "",
        "content": "\u003cdankrad\u003e the correct mitigation is that people should run clients other than prysm",
        "created_at": "2022-02-06T17:30:47.573000+00:00",
        "attachments": null
    },
    {
        "author": "pietjepuk",
        "category": "general",
        "parent": "",
        "content": "In the current situation, sure. But what about the hypothetical case of a 2 out of 5 (client) failure, or maybe even 4 out of 5? Even if Prysm is less than 33% market share, early detection of consensus bugs a la forkmon can be helpful. \nI'd personally like some client teams to weigh in about what they think should happen if an epoch/block is finalized that does not follow the specifications (whether EL or CL).",
        "created_at": "2022-02-06T17:42:24.236000+00:00",
        "attachments": null
    },
    {
        "author": "bridge-bot",
        "category": "general",
        "parent": "",
        "content": "\u003cdannyryan\u003e Client failures are bad but the protocol knows nothing about clients. Just that there is a protocol\nAttempting to bake multi-client mitigations into the protocol will almost certainly make things more centralized (e.g. whitelist of clients) and more brittle (e.g. client A fails critically, people swap to client B, how does protocol know client A is no longer around) and less resilient/nimble\nAlso what is a client? Each release, a client might disagree with the prior. So each release begins to look like a different client in extreme scenarios. Or you could imagine malicious inputs splitting a client of same type/release!\nFailures are bad and certain types can be made less likely with different client distributions but defining these things in protocol is not a practical path, imo",
        "created_at": "2022-02-06T17:54:48.878000+00:00",
        "attachments": null
    },
    {
        "author": "bridge-bot",
        "category": "general",
        "parent": "",
        "content": "\u003cvbuterin\u003e I think I agree",
        "created_at": "2022-02-06T18:07:08.201000+00:00",
        "attachments": null
    },
    {
        "author": "bridge-bot",
        "category": "general",
        "parent": "",
        "content": "\u003cvbuterin\u003e One thing we could consider is increasing the finality threshold from 67% to 75%, making it even less likely that a client split leads to immediate finalization",
        "created_at": "2022-02-06T18:07:33.880000+00:00",
        "attachments": null
    },
    {
        "author": "bridge-bot",
        "category": "general",
        "parent": "",
        "content": "\u003cvbuterin\u003e So for any big disagreement there is time for human intervention",
        "created_at": "2022-02-06T18:07:46.712000+00:00",
        "attachments": null
    },
    {
        "author": "tokey1475",
        "category": "general",
        "parent": "",
        "content": "I think something like this is the right direction.  Until we have battle tested the merge (and ideally have more client diversity), it makes sense to prioritize protection against finalizing the wrong chain over minimizing finalization time",
        "created_at": "2022-02-06T18:09:49.960000+00:00",
        "attachments": null
    },
    {
        "author": "potuz",
        "category": "general",
        "parent": "",
        "content": "\u003c@!340345049063882753\u003e \u003c@!361447803194441738\u003e The following question arose when discussing our implementation of optimistic sync with \u003c@!363800010518822915\u003e. Can the following situation even be possible? The question is about having a fork with different terminal pow blocks each having a merge block that hasn't been finalized. But one branch having a justified point before the merge block and the other branch having its justified point after the merge block. Something like this\n```\nF -- A -- B -- C -- J1 -- D -- E -- G -- I\n                \\\n                  -- K -- L -- J2 -- M -- H\n```\nHere F is final, J1 and J2 are justified. H is the current fork choice head. And we have `is_execution_block(J1) = false`  and `is_execution_block(J2) = true`. Suppose we get the block labelled I and suppose moreover that `I.slot + SAFE_SLOTS_TO_IMPORT_OPTIMISTICALLY \u003e current_slot`  so that it is not a deep block.  Then the current optimistic sync spec would make\n`is_optimistic_candidate_block(I) = true`  but because `J2` is execution enabled. This seems pretty odd, shouldn't we  use the last justified ancestor of `I`  instead of the current justified checkpoint as defined in this line? :\n```\n    justified_root = opt_store.block_states[opt_store.head_block_root].current_justified_checkpoint.root\n```",
        "created_at": "2022-02-06T22:09:38.070000+00:00",
        "attachments": null
    },
    {
        "author": "ajsutton",
        "category": "general",
        "parent": "",
        "content": "For H to have justified J2, 2/3rds of the validators must have attested to J2 and thus must have received the terminal block it's built on, so it's safe to assume that the terminal block is available on the network and you can safely optimistically import.  H should wind up being the canonical chain (and I isn't a viable head because it doesn't descend from the justified checkpoint J2).",
        "created_at": "2022-02-06T22:19:26.287000+00:00",
        "attachments": null
    },
    {
        "author": "ajsutton",
        "category": "general",
        "parent": "",
        "content": "That's on the assumption that J2 is in a later epoch than J1.  If they're in the same epoch a lot of people are getting slashed.",
        "created_at": "2022-02-06T22:19:55.871000+00:00",
        "attachments": null
    },
    {
        "author": "potuz",
        "category": "general",
        "parent": "",
        "content": "I am asking about I not H",
        "created_at": "2022-02-06T22:21:00.814000+00:00",
        "attachments": null
    },
    {
        "author": "potuz",
        "category": "general",
        "parent": "",
        "content": "Oh sorry I misread",
        "created_at": "2022-02-06T22:21:37.301000+00:00",
        "attachments": null
    },
    {
        "author": "potuz",
        "category": "general",
        "parent": "",
        "content": "I don't understand why can't there be a reorg to I",
        "created_at": "2022-02-06T22:21:54.845000+00:00",
        "attachments": null
    },
    {
        "author": "potuz",
        "category": "general",
        "parent": "",
        "content": "Ah right, I drew the lines the other way around, the epochs should have been crossed",
        "created_at": "2022-02-06T22:22:32.735000+00:00",
        "attachments": null
    },
    {
        "author": "potuz",
        "category": "general",
        "parent": "",
        "content": "Correct, if epoch of J2 \u003e than epoch of J1 I don't think there can be a reorg from H to I, but is the situation with the other order of the epochs impossible?",
        "created_at": "2022-02-06T22:23:32.075000+00:00",
        "attachments": null
    },
    {
        "author": "potuz",
        "category": "general",
        "parent": "",
        "content": "namely I could have I being my head, and then receive H, the current spec would tell me that I can't optimistically sync it, while I should be able since J2 is an execution block.",
        "created_at": "2022-02-06T22:25:24.314000+00:00",
        "attachments": null
    },
    {
        "author": "potuz",
        "category": "general",
        "parent": "",
        "content": "is the same kind of concern",
        "created_at": "2022-02-06T22:25:31.462000+00:00",
        "attachments": null
    },
    {
        "author": "potuz",
        "category": "general",
        "parent": "",
        "content": "Ah no, right, the current checkpoint will in both cases be J2 if it's the latest epoch.",
        "created_at": "2022-02-06T22:27:26.082000+00:00",
        "attachments": null
    },
    {
        "author": "ajsutton",
        "category": "general",
        "parent": "",
        "content": "I think the problem is that you can't establish that H justified at J2 until *after* you've optimistically imported it. And when you do discover J2 you'd also update the justified checkpoint in your node's Store to that but that's not safe because you might have just locked yourself into a terminal block that isn't actually availab.e",
        "created_at": "2022-02-06T22:28:28.407000+00:00",
        "attachments": null
    }
]