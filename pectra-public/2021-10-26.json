[
    {
        "author": "funnygiulio",
        "category": "general",
        "parent": "",
        "content": "I am not talking about pruned databases, usually prune is used by miners and in the case of ETH2 validators, but they dont have any other use and they are extremely limited. my real interest is in Archive or partially archived node, because those are the important one for the functioning of the ecosystem",
        "created_at": "2021-10-26T00:06:08.471000+00:00",
        "attachments": null
    },
    {
        "author": "funnygiulio",
        "category": "general",
        "parent": "",
        "content": "how sustainable is the beacon chain if an empty chain can go up to 190 GB after only 8 months",
        "created_at": "2021-10-26T00:07:15.614000+00:00",
        "attachments": null
    },
    {
        "author": "ajsutton",
        "category": "general",
        "parent": "",
        "content": "I'm not sure why you think an archive or partially archived node is required.  A pruned node still holds all old blocks, just not old states.",
        "created_at": "2021-10-26T00:14:03.049000+00:00",
        "attachments": null
    },
    {
        "author": "ajsutton",
        "category": "general",
        "parent": "",
        "content": "Literally every node on the beacon chain could be a pruned node and it would function perfectly.  You can't access the finalized states via libp2p so it's impossible to know if a peer your connected to is an archive node or a pruned node.",
        "created_at": "2021-10-26T00:14:56.037000+00:00",
        "attachments": null
    },
    {
        "author": "potuz",
        "category": "general",
        "parent": "",
        "content": "Indeed, I don't even understand why clients ship with an embedded genesis state instead of a recent finalized state and backfill, the level of trust is the same",
        "created_at": "2021-10-26T00:48:22.947000+00:00",
        "attachments": null
    },
    {
        "author": "ajsutton",
        "category": "general",
        "parent": "",
        "content": "Because it's a pain for us to keep updating mostly (and we'd have to ship genesis as well for people who want archive sync).  It is definitely something I've considered for teku though.",
        "created_at": "2021-10-26T00:58:20.580000+00:00",
        "attachments": null
    },
    {
        "author": "bridge-bot",
        "category": "general",
        "parent": "",
        "content": "\u003cdannyryan\u003e \u003e because those are the important one for the functioning of the ecosystem\nCan you expound upon this?",
        "created_at": "2021-10-26T00:59:23.430000+00:00",
        "attachments": null
    },
    {
        "author": "funnygiulio",
        "category": "general",
        "parent": "",
        "content": "ok, i get why most people would not need an Archive Beacon chain now on second thought. my main concern at this point would still be db size(20 GB) which seems still pretty high for an empty chains still. but i am already more optimist about this than before",
        "created_at": "2021-10-26T09:13:36.034000+00:00",
        "attachments": null
    },
    {
        "author": "ajsutton",
        "category": "general",
        "parent": "",
        "content": "The chain isn't empty though. And currently we're storing all blocks back to genesis since not all clients support checkpoint sync (and we don't have other places to ensure the blocks remain available).  In the future we'd stop storing those blocks and the consensus disk storage becomes almost constant size (grows a bit as the number of validators increases but not significantly)",
        "created_at": "2021-10-26T09:14:58.890000+00:00",
        "attachments": null
    },
    {
        "author": "funnygiulio",
        "category": "general",
        "parent": "",
        "content": "If that is the case then all my doubts are cleared then",
        "created_at": "2021-10-26T09:21:07.698000+00:00",
        "attachments": null
    },
    {
        "author": "sauliusgrigaitis",
        "category": "general",
        "parent": "",
        "content": "It is empty from the Execution Layer perspective. However, it's full of data from Consensus Layer perspective - it contains validators votes etc. For example, if you want to check how your validators performed in each epoch from Genesis, then those 10s of GBs become usable as it contains that data. However, if you don't need such historical information then the needed disk space is very low.",
        "created_at": "2021-10-26T09:52:29.082000+00:00",
        "attachments": null
    },
    {
        "author": "sauliusgrigaitis",
        "category": "general",
        "parent": "",
        "content": "There is a slightly higher trust in this case as it's easier to mess often changing latest burnt-in state compared to the genesis state that never changes, however, the trust needed is still incomparable to the random state downloaded from a trusted source. IMO that's actually the way sync should be implemented after withdrawals are implemented - relatively slow withdrawal rate so that regular client releases contain safe burned-in states for long enough, then simply sync from the burnt-in state to the head. The current checkpoint sync proposal just moves responsibility to the user.",
        "created_at": "2021-10-26T10:38:24.628000+00:00",
        "attachments": null
    },
    {
        "author": "ajsutton",
        "category": "general",
        "parent": "",
        "content": "The checkpoint sync approach gets you *way* closer to in-sync as a starting point than a version embedded in the client which would regularly be at least a month old. I'm not sure what the weak subjectivity period is now given the number of validators but staying within it would require very regular releases which is a burden we probably shouldn't be putting on the client dev teams.\n\nIn the past there's been a lot of pushback from client teams about being made to be the arbiter of the canonical chain which I think is quite reasonable as well. The big advantage of the checkpoint sync approach is that you can have a variety of different providers and users can choose which they want to trust to decide the canonical chain.",
        "created_at": "2021-10-26T10:44:45.146000+00:00",
        "attachments": null
    },
    {
        "author": "sauliusgrigaitis",
        "category": "general",
        "parent": "",
        "content": "If the withdrawal rate is slow enough and syncing is optimized, then even a few months old burnt-in state is not that big deal.\n\nClients already ship Genesis, so client teams are already arbiters. \n \n_The big advantage of the checkpoint sync approach is that you can have a variety of different providers and users can choose which they want to trust to decide the canonical chain._ - I'm not sure that it's a big advantage for users. Users just want the canonical chain, not the headache to choose another trusted provider. Some of them may even not understand that the trusted provider may serve a different \"canonical chain\".",
        "created_at": "2021-10-26T11:53:59.509000+00:00",
        "attachments": null
    }
]