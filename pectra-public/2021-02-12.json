[
    {
        "author": "m.kalinin",
        "category": "general",
        "parent": "",
        "content": "It makes a lot of sense to do possible pre-computations without big impact on either consensus or users. Say, we want shards crosslinks to be utilized by execution as fast as it's possible, but if block is pre-computed then corresponding transactions may be delayed by yet another slot. Though, I am inclined to retaining the pending block after the merge. As it's been said, there are trade-offs. And I guess we'll get more understanding from testnets.",
        "created_at": "2021-02-12T08:40:32.168000+00:00",
        "attachments": null
    },
    {
        "author": "jgm",
        "category": "general",
        "parent": "",
        "content": "There is always going to be the situation where users run \"on the edge\".  If you reduce the requirements, some users will run on lower-powered hardware so you will end up with similar issues.\n\nNot to say that optimisation shouldn't be carried out.  Conceptually, pre-compute in the \"dead time\", for example after aggregates have been generated, is a great idea and could have significant impacts.  And there can be benefits to having higher-end hardware, for example if a block is computed and re-computed each time a new aggregate arrives, with a \"hard\" (i.e. spec-defined) deadline of 2s after slot start to broadcast what you have, then the user with the faster hardware is likely to include more attestations.\n\nThe combination of the hard deadline of 2s after slot start to send a block, along with the ability to pre-compute an 'empty' block which can then be progressively filled, could be a decent way to balance out the performance differences between hardware.",
        "created_at": "2021-02-12T08:51:15.711000+00:00",
        "attachments": null
    },
    {
        "author": "m.kalinin",
        "category": "general",
        "parent": "",
        "content": "IMHO, there should be some level of validator's hardware that allows for the network to progress well and stay healthy. If a portion of nodes are running on a faster hardware it should not affect the others but if a big chunk of network is running on a hardware that is not capable of processing blocks and attestations in time then how it can be balanced out?",
        "created_at": "2021-02-12T09:16:05.727000+00:00",
        "attachments": null
    },
    {
        "author": "jgm",
        "category": "general",
        "parent": "",
        "content": "It probably comes down to incentives: better hardware results in higher rewards (up to a point, of course).\n\nA good example at current is that people are turning off their geth instances next to their beacon nodes because of its resource utilisation is not balanced with the rewards for providing the correct (and independent) ETH1 data in a proposed block.",
        "created_at": "2021-02-12T09:30:16.632000+00:00",
        "attachments": null
    },
    {
        "author": "jgm",
        "category": "general",
        "parent": "",
        "content": "One thing I was thinking about was the ability for a single proposer to generate multiple ETH1 blocks in their slot if capable.  They would still only obtain a single block reward regardless, but could obtain multiple sets of transaction rewards.  This would suitably reward faster hardware, but I admit I haven't thought through the impact on the rest of the network if a supercomputer managed to generate 1,000 blocks in a single slot.  Perhaps some sort of upper bound on the number of blocks, maybe.",
        "created_at": "2021-02-12T09:34:54.723000+00:00",
        "attachments": null
    },
    {
        "author": "m.kalinin",
        "category": "general",
        "parent": "",
        "content": "It could be a single block instead of multiple ones. Jacek was demanding mechanism that allows for \"pick a block and go\" strategy. Eth1-engine may constantly (e.g. at 100ms interval) send an updated batch of transactions to eth2-client and the latter decides when it's ready to go and uses the latest batch it received. In general, this is what geth is doing now having pending block. Potential problem here is very similar to what you have just described, what if gas limit is not well adjusted with the processing time (by an attack or not), in this case if pending block starts to being prepared e.g. at the middle of a slot (upon inserting the previous one) it has a chance to become huge enough to take too much time to process it and will be orphaned. We need a strict balance between processing time and gas limit (i.e. gas limit should not allow for creating a block that takes too much time to become an orphan) or some clever mechanism to compute pending block. Impact of 1559 on the block size should also be taken in account",
        "created_at": "2021-02-12T09:53:53.121000+00:00",
        "attachments": null
    },
    {
        "author": "jgm",
        "category": "general",
        "parent": "",
        "content": "Can we not go with a deadline-based approach and let the system be adaptive?  So something like:\n\n  - once the current ETH1 block has arrived, the next ETH1 block is prepared\n  - the ETH1 block in preparation starts empty, ETH1 engine starts to fill it with transactions\n    - this is an on-going process, rebuilding the tx list each time it receives a new tx that is better suited for inclusion\n  - at the appointed time the ETH2 client asks for the current best block and goes with it, whatever it is\n\nA low-powered ETH1 engine may just grab a few txs with little processing involved, a higher-powered ETH1 engine could keep readjusting the block to be optimum",
        "created_at": "2021-02-12T10:11:46.870000+00:00",
        "attachments": null
    },
    {
        "author": "m.kalinin",
        "category": "general",
        "parent": "",
        "content": "Yes, we can. If, in the context of the beacon chain time restrictions, the gas limit is more of a constraint than the processing time for the most part of eth1-engines in the network then we're safe. Potentially there could be the cases in which this condition is not held.",
        "created_at": "2021-02-12T10:24:42.466000+00:00",
        "attachments": null
    }
]