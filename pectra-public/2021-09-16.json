[
    {
        "author": "ajsutton",
        "category": "Channel Graveyard",
        "parent": "",
        "content": "\u003c@!425572898787426305\u003e Just checking something with the initialisation of the transition store (https://github.com/ethereum/consensus-specs/blob/dev/specs/merge/fork.md#initializing-transition-store).  It seems that the block that triggers initialisation of the transition store may differ for different nodes because it's whichever block first causes the node to apply the slot transition into the first slot of `MERGE_FORK_EPOCH`. If there are multiple forks at that point, different nodes could be processing different blocks when they first initialise the transition store.\n\nSo long as those forks still agreed on the same Eth1Data I think it all works out, but if they are different for some reason then we'll have a permanent chain split based on which block nodes happen to process first.  Potentially that could be caused by something as simple as the last block before `MERGE_FORK_EPOCH` being orphaned if it was that last block in the eth1 voting period that reached the 50% mark to vote in a new Eth1Data.\n\nMany clients pre-process the epoch transition as well to be ready to import the first block of the next epoch quickly which would also trigger initializing the transition store even if there's never a block built on top of that last block.",
        "created_at": "2021-09-16T01:33:07.472000+00:00",
        "attachments": null
    },
    {
        "author": "ajsutton",
        "category": "Channel Graveyard",
        "parent": "",
        "content": "To give a concrete example, lets say MERGE_FORK_EPOCH=100 and thus slot 3199 is the last slot before the merge fork activates and slot 3200 the first one after it.  And also assume epoch 100 is the end of the eth1 voting period (probably not actually true but makes numbers nice and round).\n\nAt slot 3198, the Eth1Data voting process is one vote short of agreeing on the new Eth1Data.\nAt slot 3199, a block is published to a minority of nodes which provides that last required vote.\nNodes that receive block 3199 and pre-process the epoch transition, will now initialize their transition store because they're following a fork where block 3199 is included on the chain.\nThen block 3200 is received which uses block 3198 as its parent and it is accepted as the canonical chain, orphaning block 3199.  Thus the canonical Eth1Data is the old one because 50% was never reached.\n\nAt this point there's no visible consensus split - all nodes will reorg over to block 3200 and use the old Eth1Data as canonical for including deposits etc.  However the minority of nodes which did receive block 3199 will have initialised TransitionStore based on the new Eth1Data, calculating a different terminal total difficulty to the other nodes.  When the earlier of the terminal difficulties is reach the chain split will be revealed as different nodes will expect a different terminal PoW block.",
        "created_at": "2021-09-16T01:40:22.142000+00:00",
        "attachments": null
    },
    {
        "author": "ajsutton",
        "category": "Channel Graveyard",
        "parent": "",
        "content": "Also a node that uses checkpoint sync to a state after the merge fork first activates will calculate a different terminal total difficulty (assuming a new Eth1Data has been agreed by then).  It seems to me that the terminal total difficulty really needs to be in the `BeaconState` so it's actually part of consensus.",
        "created_at": "2021-09-16T01:44:30.399000+00:00",
        "attachments": null
    },
    {
        "author": "ajsutton",
        "category": "Channel Graveyard",
        "parent": "",
        "content": "The first split is pretty unlikely to be an issue because Eth1Data voting is unlikely to be that close, though it becomes more likely the longer the fork is, but the checkpoint sync case is definitely going to be an issue.  We can put out a new release that hard codes the transition total difficulty but then I'm not really sure what the point of dynamically calculating it is.",
        "created_at": "2021-09-16T02:43:02.289000+00:00",
        "attachments": null
    },
    {
        "author": "m.kalinin",
        "category": "Channel Graveyard",
        "parent": "",
        "content": "The idea was to re-initialize the TransitionStore each time the epoch boundary crossed. And the question about the WS sync and TransitionStore as a part of the checkpoint state has been raised some time ago and no decision has been made on it.",
        "created_at": "2021-09-16T02:48:31.387000+00:00",
        "attachments": null
    },
    {
        "author": "ajsutton",
        "category": "Channel Graveyard",
        "parent": "",
        "content": "ah ok, so the spec includes the condition `and the transition store has not already been initialized` which made me think it was the first time.  I suspect that has the same problem and possibly worse though - now if I am scheduled to publish a block after the merge transition, I could just use an old block from before Eth1Data is updated as the parent.  That would cause processSlots to run through the merge transition again and overwrite the correct transition store with one calculated from old Eth1Data even though my block isn't going to be canonical.",
        "created_at": "2021-09-16T02:51:31.051000+00:00",
        "attachments": null
    },
    {
        "author": "ajsutton",
        "category": "Channel Graveyard",
        "parent": "",
        "content": "Hopefully we get finality between the Eth1Data updating and the end of the voting period which prevents that attack but it's not guaranteed.",
        "created_at": "2021-09-16T02:51:57.113000+00:00",
        "attachments": null
    },
    {
        "author": "ajsutton",
        "category": "Channel Graveyard",
        "parent": "",
        "content": "I mean it's probably not the biggest issue to worry about but it feels like things are just devolving to hard coding the terminal difficulty in a release.",
        "created_at": "2021-09-16T02:52:32.009000+00:00",
        "attachments": null
    },
    {
        "author": "m.kalinin",
        "category": "Channel Graveyard",
        "parent": "",
        "content": "Good point! And the corresponding message will notify the execution side about the wrong TTD as well",
        "created_at": "2021-09-16T02:56:45.705000+00:00",
        "attachments": null
    },
    {
        "author": "m.kalinin",
        "category": "Channel Graveyard",
        "parent": "",
        "content": "Are you expecting to make a release after the Merge HF and before the transition? Users will have to updated their nodes shortly",
        "created_at": "2021-09-16T02:57:37.511000+00:00",
        "attachments": null
    },
    {
        "author": "m.kalinin",
        "category": "Channel Graveyard",
        "parent": "",
        "content": "Probably, we should initialize the store when the `MERGE_FORK_EPOCH` boundary gets finalized?",
        "created_at": "2021-09-16T03:00:05.674000+00:00",
        "attachments": null
    },
    {
        "author": "ajsutton",
        "category": "Channel Graveyard",
        "parent": "",
        "content": "For the beacon chain mainnet launch we did set the expectation that users should expect to upgrade in the week between genesis being set and the chain actually launching. That gave the ability to fix any issues if we got the wrong genesis but in the end there weren't any issues. We still put out a release that embedded the calculated genesis anyway.\n\nFor the merge it seems sensible to set the same expectations.  Even if the TTD calculation is guaranteed to agree on all nodes, it only runs once so there's a higher than normal chance of bugs slipping through. So if we know users expect to upgrade in that week, we can recover from any issues.  Given the current approach to calculating it I think we'd have to have a release that hard codes it to be sure all nodes agree on the value.",
        "created_at": "2021-09-16T03:01:27.792000+00:00",
        "attachments": null
    },
    {
        "author": "ajsutton",
        "category": "Channel Graveyard",
        "parent": "",
        "content": "Waiting until its finalized would solve the problem of nodes calculating it incorrectly.  Checkpoint sync is still busted, so we're still requiring a release to hard code TTD.",
        "created_at": "2021-09-16T03:02:34.569000+00:00",
        "attachments": null
    },
    {
        "author": "m.kalinin",
        "category": "Channel Graveyard",
        "parent": "",
        "content": "hmm, would it be hard to include TTD into the WS checkpoint state (aside with the beacon state)? Shipping a support of TTD in the WS sync could done in the same release as with the Merge logic. Does it sound too complicated? The reason of not including this parameter into beacon state is that this is a one time parameter and changing state back and forth would be suboptimal in this case",
        "created_at": "2021-09-16T03:06:46.258000+00:00",
        "attachments": null
    },
    {
        "author": "ajsutton",
        "category": "Channel Graveyard",
        "parent": "",
        "content": "The problem is it's been a real fight to get infrastructure setup so people can get a state for checkpoint sync.  Suddenly requiring something different as input breaks that infrastructure again and we're back to square one where people have no way to get a state+TTD required to do a checkpoint sync.",
        "created_at": "2021-09-16T03:08:25.570000+00:00",
        "attachments": null
    },
    {
        "author": "ajsutton",
        "category": "Channel Graveyard",
        "parent": "",
        "content": "So it would just wind up back with us putting out a release that hard codes the TTD so we can sync from just a state again.",
        "created_at": "2021-09-16T03:08:46.860000+00:00",
        "attachments": null
    },
    {
        "author": "ajsutton",
        "category": "Channel Graveyard",
        "parent": "",
        "content": "It really is a pain to lose the property of being able to apply a block just by having the pre-state and the block itself.",
        "created_at": "2021-09-16T03:09:18.884000+00:00",
        "attachments": null
    },
    {
        "author": "ajsutton",
        "category": "Channel Graveyard",
        "parent": "",
        "content": "Basically instead of adding a field to the state we add a whole bunch of extra infrastructure to track and store the TransitionStore, only to then need to rip it back out.",
        "created_at": "2021-09-16T03:10:13.800000+00:00",
        "attachments": null
    },
    {
        "author": "m.kalinin",
        "category": "Channel Graveyard",
        "parent": "",
        "content": "I see",
        "created_at": "2021-09-16T03:10:25.551000+00:00",
        "attachments": null
    },
    {
        "author": "m.kalinin",
        "category": "Channel Graveyard",
        "parent": "",
        "content": "From your perspective changing the state would be easier than changing the input data of WS sync, right?",
        "created_at": "2021-09-16T03:15:01.692000+00:00",
        "attachments": null
    },
    {
        "author": "ajsutton",
        "category": "Channel Graveyard",
        "parent": "",
        "content": "I think it would make pretty much everything about this easier to be honest.  You'd just be setting an extra field in the special merge transition and all the storage processes, fork handling etc remain the same.",
        "created_at": "2021-09-16T03:15:53.487000+00:00",
        "attachments": null
    },
    {
        "author": "ajsutton",
        "category": "Channel Graveyard",
        "parent": "",
        "content": "And we already have experience with both adding and removing fields from the state as that happened in Altair. It's not trivial but its well understood.",
        "created_at": "2021-09-16T03:16:28.731000+00:00",
        "attachments": null
    },
    {
        "author": "ajsutton",
        "category": "Channel Graveyard",
        "parent": "",
        "content": "The other gotcha I just realized for Teku is that we process slots separately to applying the block so we can cache the state without the block applied (and usually pre-calculate it). Which means that even an invalid block could be used to trigger setting the transition store.",
        "created_at": "2021-09-16T03:17:54.502000+00:00",
        "attachments": null
    },
    {
        "author": "ajsutton",
        "category": "Channel Graveyard",
        "parent": "",
        "content": "Although the do-it-on-finalization would solve that.",
        "created_at": "2021-09-16T03:18:41.763000+00:00",
        "attachments": null
    },
    {
        "author": "m.kalinin",
        "category": "Channel Graveyard",
        "parent": "",
        "content": "I agree that tieing TTD to the block/state tree helps to avoid the corner cases and adds guarantee that nodes are using the same TTD value without additional checks. Btw, having the TTD value in a separate store would likely need to be accompanied with the corresponding API request to allow users to verify that they are in agreement with the canonical TTD value that is meant to be published on some trustworthy site",
        "created_at": "2021-09-16T03:37:07.672000+00:00",
        "attachments": null
    },
    {
        "author": "m.kalinin",
        "category": "Channel Graveyard",
        "parent": "",
        "content": "It seems like having TTD in state would be less complicated ðŸ¤”",
        "created_at": "2021-09-16T03:37:39.758000+00:00",
        "attachments": null
    },
    {
        "author": "m.kalinin",
        "category": "Channel Graveyard",
        "parent": "",
        "content": "Sending `engine_TTDUpdated` could still be unsafe before we get TTD finalized, even if TTD is in the state",
        "created_at": "2021-09-16T03:42:20.172000+00:00",
        "attachments": null
    },
    {
        "author": "ajsutton",
        "category": "Channel Graveyard",
        "parent": "",
        "content": "Yeah putting TTD in the state does make it pretty much impossible to override - doing so would be an irregular state transition effectively.",
        "created_at": "2021-09-16T03:45:24.232000+00:00",
        "attachments": null
    },
    {
        "author": "ajsutton",
        "category": "Channel Graveyard",
        "parent": "",
        "content": "Is there a link to the discussions on why we wound up calculating this instead of just hard coding TTD? I know it was discussed but I'm not up on the reasoning.",
        "created_at": "2021-09-16T03:45:55.507000+00:00",
        "attachments": null
    },
    {
        "author": "m.kalinin",
        "category": "Channel Graveyard",
        "parent": "",
        "content": "The rationale is in this PR, https://github.com/ethereum/consensus-specs/pull/2462\nHaving this value hardcoded a month before the actual transition would make us setting it to relatively high value to be sure that the Merge HF happens before the transition. If difficulty drops after that we will have to wait for the Merge longer.",
        "created_at": "2021-09-16T03:49:52.014000+00:00",
        "attachments": null
    },
    {
        "author": "m.kalinin",
        "category": "Channel Graveyard",
        "parent": "",
        "content": "It could be hardcoded and released after the Merge HF. But would require all users to update their nodes once again to be ready for the transition.",
        "created_at": "2021-09-16T03:51:05.248000+00:00",
        "attachments": null
    },
    {
        "author": "ajsutton",
        "category": "Channel Graveyard",
        "parent": "",
        "content": "Ah yeah I can see the thinking there.  I suspect with the current dynamic logic there's pretty likely to need to be a release between Merge HF and the terminal block anyway. Certainly required for any client supporting checkpoint sync.",
        "created_at": "2021-09-16T03:52:33.977000+00:00",
        "attachments": null
    },
    {
        "author": "ajsutton",
        "category": "Channel Graveyard",
        "parent": "",
        "content": "I think having the API to override TTD makes sense as well and is compatible with a \"hard coded\" version.  So potentially users could upgrade once then set the TTD manually instead of upgrading a second time, but it's likely much easier and safer to just upgrade a second time.",
        "created_at": "2021-09-16T03:53:48.220000+00:00",
        "attachments": null
    },
    {
        "author": "m.kalinin",
        "category": "Channel Graveyard",
        "parent": "",
        "content": "I would not rely on users in this case",
        "created_at": "2021-09-16T03:54:19.898000+00:00",
        "attachments": null
    },
    {
        "author": "m.kalinin",
        "category": "Channel Graveyard",
        "parent": "",
        "content": "It looks like we have some trade offs here ðŸ˜†  What do you think about filing an issue and facilitate discussion?",
        "created_at": "2021-09-16T03:55:27.440000+00:00",
        "attachments": null
    },
    {
        "author": "ajsutton",
        "category": "Channel Graveyard",
        "parent": "",
        "content": "I'm thinking more of advanced setups like staking pools. Home stakers are unlikely to have an issue upgrading again, but big setups can be slower. Fortunately they're also more sophisticated and likely to be able to set it manually.",
        "created_at": "2021-09-16T03:55:30.149000+00:00",
        "attachments": null
    },
    {
        "author": "ajsutton",
        "category": "Channel Graveyard",
        "parent": "",
        "content": "I can file an issue at least. ðŸ™‚",
        "created_at": "2021-09-16T03:55:44.251000+00:00",
        "attachments": null
    },
    {
        "author": "m.kalinin",
        "category": "Channel Graveyard",
        "parent": "",
        "content": "go for it! ðŸ™‚",
        "created_at": "2021-09-16T03:56:37.590000+00:00",
        "attachments": null
    },
    {
        "author": "ajsutton",
        "category": "Channel Graveyard",
        "parent": "",
        "content": "Essay written: https://github.com/ethereum/consensus-specs/issues/2603 ðŸ™‚",
        "created_at": "2021-09-16T04:29:19.136000+00:00",
        "attachments": null
    },
    {
        "author": "m.kalinin",
        "category": "Channel Graveyard",
        "parent": "",
        "content": "\u003e The header chain must contain the checkpoint header `Hw`, and sync fails if a different header is encountered at the same block number. This sanity check exists to ensure that the chain is valid without having to sync all the way back to the genesis block.\n\nAssuming that the execution client trusts its consensus counter party and that the consensus client follows the protocol, this check looks redundant. The most recent finalized checkpoint must be a descendant of the WS checkpoint, otherwise, it couldn't be possible for an honest consensus client to reach this finalized checkpoint. Even in the case when soft fork has happened the WS checkpoint must be redefined to satisfy this requirement.\n\nMy question is how strong do we need `checkpoint(H)` call for the sync process, the process is triggered by the `final(B)` call and from my perspective `checkpoint(H)` doesn't buy us anything else than the need of adding yet another method to the Engine API?\n\n\u003c@!194432762315407360\u003e What do you think on that?",
        "created_at": "2021-09-16T05:48:27.316000+00:00",
        "attachments": null
    },
    {
        "author": ".fjl",
        "category": "Channel Graveyard",
        "parent": "",
        "content": "I think you are right and we don't need another method for this",
        "created_at": "2021-09-16T08:06:10.689000+00:00",
        "attachments": null
    },
    {
        "author": ".fjl",
        "category": "Channel Graveyard",
        "parent": "",
        "content": "But it would be nice for the client to have some historical reference blocks",
        "created_at": "2021-09-16T08:06:42.354000+00:00",
        "attachments": null
    },
    {
        "author": ".fjl",
        "category": "Channel Graveyard",
        "parent": "",
        "content": "More sanity checks always good. Also, these checks are really cheap, it's just blockhash",
        "created_at": "2021-09-16T08:07:22.665000+00:00",
        "attachments": null
    },
    {
        "author": "m.kalinin",
        "category": "Channel Graveyard",
        "parent": "",
        "content": "The hash of a block at the WS checkpoint could be sent with other things via `engine_consensusStatus` if we end up having this method in the API. But for now I'd remove this additional method, at least from the interop spec version.",
        "created_at": "2021-09-16T09:44:46.242000+00:00",
        "attachments": null
    },
    {
        "author": "mariusvanderwijden",
        "category": "Channel Graveyard",
        "parent": "",
        "content": "I've looked a bit into the current interface and have a couple of questions: \n- The type of the status field is `Enum`, which does not specify the max bitlength of the field. Given we only have three values, I would vote to specify the length to max 8 bits\n- ForkchoiceUpdated has no specified return values. It would be good if the el client could notify the cl client about its sync status here",
        "created_at": "2021-09-16T11:06:16.320000+00:00",
        "attachments": null
    },
    {
        "author": "mariusvanderwijden",
        "category": "Channel Graveyard",
        "parent": "",
        "content": "- PreparePayload has no way to return an error if the underlying node is not yet synced",
        "created_at": "2021-09-16T11:06:40.277000+00:00",
        "attachments": null
    },
    {
        "author": "mariusvanderwijden",
        "category": "Channel Graveyard",
        "parent": "",
        "content": "This is what I have right now as an interface\n```go\ntype Engine interface {\n    PreparePayload(parentHash common.Hash, timestamp uint64, random [32]byte, feeRecipient common.Address, payloadID uint64)\n    GetPayload(payloadID uint64) (ExecutionPayload, error)\n    ExecutePayload(payload ExecutionPayload) (common.Hash, Status)\n    ConsensusValidated(blockHash common.Hash) Status\n    ForkchoiceUpdated(headBlockHash, finalizedBlockHash, confirmedBlockHash common.Hash) error\n}\n```",
        "created_at": "2021-09-16T11:12:21.207000+00:00",
        "attachments": null
    },
    {
        "author": "m.kalinin",
        "category": "Channel Graveyard",
        "parent": "",
        "content": "We're currently working on the Merge F2F edition of the Engine API standard, should be published today or tomorrow and it may address this questions. `Enum` is gonna be converted to a `String` with a finite number of values. \n\nGood inputs on `PreparePayload` and `ForkchoiceUpdated`. What do you think it should return in a normal case? `ACK`?",
        "created_at": "2021-09-16T11:29:36.336000+00:00",
        "attachments": null
    },
    {
        "author": "mariusvanderwijden",
        "category": "Channel Graveyard",
        "parent": "",
        "content": "Probably, we should return something to make sure that the message was understood, otherwise the cl can probably not distinguish between successful call and an el disconnecting",
        "created_at": "2021-09-16T11:33:12.616000+00:00",
        "attachments": null
    },
    {
        "author": "m.kalinin",
        "category": "Channel Graveyard",
        "parent": "",
        "content": "I am curious about all response statuses listed in the sync draft for the `final(B)` call: `'old', 'syncing', invalid(B) or synced(B)`. Do we need all of them?",
        "created_at": "2021-09-16T11:35:21.060000+00:00",
        "attachments": null
    },
    {
        "author": "mariusvanderwijden",
        "category": "Channel Graveyard",
        "parent": "",
        "content": "cc \u003c@!194432762315407360\u003e",
        "created_at": "2021-09-16T11:36:23.072000+00:00",
        "attachments": null
    },
    {
        "author": ".fjl",
        "category": "Channel Graveyard",
        "parent": "",
        "content": "I'm not sure what we will need in the end",
        "created_at": "2021-09-16T11:37:51.607000+00:00",
        "attachments": null
    },
    {
        "author": ".fjl",
        "category": "Channel Graveyard",
        "parent": "",
        "content": "In the document, I just invented one response value for every possible outcome.",
        "created_at": "2021-09-16T11:38:19.758000+00:00",
        "attachments": null
    },
    {
        "author": ".fjl",
        "category": "Channel Graveyard",
        "parent": "",
        "content": "BTW, I am still working on the next version of the document. I hope to be done with it next week.",
        "created_at": "2021-09-16T11:39:39.798000+00:00",
        "attachments": null
    },
    {
        "author": "m.kalinin",
        "category": "Channel Graveyard",
        "parent": "",
        "content": "I would not mix outages with the sync or any other process. As this kind of cases should be handled with the mechanism that is unified for all methods across the API. I think we should better focus on it after interop",
        "created_at": "2021-09-16T11:40:04.860000+00:00",
        "attachments": null
    },
    {
        "author": "m.kalinin",
        "category": "Channel Graveyard",
        "parent": "",
        "content": "I see, let us wait for the new version of the document",
        "created_at": "2021-09-16T11:40:57.080000+00:00",
        "attachments": null
    }
]