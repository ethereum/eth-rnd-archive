[
    {
        "author": "meowbroski",
        "category": "general",
        "parent": "",
        "content": "How do you plan on measuring Scalability?",
        "created_at": "2022-01-31T21:27:39.418000+00:00",
        "attachments": []
    },
    {
        "author": "potuz",
        "category": "general",
        "parent": "",
        "content": "What sort of benchmark are you interested in? Some measures are inherent to the protocol and do not need to be measured: things like \"blocks per day\" for example. Others can be benchmarked in an application basis, things like, \"synced blocks per second\". I suspect you are interested in a mixture of those: things that pertain to scalability of the form \"how many transactions per block can we process?\" Where there's a component of the protocol and another of the implementation",
        "created_at": "2022-01-31T22:30:23.092000+00:00",
        "attachments": []
    },
    {
        "author": "potuz",
        "category": "general",
        "parent": "",
        "content": "\u003e why different applications though?\nBecause different clients (may) perform differently the same task. Some may optimize for disk space others for fast state transition and so forth",
        "created_at": "2022-01-31T22:31:04.301000+00:00",
        "attachments": []
    },
    {
        "author": "potuz",
        "category": "general",
        "parent": "",
        "content": "\u003e is there a place I can read?\nI don't think I understand exactly what you want to measure, but if you want to benchmark for example state transition processing time as a function of block size I'd look into the repositories of Besu, Erigorn, Geth and Nethermind",
        "created_at": "2022-01-31T22:31:48.665000+00:00",
        "attachments": []
    },
    {
        "author": "potuz",
        "category": "general",
        "parent": "",
        "content": "\u003e yes, throughput latency in transactions\nThen you shouldn't be benchmarking the protocol, but rather different applications. The bottleneck currently seems to be dictated by state growth and it's a can of worms that I don't want to open here. But what I want to say is that there's no \"number\" that to can get that is the current \"number of transactions we can process per block\". Rather you can get a table where the gas limit is an entry, the number of transactions is another, and then you get biproducts like block size, etc",
        "created_at": "2022-01-31T22:32:45.487000+00:00",
        "attachments": []
    },
    {
        "author": "potuz",
        "category": "general",
        "parent": "",
        "content": "\u003e I want to measure Ethereum scalability\nTPS is dependant on block size, of you increase block gas size you will get more TPS. This is not something that you can \"measure\" more than you can compute it. Scalability is a broad term, do you mean TPS \u003e N while keeping M validators?",
        "created_at": "2022-01-31T22:33:11.901000+00:00",
        "attachments": []
    },
    {
        "author": "potuz",
        "category": "general",
        "parent": "",
        "content": "Things get complicated if you want to start including all parameters that enter the equation: user demand, disk space, CPU, bandwidth, etc",
        "created_at": "2022-01-31T22:33:54.950000+00:00",
        "attachments": []
    },
    {
        "author": "potuz",
        "category": "general",
        "parent": "",
        "content": "Moved from \u003c#745077610685661265\u003e  what I could",
        "created_at": "2022-01-31T22:34:27.482000+00:00",
        "attachments": []
    }
]