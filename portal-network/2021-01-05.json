[
    {
        "author": "pipermerriam",
        "category": "Channel Graveyard",
        "parent": "",
        "content": "I've been digesting the \"on demand state availability\" problem over the last few days.  I've got a messy hackmd document and 7 pages of hand written notes trying to write down every facet of the problem.  These aren't well formed for external consumption but I'm working on translating them so that they are.  It's an ugly problem....\n\nAt present, I'm seeing a couple of paths forward, none of which are solid.\n\n1. we do it GetNodeData style.  The network is an archive node.  It holds all historical state.  It's a blunt but effective solution.  It side steps all of the complex pieces that arise in other approaches at the cost of multiple different types of inneficiencies.  we could build this today.  It's unclear how hard it would be to make it scale to the necessary performance level.\n2. we do it Firehose/RedQueen style.  We try to store data more effeciently using things learned by flat database layout approaches.  We have hard problems to solve like dealing with the imbalanced nature of contract storages.  We have to store proofs alongside the data and update the proofs.  Here we accept complexity as a trade-off for \"maybe\" making the network more efficient in some meaningful ways.\n3. we do something completely new.  Maybe it involves actually changing the core protocol in some way.  We come at the problem as if we had zero existing design constraints and try to find a workable solution and then work back from there towards something viable.\n\nI'm all over the place with respect to how to move forward.  Two days ago I was leaning into option 3.  Before that I've been picking option 2 apart forever and it just consistently feels complex.   Today I'm  leaning towards trying to invalidate option 1 because as maybe it can actually work and if it can.....",
        "created_at": "2021-01-05T16:50:21.183000+00:00",
        "attachments": null
    },
    {
        "author": "pipermerriam",
        "category": "Channel Graveyard",
        "parent": "",
        "content": "Invalidating option 1 requires something like:\n\n1. getting the count of total nodes in an archive node\n2. running the numbers on rough rate of growth (how many new nodes per hour/day/month/year)\n3. running the numbers on average size of each node in the trie\n4. running the numbers on the number of trie nodes each node in the network would need to hold for the network to be healthy.\n5. determining how long it would take to retrieve the necessary state to estimate the gas for a transaction based on number of network round trips and estimated latency of these requests.\n\nThis all assumes a DHT of some sort for storing the data.",
        "created_at": "2021-01-05T16:55:36.281000+00:00",
        "attachments": null
    },
    {
        "author": "pipermerriam",
        "category": "Channel Graveyard",
        "parent": "",
        "content": "The solution isn't viable if:\n\n- It takes an unreasonably large amount of time to run a simple transaction like an ERC20 token transfer.\n- The size of the stored data that each node would need to house for a healthy network ends up being prohibitively large such as the network needing to have 100k nodes each storing 100mb of data or something like that....\n- Other things.....  (I'm figuring this out as I go)",
        "created_at": "2021-01-05T16:57:55.534000+00:00",
        "attachments": null
    },
    {
        "author": "holiman",
        "category": "Channel Graveyard",
        "parent": "",
        "content": "Option one is basically 'light client'. Ok done ðŸšŽ",
        "created_at": "2021-01-05T16:58:08.142000+00:00",
        "attachments": null
    },
    {
        "author": "pipermerriam",
        "category": "Channel Graveyard",
        "parent": "",
        "content": "I don't understand that statement, can you elaborate?",
        "created_at": "2021-01-05T16:58:40.433000+00:00",
        "attachments": null
    },
    {
        "author": "pipermerriam",
        "category": "Channel Graveyard",
        "parent": "",
        "content": "I also just realized that option 1, if it worked, could be a viable way to eliminate `GetNodeData` from the devp2p core protocol....",
        "created_at": "2021-01-05T16:59:26.962000+00:00",
        "attachments": null
    },
    {
        "author": "pipermerriam",
        "category": "Channel Graveyard",
        "parent": "",
        "content": "Option 1 would be a DHT, where each node stores trie nodes who's hash is \"near\" them in the network, evenly distributing all of the trie data across all of the nodes in the network.  It's not clear to me how this is \"light client\"?",
        "created_at": "2021-01-05T17:00:40.791000+00:00",
        "attachments": null
    },
    {
        "author": "holiman",
        "category": "Channel Graveyard",
        "parent": "",
        "content": "A les client assumes the network has all that may be relevant, and fetches state as needed on demand. It already exists, but has problems actually finding servers to serve them",
        "created_at": "2021-01-05T17:01:03.454000+00:00",
        "attachments": null
    },
    {
        "author": "pipermerriam",
        "category": "Channel Graveyard",
        "parent": "",
        "content": "Yeah, those aren't the same because LES exists in a client server model.  I'm proposing a homogenous network and no presumption that any node has all of the data.  The DHT provides routing to \"find\" the network nodes that have the data you want.",
        "created_at": "2021-01-05T17:01:30.829000+00:00",
        "attachments": null
    },
    {
        "author": "sky.cactus",
        "category": "Channel Graveyard",
        "parent": "",
        "content": "Why homogeneous?",
        "created_at": "2021-01-05T17:01:43.620000+00:00",
        "attachments": null
    },
    {
        "author": "holiman",
        "category": "Channel Graveyard",
        "parent": "",
        "content": "The trolley-bus was also meant to signify that I wasn't 100% serious",
        "created_at": "2021-01-05T17:02:00.217000+00:00",
        "attachments": null
    },
    {
        "author": "pipermerriam",
        "category": "Channel Graveyard",
        "parent": "",
        "content": "Ah, that didn't translate for me ðŸ˜…",
        "created_at": "2021-01-05T17:02:27.929000+00:00",
        "attachments": null
    },
    {
        "author": "sky.cactus",
        "category": "Channel Graveyard",
        "parent": "",
        "content": "I thought everyone knew what the ðŸšŽ meant.  ðŸ˜„",
        "created_at": "2021-01-05T17:02:56.286000+00:00",
        "attachments": null
    },
    {
        "author": "sky.cactus",
        "category": "Channel Graveyard",
        "parent": "",
        "content": "More specifically, why are you starting with the requirement that the network be homogeneous?",
        "created_at": "2021-01-05T17:03:54.416000+00:00",
        "attachments": null
    },
    {
        "author": "pipermerriam",
        "category": "Channel Graveyard",
        "parent": "",
        "content": "Homogenous because the client/server architecture of LES makes it so that it depends on the altruism of a few nodes and doesn't make it possible for the light nodes to contribute back.  By removing the client/server and making it homogenous **AND** making it easy for light nodes to contribute back, my assertion it is that it can work without incentivization.",
        "created_at": "2021-01-05T17:04:06.846000+00:00",
        "attachments": null
    },
    {
        "author": "sky.cactus",
        "category": "Channel Graveyard",
        "parent": "",
        "content": "Why do you want to avoid incentivization?",
        "created_at": "2021-01-05T17:04:31.508000+00:00",
        "attachments": null
    },
    {
        "author": "sky.cactus",
        "category": "Channel Graveyard",
        "parent": "",
        "content": "I want to run Ethereum on my phone.  I would rather pay someone with a computer a small amount of money that have to upgrade my phone to the ZX9000 with a 500GB SSD.",
        "created_at": "2021-01-05T17:05:36.774000+00:00",
        "attachments": null
    },
    {
        "author": "pipermerriam",
        "category": "Channel Graveyard",
        "parent": "",
        "content": "Because the UX sucks and it's also hard problem.  Who's paying.  How do they pay.  Nobody wants to pay for things....",
        "created_at": "2021-01-05T17:05:54.675000+00:00",
        "attachments": null
    },
    {
        "author": "sky.cactus",
        "category": "Channel Graveyard",
        "parent": "",
        "content": "To me, incentives are better than a homogeneous solution because reality isn't homogeneous.",
        "created_at": "2021-01-05T17:06:04.027000+00:00",
        "attachments": null
    },
    {
        "author": "sky.cactus",
        "category": "Channel Graveyard",
        "parent": "",
        "content": "I have a phone, you have a data center.  You can store data way cheaper than I can.",
        "created_at": "2021-01-05T17:06:27.353000+00:00",
        "attachments": null
    },
    {
        "author": "sky.cactus",
        "category": "Channel Graveyard",
        "parent": "",
        "content": "I save money by paying you, instead of upgrading my phone.",
        "created_at": "2021-01-05T17:07:19.250000+00:00",
        "attachments": null
    },
    {
        "author": "pipermerriam",
        "category": "Channel Graveyard",
        "parent": "",
        "content": "Right, but wouldn't it be nice if 100k lightweight clients (1 CPU, 100MB of memory, minimal bandwidth) running on a myriad of different devices were able to support the network....",
        "created_at": "2021-01-05T17:07:30.330000+00:00",
        "attachments": null
    },
    {
        "author": "sky.cactus",
        "category": "Channel Graveyard",
        "parent": "",
        "content": "You can achieve that by constraining the network sufficiently.  ðŸ˜„",
        "created_at": "2021-01-05T17:08:05.113000+00:00",
        "attachments": null
    },
    {
        "author": "pipermerriam",
        "category": "Channel Graveyard",
        "parent": "",
        "content": "I'm looking for  a solution that would actually allow you to make a meaningful contribution with a raspberry pi plugged into a consumer grade internet connection.",
        "created_at": "2021-01-05T17:08:07.898000+00:00",
        "attachments": null
    },
    {
        "author": "pipermerriam",
        "category": "Channel Graveyard",
        "parent": "",
        "content": "And I'm not sure it's possible, but I haven't seen anything that convinces me it isn't possible.",
        "created_at": "2021-01-05T17:08:29.472000+00:00",
        "attachments": null
    },
    {
        "author": "sky.cactus",
        "category": "Channel Graveyard",
        "parent": "",
        "content": "As seen by PoW, specialized hardware is just so many orders of magnitude better at specialized tasks that you'll never be able to make it so the raspberry pi is *reasonable* on a network with data centers.",
        "created_at": "2021-01-05T17:08:58.760000+00:00",
        "attachments": null
    },
    {
        "author": "sky.cactus",
        "category": "Channel Graveyard",
        "parent": "",
        "content": "You can constrain the network such that the pi *can* function, but it seems better to allow the network to grow by leveraging specialization where we can.",
        "created_at": "2021-01-05T17:09:38.924000+00:00",
        "attachments": null
    },
    {
        "author": "pipermerriam",
        "category": "Channel Graveyard",
        "parent": "",
        "content": "\u003c@!301186049323958275\u003e I agree that specialized hardware can do these things well.  I'm not arguing with that.  I just think there's a different way and that's where I'm focusing my efforts right now.",
        "created_at": "2021-01-05T17:10:05.051000+00:00",
        "attachments": null
    },
    {
        "author": "dryajov",
        "category": "Channel Graveyard",
        "parent": "",
        "content": "I disagree, eth2 runs on a raspberry pi and does a lot of the things that a network like this would do",
        "created_at": "2021-01-05T17:10:38.016000+00:00",
        "attachments": null
    },
    {
        "author": "djrtwo",
        "category": "Channel Graveyard",
        "parent": "",
        "content": "I don't believe homogeny in this context means that all clients will be the same and serve the same amount, but that small and large clients can both produce and consume",
        "created_at": "2021-01-05T17:11:00.916000+00:00",
        "attachments": null
    },
    {
        "author": "djrtwo",
        "category": "Channel Graveyard",
        "parent": "",
        "content": "the les server *is* the network rahter than particular nodes",
        "created_at": "2021-01-05T17:11:18.425000+00:00",
        "attachments": null
    },
    {
        "author": "sky.cactus",
        "category": "Channel Graveyard",
        "parent": "",
        "content": "I also suspect it is possible to build a state network that would distribute data replication across a large number of nodes without requiring they all store everything.  I just suspect it isn't worth it compared to a world where we leverage specialization and incentives.",
        "created_at": "2021-01-05T17:11:29.419000+00:00",
        "attachments": null
    },
    {
        "author": "pipermerriam",
        "category": "Channel Graveyard",
        "parent": "",
        "content": "I will happily/begrudgingly look at an incentive based solution, I'm just not personally going down that road at this time.",
        "created_at": "2021-01-05T17:12:04.827000+00:00",
        "attachments": null
    },
    {
        "author": "sky.cactus",
        "category": "Channel Graveyard",
        "parent": "",
        "content": "ETH2 also doesn't do much at the moment.  ðŸ™‚  In particular, it doesn't have much state nor complex and frequent state transitions.",
        "created_at": "2021-01-05T17:13:25.257000+00:00",
        "attachments": null
    },
    {
        "author": "dryajov",
        "category": "Channel Graveyard",
        "parent": "",
        "content": "\u003c@!364458974906548225\u003e (sorry, I still owe you that writeup) - just a quick recap of what we attempted with mustekala, which is very similar to this:\n- We did more or less the same ting you're suggesting with splitting the state into chunks/subtries and storing them on nodes close to the chunk/subtrie\n- We kept those subtries up to date, by propagating updates to them over pubsub (gossipsub)\n- The big issues is contract storage, which potentially requires a change to the patricia merkle trie to something more predictable/balanced",
        "created_at": "2021-01-05T17:14:42.079000+00:00",
        "attachments": null
    },
    {
        "author": "pipermerriam",
        "category": "Channel Graveyard",
        "parent": "",
        "content": "I think I wrote off the DHT/`GetNodeData` based solution a while back because `GetNodeData` has been a \"thorn in the protocol's side\" for a long time, and the inefficiencies bothered me.  But after spending time this last week going back over thing, those inefficiencies feel reasonably given the complexities I've run into every other way I've tried to come at the problem.",
        "created_at": "2021-01-05T17:14:55.434000+00:00",
        "attachments": null
    },
    {
        "author": "dryajov",
        "category": "Channel Graveyard",
        "parent": "",
        "content": "overall, the model works, like I said, the issue is with the unbalanced nature of the patricia trie",
        "created_at": "2021-01-05T17:15:26.338000+00:00",
        "attachments": null
    },
    {
        "author": "pipermerriam",
        "category": "Channel Graveyard",
        "parent": "",
        "content": "\u003e - The big issues is contract storage, which potentially requires a change to the patricia merkle trie to something more predictable/balanced\nYeah, this is the wall I run into over and over again and I haven't seen a way around it",
        "created_at": "2021-01-05T17:15:33.260000+00:00",
        "attachments": null
    },
    {
        "author": "djrtwo",
        "category": "Channel Graveyard",
        "parent": "",
        "content": "does code merkilization fix that?",
        "created_at": "2021-01-05T17:15:47.622000+00:00",
        "attachments": null
    },
    {
        "author": "dryajov",
        "category": "Channel Graveyard",
        "parent": "",
        "content": "My conclusion was that this wouldn't be possible without a protocol change",
        "created_at": "2021-01-05T17:15:56.696000+00:00",
        "attachments": null
    },
    {
        "author": "pipermerriam",
        "category": "Channel Graveyard",
        "parent": "",
        "content": "I have even thought about dividing the problem in two.  One network for accounts, and then try to figure out the contract storage separately.",
        "created_at": "2021-01-05T17:16:00.073000+00:00",
        "attachments": null
    },
    {
        "author": "dryajov",
        "category": "Channel Graveyard",
        "parent": "",
        "content": "a binary merkle trie for example or going all the way with ssz",
        "created_at": "2021-01-05T17:16:16.181000+00:00",
        "attachments": null
    },
    {
        "author": "pipermerriam",
        "category": "Channel Graveyard",
        "parent": "",
        "content": "I'm leaning this way too",
        "created_at": "2021-01-05T17:16:22.014000+00:00",
        "attachments": null
    },
    {
        "author": "pipermerriam",
        "category": "Channel Graveyard",
        "parent": "",
        "content": "also, `SELFDESTRUCT` seems really hard.  Did you have any thoughts on how to deal with a contract with huge storage that wipes itself?",
        "created_at": "2021-01-05T17:17:23.507000+00:00",
        "attachments": null
    },
    {
        "author": "dryajov",
        "category": "Channel Graveyard",
        "parent": "",
        "content": "no, but I don't think it's a problem, the network stores a snapshot of the data, so for block 12345, contract AAABBBFFF, will be there, but for block 67890, it wont...",
        "created_at": "2021-01-05T17:18:48.816000+00:00",
        "attachments": null
    },
    {
        "author": "pipermerriam",
        "category": "Channel Graveyard",
        "parent": "",
        "content": "would data simply \"expire/naturally-fall-off\"?",
        "created_at": "2021-01-05T17:19:16.632000+00:00",
        "attachments": null
    },
    {
        "author": "dryajov",
        "category": "Channel Graveyard",
        "parent": "",
        "content": "the snapshot tracks the block essentially",
        "created_at": "2021-01-05T17:19:18.280000+00:00",
        "attachments": null
    },
    {
        "author": "pipermerriam",
        "category": "Channel Graveyard",
        "parent": "",
        "content": "or is the network an archive node?",
        "created_at": "2021-01-05T17:19:28.587000+00:00",
        "attachments": null
    },
    {
        "author": "dryajov",
        "category": "Channel Graveyard",
        "parent": "",
        "content": "you can do either, there might be different types of nodes, historical nodes will hoard all the states, others will cache more recent stuff...",
        "created_at": "2021-01-05T17:19:57.860000+00:00",
        "attachments": null
    },
    {
        "author": "dryajov",
        "category": "Channel Graveyard",
        "parent": "",
        "content": "the beauty of this approach is that it allows for all sorts of clever/flexible schemes",
        "created_at": "2021-01-05T17:20:23.474000+00:00",
        "attachments": null
    },
    {
        "author": "dryajov",
        "category": "Channel Graveyard",
        "parent": "",
        "content": "casual nodes might for example serve/store some chunks that they've recently used that other nodes would request from it",
        "created_at": "2021-01-05T17:21:00.409000+00:00",
        "attachments": null
    },
    {
        "author": "dryajov",
        "category": "Channel Graveyard",
        "parent": "",
        "content": "think of it as a dynamic cdn",
        "created_at": "2021-01-05T17:21:20.932000+00:00",
        "attachments": null
    },
    {
        "author": "s1na",
        "category": "Channel Graveyard",
        "parent": "",
        "content": "sth like merging storage tries and the account trie?",
        "created_at": "2021-01-05T17:21:42.305000+00:00",
        "attachments": null
    },
    {
        "author": "dryajov",
        "category": "Channel Graveyard",
        "parent": "",
        "content": "well, the problem is in the data-structure itself, the patricia trie is unpredictable",
        "created_at": "2021-01-05T17:22:39.859000+00:00",
        "attachments": null
    },
    {
        "author": "dryajov",
        "category": "Channel Graveyard",
        "parent": "",
        "content": "so chunking it becomes a real issue",
        "created_at": "2021-01-05T17:22:49.294000+00:00",
        "attachments": null
    },
    {
        "author": "dryajov",
        "category": "Channel Graveyard",
        "parent": "",
        "content": "as for what data goes there, it really doesn't matter as long as it's uniform/predictable enough",
        "created_at": "2021-01-05T17:23:10.068000+00:00",
        "attachments": null
    },
    {
        "author": "pipermerriam",
        "category": "Channel Graveyard",
        "parent": "",
        "content": "\u003c@!453997683431178243\u003e any thoughts on the less fancy DHT+`GetNodeData` approach.  Anything that you know of that firmly stands in the way of it working?",
        "created_at": "2021-01-05T17:25:01.757000+00:00",
        "attachments": null
    },
    {
        "author": "dryajov",
        "category": "Channel Graveyard",
        "parent": "",
        "content": "basically storing individual nodes?",
        "created_at": "2021-01-05T17:25:47.029000+00:00",
        "attachments": null
    },
    {
        "author": "dryajov",
        "category": "Channel Graveyard",
        "parent": "",
        "content": "I don't think so, it might actually not be such a bad idea",
        "created_at": "2021-01-05T17:25:57.385000+00:00",
        "attachments": null
    },
    {
        "author": "pipermerriam",
        "category": "Channel Graveyard",
        "parent": "",
        "content": "I recognize that it sucks to have to make ~7 round trips to get down to the actually account, walking your way down the tree....",
        "created_at": "2021-01-05T17:25:58.528000+00:00",
        "attachments": null
    },
    {
        "author": "dryajov",
        "category": "Channel Graveyard",
        "parent": "",
        "content": "so, anecdotal, but we tried this with IPFS/IPLD, essentially mapping the merkle patricia on top of IPLD and that was the killer issue - too many roundrips",
        "created_at": "2021-01-05T17:27:01.364000+00:00",
        "attachments": null
    },
    {
        "author": "pipermerriam",
        "category": "Channel Graveyard",
        "parent": "",
        "content": "but it also side steps:\n\n- chunking\n- updating proofs\n- needing proofs at all for most things\n- dealing with imbalanced contract storage",
        "created_at": "2021-01-05T17:27:03.432000+00:00",
        "attachments": null
    },
    {
        "author": "dryajov",
        "category": "Channel Graveyard",
        "parent": "",
        "content": "yeah, as I remember it now, we landed on chunking precisely because of the roundtrip issues",
        "created_at": "2021-01-05T17:27:34.211000+00:00",
        "attachments": null
    },
    {
        "author": "pipermerriam",
        "category": "Channel Graveyard",
        "parent": "",
        "content": "Yeah, at 50ms per round trip which is probably generous in many contexts, thats 350ms per account lookup, which probably translates to 3-10 seconds for a very simple ERC20 transfer...",
        "created_at": "2021-01-05T17:28:27.125000+00:00",
        "attachments": null
    },
    {
        "author": "dryajov",
        "category": "Channel Graveyard",
        "parent": "",
        "content": "honestly, I think the chunking approach is actually not as hard to implement at all, given that we have a better merkle data structure to work with",
        "created_at": "2021-01-05T17:28:38.814000+00:00",
        "attachments": null
    },
    {
        "author": "pipermerriam",
        "category": "Channel Graveyard",
        "parent": "",
        "content": "That doesn't solve the imbalanced nature of contract storage does it?",
        "created_at": "2021-01-05T17:29:12.350000+00:00",
        "attachments": null
    },
    {
        "author": "dryajov",
        "category": "Channel Graveyard",
        "parent": "",
        "content": "yeah, I mean with the addoption of a more balanced structure",
        "created_at": "2021-01-05T17:29:27.234000+00:00",
        "attachments": null
    },
    {
        "author": "dryajov",
        "category": "Channel Graveyard",
        "parent": "",
        "content": "wasn't there a proposal to use a binary merkle trie?",
        "created_at": "2021-01-05T17:29:39.982000+00:00",
        "attachments": null
    },
    {
        "author": "dryajov",
        "category": "Channel Graveyard",
        "parent": "",
        "content": "how far out is that?",
        "created_at": "2021-01-05T17:29:58.977000+00:00",
        "attachments": null
    },
    {
        "author": "pipermerriam",
        "category": "Channel Graveyard",
        "parent": "",
        "content": "not close",
        "created_at": "2021-01-05T17:30:08.733000+00:00",
        "attachments": null
    },
    {
        "author": "dryajov",
        "category": "Channel Graveyard",
        "parent": "",
        "content": "ðŸ˜¦",
        "created_at": "2021-01-05T17:30:14.818000+00:00",
        "attachments": null
    },
    {
        "author": "pipermerriam",
        "category": "Channel Graveyard",
        "parent": "",
        "content": "soonest, next fork after berlin if it gets seriously prioritized.  maybe more realistically the one after that as the soonest....  It's a significant change/migration",
        "created_at": "2021-01-05T17:31:00.070000+00:00",
        "attachments": null
    },
    {
        "author": "dryajov",
        "category": "Channel Graveyard",
        "parent": "",
        "content": "hmm, yeah I'm honestly not sure if we can do this without that, that was the major blocker I ran into",
        "created_at": "2021-01-05T17:32:29.985000+00:00",
        "attachments": null
    },
    {
        "author": "dryajov",
        "category": "Channel Graveyard",
        "parent": "",
        "content": "so, I think without going down that rabbit hole, option 2 might be a viable stop gap solution",
        "created_at": "2021-01-05T17:34:50.097000+00:00",
        "attachments": null
    },
    {
        "author": "pipermerriam",
        "category": "Channel Graveyard",
        "parent": "",
        "content": "I *think* that I'm going to focus on trying to eliminate option 1 because otherwise I'm going to keep coming back to it when I dead-end elsewhere",
        "created_at": "2021-01-05T17:36:37.978000+00:00",
        "attachments": null
    },
    {
        "author": "pipermerriam",
        "category": "Channel Graveyard",
        "parent": "",
        "content": "Even if it takes 30 seconds to do gas estimation on a transaction.....  it isn't the only option people have.... and maybe it can even serve as the foundation for a layer on top of it that can do it more efficiently",
        "created_at": "2021-01-05T17:38:28.391000+00:00",
        "attachments": null
    },
    {
        "author": "dryajov",
        "category": "Channel Graveyard",
        "parent": "",
        "content": "yeah, thats not a bad path forward, tbh",
        "created_at": "2021-01-05T17:39:46.232000+00:00",
        "attachments": null
    },
    {
        "author": "dryajov",
        "category": "Channel Graveyard",
        "parent": "",
        "content": "some/most of it can be reused I suppose",
        "created_at": "2021-01-05T17:40:04.665000+00:00",
        "attachments": null
    },
    {
        "author": "dryajov",
        "category": "Channel Graveyard",
        "parent": "",
        "content": "also, keep in mind that we attempted to do this on top of IPFS/IPLD and that might have added additional overhead",
        "created_at": "2021-01-05T17:40:30.235000+00:00",
        "attachments": null
    },
    {
        "author": "dryajov",
        "category": "Channel Graveyard",
        "parent": "",
        "content": "tho I still think that most of the overhead is simply from the amount of roundtrips themself",
        "created_at": "2021-01-05T17:41:02.561000+00:00",
        "attachments": null
    },
    {
        "author": "pipermerriam",
        "category": "Channel Graveyard",
        "parent": "",
        "content": "\u003c@!211091239112671234\u003e curious to know whether such a network that could effectively serve `GetNodeData` requests would be compelling for use with SNAP",
        "created_at": "2021-01-05T17:44:38.630000+00:00",
        "attachments": null
    },
    {
        "author": "pipermerriam",
        "category": "Channel Graveyard",
        "parent": "",
        "content": "(let me know if there's someone better for me to direct that question towards)",
        "created_at": "2021-01-05T17:44:53.356000+00:00",
        "attachments": null
    },
    {
        "author": "holiman",
        "category": "Channel Graveyard",
        "parent": "",
        "content": "Maybe I'm not understanding the full context of the question. But snap is good for serving parts of a large trie, in chunks of leafs, trustlessly. Snap is less good for serving small portions of state efficiently, since then the proofs take more space than the data",
        "created_at": "2021-01-05T18:02:56.638000+00:00",
        "attachments": null
    },
    {
        "author": "holiman",
        "category": "Channel Graveyard",
        "parent": "",
        "content": "Clarification: good for transmitting maybe 20k leafs per chunk",
        "created_at": "2021-01-05T18:03:33.984000+00:00",
        "attachments": null
    },
    {
        "author": "dryajov",
        "category": "Channel Graveyard",
        "parent": "",
        "content": "whats snap if you don't mind me asking, it sounds pretty interesting",
        "created_at": "2021-01-05T18:03:34.300000+00:00",
        "attachments": null
    },
    {
        "author": "holiman",
        "category": "Channel Graveyard",
        "parent": "",
        "content": "https://github.com/ethereum/devp2p/blob/master/caps/snap.md",
        "created_at": "2021-01-05T18:04:27.646000+00:00",
        "attachments": null
    },
    {
        "author": "dryajov",
        "category": "Channel Graveyard",
        "parent": "",
        "content": "thanks!",
        "created_at": "2021-01-05T18:04:33.165000+00:00",
        "attachments": null
    },
    {
        "author": "holiman",
        "category": "Channel Graveyard",
        "parent": "",
        "content": "Merged into geth, coming in next release. The next generation sync as far as geth is concerned",
        "created_at": "2021-01-05T18:05:05.783000+00:00",
        "attachments": null
    },
    {
        "author": "pipermerriam",
        "category": "Channel Graveyard",
        "parent": "",
        "content": "\u003c@!211091239112671234\u003e My question was targeted at a mechanism of SNAP sync, not the actual protocol.  My understanding is that SNAP gives you a snapshot, but that snapshot ends up with some holes in it.  So, `GetNodeData` is used to patch up these holes.  Which prevents us from dropping `GetNodeData` from the `eth` protocol.  My question is: supposing there was a DHT that could serve `GetNodeData` style requests, is there enough interest in getting rid of `GetNodeData` to migrate that mechanism onto this new imaginary network.",
        "created_at": "2021-01-05T18:38:18.136000+00:00",
        "attachments": null
    },
    {
        "author": "holiman",
        "category": "Channel Graveyard",
        "parent": "",
        "content": "Snap doesn't rely on eth getnodedata",
        "created_at": "2021-01-05T20:13:04.068000+00:00",
        "attachments": null
    },
    {
        "author": "holiman",
        "category": "Channel Graveyard",
        "parent": "",
        "content": "See https://github.com/ethereum/devp2p/blob/master/caps/snap.md#gettrienodes-0x06",
        "created_at": "2021-01-05T20:15:03.807000+00:00",
        "attachments": null
    },
    {
        "author": "holiman",
        "category": "Channel Graveyard",
        "parent": "",
        "content": "\u003e Requests a number of state (either account or storage) Merkle trie nodes by path. This is analogous in functionality to the eth/63 GetNodeData, but restricted to only tries and queried by path, to break the generality that causes issues with database optimizations.",
        "created_at": "2021-01-05T20:15:28.478000+00:00",
        "attachments": null
    },
    {
        "author": "pipermerriam",
        "category": "Channel Graveyard",
        "parent": "",
        "content": "Am I correct that a previous iteration of SNAP did use `GetNodeData` or did I just pull that from thin air?",
        "created_at": "2021-01-05T20:33:18.931000+00:00",
        "attachments": null
    },
    {
        "author": "holiman",
        "category": "Channel Graveyard",
        "parent": "",
        "content": "Maybe a very long time ago",
        "created_at": "2021-01-05T20:56:02.299000+00:00",
        "attachments": null
    },
    {
        "author": "holiman",
        "category": "Channel Graveyard",
        "parent": "",
        "content": "And originally it wasn't by-path requests, but by-hash, like getnodedata",
        "created_at": "2021-01-05T20:58:39.585000+00:00",
        "attachments": null
    }
]