[
    {
        "author": "sky.cactus",
        "category": "Channel Graveyard",
        "parent": "",
        "content": "Is there a stateless call happening right now or in the near future?",
        "created_at": "2021-01-26T15:45:46.415000+00:00",
        "attachments": []
    },
    {
        "author": "0xraino",
        "category": "Channel Graveyard",
        "parent": "",
        "content": "Yes, in 15 mins",
        "created_at": "2021-01-26T15:45:57.332000+00:00",
        "attachments": []
    },
    {
        "author": "sky.cactus",
        "category": "Channel Graveyard",
        "parent": "",
        "content": "How does one acquire a link?  I think I got an invite, but I cannot find it now.",
        "created_at": "2021-01-26T15:46:09.103000+00:00",
        "attachments": []
    },
    {
        "author": "0xraino",
        "category": "Channel Graveyard",
        "parent": "",
        "content": "Let me see who sent it out and get you on the list, for now, here's the link:",
        "created_at": "2021-01-26T15:46:57.511000+00:00",
        "attachments": []
    },
    {
        "author": "0xraino",
        "category": "Channel Graveyard",
        "parent": "",
        "content": "https://www.google.com/url?q=https://consensysmesh.zoom.us/my/rdrost\u0026sa=D\u0026source=calendar\u0026ust=1612100268106000\u0026usg=AOvVaw1p0VfrTLQa8uoSFm9PeC6F",
        "created_at": "2021-01-26T15:46:58.727000+00:00",
        "attachments": []
    },
    {
        "author": "nick.ghita",
        "category": "Channel Graveyard",
        "parent": "",
        "content": "i've put up a small dashboard with preliminary findings from looking into how often txs access state. https://txstateaccess.herokuapp.com/ i'm considering running the experiment against another block to enhance / validate the findings. lmk if there are any questions or suggestions on how to tweak it",
        "created_at": "2021-01-26T16:34:49.661000+00:00",
        "attachments": []
    },
    {
        "author": "sky.cactus",
        "category": "Channel Graveyard",
        "parent": "",
        "content": "\u003c@364458974906548225\u003e Where can one find your 3 part blog post you mentioned toward the end?",
        "created_at": "2021-01-26T17:06:53.775000+00:00",
        "attachments": []
    },
    {
        "author": "pipermerriam",
        "category": "Channel Graveyard",
        "parent": "",
        "content": "https://snakecharmers.ethereum.org/the-winding-road-to-functional-light-clients/",
        "created_at": "2021-01-26T17:07:14.591000+00:00",
        "attachments": []
    },
    {
        "author": "samwilsn",
        "category": "Channel Graveyard",
        "parent": "",
        "content": "Is there a written description of how the state is addressed in alexandria? Curious to see how that works.",
        "created_at": "2021-01-26T17:31:13.589000+00:00",
        "attachments": []
    },
    {
        "author": "pipermerriam",
        "category": "Channel Graveyard",
        "parent": "",
        "content": "Alexandria isn't doing state.  It was focused on chain history only",
        "created_at": "2021-01-26T17:58:17.821000+00:00",
        "attachments": []
    },
    {
        "author": "pipermerriam",
        "category": "Channel Graveyard",
        "parent": "",
        "content": "\u003c@!689161464829050960\u003e right now we're looking at addressing state the naive way, using the node hash of the trie nodes.",
        "created_at": "2021-01-26T17:58:38.679000+00:00",
        "attachments": []
    },
    {
        "author": "pipermerriam",
        "category": "Channel Graveyard",
        "parent": "",
        "content": "It's simple, it naturally extends to being an archive node, it minimizes individual node responsibility since the data never changes or has to be updated, it side-steps the imbalanced nature of contract storage.",
        "created_at": "2021-01-26T17:59:27.325000+00:00",
        "attachments": []
    },
    {
        "author": "pipermerriam",
        "category": "Channel Graveyard",
        "parent": "",
        "content": "Some very preliminary results:\n\n1. It looks like `GetNodeData` style DHT lookups for state data for common transactions are going to be doable in a reasonable amount of time.  Using the estimates of 100ms per lookup, and measurements of mainnet transactions showing us that most transactions are touching less than 50 trie nodes, that gives a 5 second rough bound on total time to do gas estimation.  There are optimizations that can likely cut that number in half reasonably easily.",
        "created_at": "2021-01-26T19:13:53.521000+00:00",
        "attachments": []
    },
    {
        "author": "pipermerriam",
        "category": "Channel Graveyard",
        "parent": "",
        "content": "So the conclusion there is that we need to do more measuring to validate the numbers on a larger sample size, but if the numbers hold, a `GetNodeData` style DHT with 100ms average latency for looking up a single trie node will be usable.",
        "created_at": "2021-01-26T19:14:42.210000+00:00",
        "attachments": []
    },
    {
        "author": "pipermerriam",
        "category": "Channel Graveyard",
        "parent": "",
        "content": "2. We need to look closer at data ingress.  DHT packet sizes are roughly 1kb (1280 bytes-ish).  In the hexary trie, we expect the first 3-4 layers of the trie to be completely full in mainnet.  A \"full\" node is 16 * 32 byte hashes -\u003e 512 bytes per full trie node.  That means our \"base\" size for a proof against a new trie node is likely on the scale of about 3kb (this needs to be measured).  So we need to figure out how data ingress will work.  The \"questions\" we want to answer are.  A) How big are the total proof sizes for blocks today, and how big are the individual \"proofs\" for all of the individual trie nodes that are part of that witness, and B) How do we send these into the network in an efficient enough manner when they don't fit into a single UDP packet.",
        "created_at": "2021-01-26T19:18:24.774000+00:00",
        "attachments": []
    },
    {
        "author": "pipermerriam",
        "category": "Channel Graveyard",
        "parent": "",
        "content": "3. Brian's work on accessing *cold* state shows that blocks regularly reach deeply into the history.  I believe these results are preliminary and need to be validated, but they match our intuition.  That means that **either** the network must be big enough to be an archive node  **or** we need some kind of garbage collection so that the *cold* state doesn't get evicted since we've found that cold state gets touched quite regularly....    \n\nSo that leads to a second question which is to prototype generating exclusion proofs for each block for all for all of the trie nodes that were removed from the trie.  We want to know that we can do this in a sane manner, and that the proofs themselves are manageable in both total size, and when they are split up into individual proofs for each node that gets deleted.",
        "created_at": "2021-01-26T19:22:05.542000+00:00",
        "attachments": []
    },
    {
        "author": "pipermerriam",
        "category": "Channel Graveyard",
        "parent": "",
        "content": "So our open questions:\n\n1. Larger sample size experiment to validate our assumptions about how many trie nodes individual transactions touch.  Ideally, this would be run across something like 1000 recent blocks, and we could group transactions by their 4-byte selector to measure average number of trie nodes touched for each different type of function call.  \u003c@!439193900096290816\u003e speak up if you're going to continue working to measure something like this.\n2. Mainnet block proof sizes.  How big are the overall proofs?  How big are the individual proofs for each trie node at various depths?\n3. Garbage collection:  If we do garbage collection... how do we create exclusion proofs for all deleted trie nodes?  How big are the individual proofs for each individual node?  What is our expected worst case scenario for `SELFDESTRUCT` which deletes lots of storage.....",
        "created_at": "2021-01-26T19:26:26.897000+00:00",
        "attachments": []
    },
    {
        "author": "samwilsn",
        "category": "Channel Graveyard",
        "parent": "",
        "content": "I'm not sure I follow with the deletion/exclusion proof stuff, but that's probably just a lack of understanding on my part. Clients aren't expected to follow the chain when participating on the state network?\n\nOn another note, does using the \"node hash of the trie nodes\" lose locality of contract storage?",
        "created_at": "2021-01-26T20:37:38.575000+00:00",
        "attachments": []
    },
    {
        "author": "pipermerriam",
        "category": "Channel Graveyard",
        "parent": "",
        "content": "deletion/exclusion proof stuff....  the network has some \"total\" capacity.  10k nodes, 100mb per node, maximum possible storage.... 10k * 100mb -\u003e ~1TB.  The sum of all trie nodes for all of history comes in at somewhere in the 6TB range.  *if* the total storage of the network is less than the size of an archive node, then the least recently used data will get discarded from the network once it hits capacity....   \n\nThe \"least\" recently touched stuff tends to be part of the active state.  Things like genesis accounts that have never transacted...  So when the network gets full, the things that will go away are going to include pieces of the active state (state that is still part of a recent state root).  Our other research shows us that blocks regularly touch old state (300,000 blocks old or more).  So, if the network isn't big enough to house the full archive state, then at capacity, it will start dropping the *coldest* parts, which will include state that is still part of recent state roots.....\n\nSo, if the network is to remain healthy, we either A: need to guarantee that the network has enough capacity to be an archive node or B: actively delete nodes from the network that are no longer part of a recent state root.  Achieving A, in the early days of the network is possible, but it will require massively subsidizing the network with a bunch of nodes that are run by us until the network grows sufficiently large.  Achieving B, is what the exclusion proofs accomplish, allowing us to garbage collect nodes that aren't part of a recent state root.",
        "created_at": "2021-01-26T20:47:38.385000+00:00",
        "attachments": []
    },
    {
        "author": "pipermerriam",
        "category": "Channel Graveyard",
        "parent": "",
        "content": "I'm not sure what the work locality means in this context.",
        "created_at": "2021-01-26T20:48:15.041000+00:00",
        "attachments": []
    },
    {
        "author": "samwilsn",
        "category": "Channel Graveyard",
        "parent": "",
        "content": "Maybe locality is the wrong word, but the property that: more of the required data for a transaction can be requested in fewer packets.",
        "created_at": "2021-01-26T20:50:12.818000+00:00",
        "attachments": []
    },
    {
        "author": "pipermerriam",
        "category": "Channel Graveyard",
        "parent": "",
        "content": "Yes, that's the big trade-off for this approach.  Multiple lookups needed to dig into the trie before you get to the leaf data.",
        "created_at": "2021-01-26T20:50:51.483000+00:00",
        "attachments": []
    },
    {
        "author": "pipermerriam",
        "category": "Channel Graveyard",
        "parent": "",
        "content": "For accounts this is roughly 7x (7 layers of trie nodes between the root and the accounts at the leaves on average)",
        "created_at": "2021-01-26T20:51:12.177000+00:00",
        "attachments": []
    },
    {
        "author": "samwilsn",
        "category": "Channel Graveyard",
        "parent": "",
        "content": "Lemme get my definitions in order:\n - active state is any bit of data used to compute the state merkle root for recent blocks, for some definition of recent?\n - old state is still active state, but hasn't been modified/read in recent blocks?\n - coldest state == oldest state?",
        "created_at": "2021-01-26T20:56:06.167000+00:00",
        "attachments": []
    },
    {
        "author": "samwilsn",
        "category": "Channel Graveyard",
        "parent": "",
        "content": "Wait, so you actually have to do multiple lookups to retrieve a single piece of state?",
        "created_at": "2021-01-26T20:57:10.408000+00:00",
        "attachments": []
    },
    {
        "author": "pipermerriam",
        "category": "Channel Graveyard",
        "parent": "",
        "content": "Yes, you would need to fetch the state root node, then follow it down until you hit the leaf.  Each step of the way would be a network request.",
        "created_at": "2021-01-26T20:57:41.017000+00:00",
        "attachments": []
    },
    {
        "author": "samwilsn",
        "category": "Channel Graveyard",
        "parent": "",
        "content": "Oof, that's rough.",
        "created_at": "2021-01-26T20:57:48.834000+00:00",
        "attachments": []
    },
    {
        "author": "pipermerriam",
        "category": "Channel Graveyard",
        "parent": "",
        "content": "preliminary numbers suggest ~23 lookups for a simple value transfer transaction and ~35 lookups for an ERC20 transfer.  at 100ms per network request, thats 2.3 and 3.5 seconds respectively.  Totally viable for tons of use cases (like estimating the gas in an ultra light client)",
        "created_at": "2021-01-26T20:58:42.508000+00:00",
        "attachments": []
    },
    {
        "author": "samwilsn",
        "category": "Channel Graveyard",
        "parent": "",
        "content": "For sure! It's well within reasonable.",
        "created_at": "2021-01-26T20:59:29.876000+00:00",
        "attachments": []
    },
    {
        "author": "samwilsn",
        "category": "Channel Graveyard",
        "parent": "",
        "content": "How effective is `LastUsedDate` as a predictor of \"will this item be used in a transaction\"? Seemed like you have some preliminary research into that question.",
        "created_at": "2021-01-26T21:00:39.106000+00:00",
        "attachments": []
    },
    {
        "author": "pipermerriam",
        "category": "Channel Graveyard",
        "parent": "",
        "content": "\u003c@!296630428754771968\u003e might be better suited to answer that question.  I'll refer to this as \"how cold\" the state is, ranging from 0 meaning it's very warm/hot and was touched in the most recent block to ~11 million for something that hasn't been touched since genesis.  The distribution of what gets touched \"appears\" to be heavily skewed towards the \"warm/hot\" stuff with an exponential fall off and very long tail towards the very cold stuff.  We don't know how far that tail goes at this stage.  At least 300k blocks.",
        "created_at": "2021-01-26T21:03:13.487000+00:00",
        "attachments": []
    },
    {
        "author": "samwilsn",
        "category": "Channel Graveyard",
        "parent": "",
        "content": "Don't feel obligated to answer me immediately, btw, I'm mostly asking out of curiority!\n\nThat said, how would the network \"age out\" the coldest state? If we're using the same radius system from what I read before, wouldn't each node contract its radius as its storage was consumed?",
        "created_at": "2021-01-26T21:15:53.829000+00:00",
        "attachments": []
    },
    {
        "author": "samwilsn",
        "category": "Channel Graveyard",
        "parent": "",
        "content": "Ah, right. The radius is just for announcements. Each node would be free to evict based on whatever criteria it wants.",
        "created_at": "2021-01-26T21:17:58.812000+00:00",
        "attachments": []
    },
    {
        "author": "pipermerriam",
        "category": "Channel Graveyard",
        "parent": "",
        "content": "* Model A: Network is just an LRU cache.  New trie nodes get pushed in.\n* Model B: Network uses exclusion proofs.  Trie nodes that are no longer part of recent state roots are actively evicted.\n\nUnder both models, the oldest un-accessed nodes get evicted when the network is full.  \n\nUnder model A the network gets unhealthy if the total capacity is below the threshold needed to store all historical state (archive node).  I believe this number is about 100 TB which maps roughly to a million nodes each offering 100 mb of storage.   If each node offers 500mb then we need 200k nodes, etc.  Trade-offs.\n\nUnder model B the network gets unhealthy if the total capacity is below the threshold needed to store the trie nodes for the most recent N state roots.  The value for N is probably 256 but I bet it could be decently larger.  Today I think the necessary storage capacity would be roughly 500GB which maps to 5k nodes each offfering 100mb of storage.\n\nThe likely route to model A is to start with model B and then grow the network once it starts gaining popularity.",
        "created_at": "2021-01-26T22:13:53.411000+00:00",
        "attachments": []
    }
]