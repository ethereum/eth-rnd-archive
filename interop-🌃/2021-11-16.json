[
    {
        "author": "marioevz",
        "category": "Testing",
        "parent": "",
        "content": "Hi, added some simple test cases for the data structures of the engine_* messages here: https://github.com/marioevz/kintsugi_testing/tree/main/tests/DataStructures, only for ForkchoiceStateV1 and PayloadAttributesV1 structures at the moment but will add more for ExecutionPayloadV1 tomorrow, let me know if need any help running the tests üôå",
        "created_at": "2021-11-16T00:22:52.484000+00:00",
        "attachments": null
    },
    {
        "author": "paulhauner",
        "category": "Testing",
        "parent": "",
        "content": "I've noticed some teams are using ‚úÖ  instead of üçµ on the milestone tracker. This is off-brand I will be forced to report you to the marketing department.",
        "created_at": "2021-11-16T00:43:39.582000+00:00",
        "attachments": null
    },
    {
        "author": "ajsutton",
        "category": "Testing",
        "parent": "",
        "content": "\u003c@!361447803194441738\u003e Picking your brains on optimistic sync if I can... üôÇ\nAt least in Teku, finding the current head in protoarray involves starting with the current justified root and finding it's best descendant. I think that's generally true because the spec `get_filtered_block_tree` filters out any blocks that don't agree with the justified_checkpoint from `store`.\n\nGiven that, if the block referenced by the justified_checkpoint is found to be invalid, when I prune it from the protoarray I'm no longer able to find the chain head because I don't have a suitable starting point.  This means we effectively can't handle justifying an invalid ExecutionPayload which is slightly less tolerant than in your write up which assumed we can't deal with an invalid finalized ExecutionPayload.\n\nI'm inclined to just be ok with that because 2/3rd of validators would have to have attested to an invalid block to get it to justify and if we try to find a new justified_checkpoint we would likely have to roll it back to an earlier epoch which creates a risk of surround vote slashing. But would be useful to know if you (or anyone else) has encountered this.",
        "created_at": "2021-11-16T04:23:20.353000+00:00",
        "attachments": null
    },
    {
        "author": "paulhauner",
        "category": "Testing",
        "parent": "",
        "content": "Ah yes! I was wondering if we'd end up having to fail on a justified invalid block. It sounds like we do.",
        "created_at": "2021-11-16T04:25:37.291000+00:00",
        "attachments": null
    },
    {
        "author": "paulhauner",
        "category": "Testing",
        "parent": "",
        "content": "I'm also comfortable with exploding if we justify an invalid payload. I'd be interested to hear what \u003c@!291925846556540928\u003e thinks.\n\nThanks for shooting ahead with the implementation, teamwork üôå",
        "created_at": "2021-11-16T04:26:45.449000+00:00",
        "attachments": null
    },
    {
        "author": "ajsutton",
        "category": "Testing",
        "parent": "",
        "content": "\"Prune\" in this case is actually just removing the entry in the blockRoot -\u003e index lookup so I could maintain a full lookup there and filter invalid nodes a different way but I'm pretty sure we then wind up with a head block which is before the justified checkpoint and that's rather mind-bending.",
        "created_at": "2021-11-16T04:27:48.140000+00:00",
        "attachments": null
    },
    {
        "author": "ajsutton",
        "category": "Testing",
        "parent": "",
        "content": "For anyone interested, https://github.com/ConsenSys/teku/pull/4639 has the key changes to ProtoArray to track optimistic/valid/invalid nodes.  It doesn't do the pruning but I thought it would be a really quick little follow up PR...",
        "created_at": "2021-11-16T04:29:07.984000+00:00",
        "attachments": null
    },
    {
        "author": "paulhauner",
        "category": "Testing",
        "parent": "",
        "content": "Yeah, it seems like we'd need to \"roll-back\" the forkchoice store in order to find a justified head that works. That would take a lot of thought and work to implement safely. Infeasible, I'd say.",
        "created_at": "2021-11-16T04:29:24.956000+00:00",
        "attachments": null
    },
    {
        "author": "ajsutton",
        "category": "Testing",
        "parent": "",
        "content": "Right, I'm going to make it blow up then. Thank you.",
        "created_at": "2021-11-16T04:30:28.895000+00:00",
        "attachments": null
    },
    {
        "author": "ajsutton",
        "category": "Testing",
        "parent": "",
        "content": "So to set expectations, it‚Äôs looking pretty unlikely that Teku will be ready for a Devnet by the 18th. We‚Äôve been going a bit slower because we‚Äôre merging everything over to master so that when we‚Äôre ready we are really ready and won‚Äôt have to spend time polishing everything between the dev nets and public testnet.\nAnd as part of that we‚Äôre not doing in-step sync at all but going straight to optimistic sync. Optimistic sync actually solves a bunch of design problems we had in the code from amphora but is more complex and so we have a fair bit more work to do before we can start any interop testing.\nIf we don‚Äôt get too many nasty surprises we hopefully won‚Äôt be too far behind but given the 18th is 2 days away it seems unlikely we‚Äôll be ready in time.",
        "created_at": "2021-11-16T06:00:01.854000+00:00",
        "attachments": null
    },
    {
        "author": "paulhauner",
        "category": "Testing",
        "parent": "",
        "content": "I don't think Lighthouse can get a full-featured optimistic sync implementation by the 18th either. We have a partial implementation which will work for devnets, but we're yet to implement the new designs we did earlier this week. What we're missing is retrospective invalidation of blocks and exposing the verified optimistic ancestor where required.\n\nThis half-implementation of opt. sync is an artefact of our progressive experimentation with it, not a design decision. FWIW, I think it's totally sensible to shoot for the full implementation without trying to land on a half-impl first.",
        "created_at": "2021-11-16T06:24:11.056000+00:00",
        "attachments": null
    },
    {
        "author": "terence0083",
        "category": "Testing",
        "parent": "",
        "content": "likewise, it'll likely take us (prysm) a few weeks to understand and implement optimistic sync. Lockstep sync works today but it's not that interesting as we already seen it in action in pithos",
        "created_at": "2021-11-16T06:26:56.299000+00:00",
        "attachments": null
    },
    {
        "author": "g11tech",
        "category": "Testing",
        "parent": "",
        "content": "lodestar has also started optimistic sync dev, the real complexity and figuring out is here on forkchoice validation/invalidation/pruning. hoping to look at \u003c@!340345049063882753\u003e and \u003c@!361447803194441738\u003e 's work and take pointers.",
        "created_at": "2021-11-16T06:42:17.246000+00:00",
        "attachments": null
    },
    {
        "author": "blaise8",
        "category": "Testing",
        "parent": "",
        "content": "No, we have different implementation",
        "created_at": "2021-11-16T08:20:04.806000+00:00",
        "attachments": null
    },
    {
        "author": "blaise8",
        "category": "Testing",
        "parent": "",
        "content": "I just wanted to know about state and learn from it. We had put execution on a shard and eth1 is having block propagation done via peers, not via beacon. Very premature statements you had claimed",
        "created_at": "2021-11-16T08:23:05.425000+00:00",
        "attachments": null
    },
    {
        "author": "blaise8",
        "category": "Testing",
        "parent": "",
        "content": "Thank you though for your concerns. I do strongly believe that open source is made to be open. My team as Silesia team was the first team running catalyst+teku implementation in december last year to January  in k8s setup.\nhttps://blazejkrzak.medium.com/making-ethereum-2-0-executable-beacon-chain-live-257cceb5ff7d \nLinks are not working anymore, but \nlook at the date. R\u0026D did learn a bit from it even before you had very first Network.\n\n\nTo other eth devs:\nGreat job, thank you for all the answers you gave me. Sorry for offtopic. If anyone wants to know about our discoveries during research let me know.",
        "created_at": "2021-11-16T08:37:11.563000+00:00",
        "attachments": null
    },
    {
        "author": "m.kalinin",
        "category": "Testing",
        "parent": "",
        "content": "You should rather do this on the `forkchoiceUpdated` as it is stated in the spec. This is because there could be a block with the payload that would induce `executePayload` but wouldn't be a valid transition block because TTD is not yet reached. As TTD may be verified after the execution because it's a part of the fork choice code the `forkchoiceUpdated` is the only reliable trigger for the switch",
        "created_at": "2021-11-16T09:57:24.234000+00:00",
        "attachments": null
    },
    {
        "author": "potuz",
        "category": "Testing",
        "parent": "",
        "content": "By exploding here you mean just with regard to optimistic sync right? I'm a little concerned by this cause if for some reason we're highly forked, even for a few epochs, it's perfectly valid (and probable) to to justify conflicting blocks.",
        "created_at": "2021-11-16T10:21:23.859000+00:00",
        "attachments": null
    },
    {
        "author": "ajsutton",
        "category": "Testing",
        "parent": "",
        "content": "We're in a lot of trouble if we manage to get 2/3rds of validators attesting to blocks with invalid execution payloads such that they are then justified.  Conflicting justified blocks isn't an issue, but invalid ones are.  But yes, it only applies to optimistic sync - if the execution engine is already in sync then you'll detect the block is invalid long before it justifies and not process any attestations or blocks for that fork so it can't justify.",
        "created_at": "2021-11-16T10:24:13.241000+00:00",
        "attachments": null
    },
    {
        "author": "potuz",
        "category": "Testing",
        "parent": "",
        "content": "Yeah I get it that this is extreme and it's more than simply fork choice in the CL side, but I feel that not being able to handle something that the protocol itself does not prevent is also an issue. Anyway if this only applies to optimistic sync in principle this is not so bad",
        "created_at": "2021-11-16T10:34:06.636000+00:00",
        "attachments": null
    },
    {
        "author": "m.kalinin",
        "category": "Testing",
        "parent": "",
        "content": "I agree with this. Following a chain that has justified an invalid payload is as dangerous as if such a payload was finalized. If the majority voted for invalid payload then there is an EL failure (including malicious scenarios) either with the majority of nodes or a local node. It's likely that an invalid payload will be finalized after the next epoch in this case.",
        "created_at": "2021-11-16T18:16:11.802000+00:00",
        "attachments": null
    }
]