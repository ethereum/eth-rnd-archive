[
    {
        "author": "ethpandaops-devnet-pulse-v2",
        "category": "Testing",
        "parent": "",
        "content": "",
        "created_at": "2025-07-03T01:00:00.410000+00:00",
        "attachments": null
    },
    {
        "author": "barnabasbusa",
        "category": "Testing",
        "parent": "",
        "content": "\u003c@\u00261367819082019377202\u003e \u003c@\u00261367819653279125645\u003e \nWe are still experiencing non finality. \nAll nimbus and nimbusEL nodes are offline. \nReth nodes seem to struggle to peer up with anyone still. \n\n\nWe have 5 different forks on the network. One lodestar, two nimbus, one grandine. \n\nPrysm-besu can't seem to sync up. \nLodestar nethermind can't seem to sync up. \nTeku bootnode is also out of sync. \n\nI'd like to ask every client team to start digging into their machines and find out what the detailed issues are. I'm around all day, happy to give any assistance needed.",
        "created_at": "2025-07-03T13:19:29.851000+00:00",
        "attachments": null
    },
    {
        "author": "mariusvanderwijden",
        "category": "Testing",
        "parent": "",
        "content": "Do you see any bad blocks? Do you think its an el issue?",
        "created_at": "2025-07-03T13:24:39.231000+00:00",
        "attachments": null
    },
    {
        "author": "terencechain",
        "category": "Testing",
        "parent": "",
        "content": "For prysm nodes outlined above, it seems to me all the ELs are in optimistic mode",
        "created_at": "2025-07-03T13:26:01.440000+00:00",
        "attachments": null
    },
    {
        "author": "barnabasbusa",
        "category": "Testing",
        "parent": "",
        "content": "I haven't seen any bad blocks, but what besu said is that they had issues fetching latest snap from geth",
        "created_at": "2025-07-03T13:29:40.359000+00:00",
        "attachments": null
    },
    {
        "author": "gtrintinalia",
        "category": "Testing",
        "parent": "",
        "content": "There was an issue with Besu that we fixed today regarding bpos forkids, but interesting, we were able to peer with Reth because they were not sending the forkid",
        "created_at": "2025-07-03T13:35:41.889000+00:00",
        "attachments": null
    },
    {
        "author": "gtrintinalia",
        "category": "Testing",
        "parent": "",
        "content": "for Prysm-besu, Besu says that there is no calls from Prysm",
        "created_at": "2025-07-03T13:36:55.057000+00:00",
        "attachments": null
    },
    {
        "author": "jameshe5018",
        "category": "Testing",
        "parent": "",
        "content": "\u003c@199561711278227457\u003e \u003c@412614104222531604\u003e do we do any chaos testing where we are restarting nodes in the middle of the run? I felt like this worked differently before ( could be a prysm bug too) but restarting any prysm beacon node can't find any peers ( this is in kurtosis)",
        "created_at": "2025-07-03T13:50:30.164000+00:00",
        "attachments": null
    },
    {
        "author": "lightclient",
        "category": "Testing",
        "parent": "",
        "content": "this is likely, we had a regression after merging the archive node work to master which devnet-2 branch was built on. it was fixed last week, but i only today rebased so might want to reroll geth",
        "created_at": "2025-07-03T14:10:14.794000+00:00",
        "attachments": null
    },
    {
        "author": "barnabasbusa",
        "category": "Testing",
        "parent": "",
        "content": "reroll as in new db?",
        "created_at": "2025-07-03T14:16:03.434000+00:00",
        "attachments": null
    },
    {
        "author": "lightclient",
        "category": "Testing",
        "parent": "",
        "content": "updating the image and restarting should be sufficient",
        "created_at": "2025-07-03T14:20:46.570000+00:00",
        "attachments": null
    },
    {
        "author": "closer__",
        "category": "Testing",
        "parent": "",
        "content": "BPO fork ids ðŸ§µ \ncan \u003c@\u00261367819653279125645\u003e devs pls confirm the devnet2 fork ids?\n```\nspec 0 fork id ForkId { hash: ForkHash(\"2640ca6c\"), next: 1751030304 }\nafter osaka fork id ForkId { hash: ForkHash(\"e3a2e49e\"), next: 1751128608 }\nafter bpo1 fork id ForkId { hash: ForkHash(\"ae61389b\"), next: 1751226912 }\nafter bpo2 fork id ForkId { hash: ForkHash(\"87bc5d50\"), next: 1751325216 }\nafter bpo3 fork id ForkId { hash: ForkHash(\"23886bd2\"), next: 1751423520 }\nafter bpo4 fork id ForkId { hash: ForkHash(\"dda58b3e\"), next: 1751540256 }\nafter bpo5 fork id ForkId { hash: ForkHash(\"99ad5a08\"), next: 0 }\n```",
        "created_at": "2025-07-03T15:19:25.791000+00:00",
        "attachments": null
    },
    {
        "author": "sunnysidedj_42398",
        "category": "Testing",
        "parent": "",
        "content": "Peering Tool to fix peering issue",
        "created_at": "2025-07-03T15:21:13.721000+00:00",
        "attachments": null
    },
    {
        "author": "closer__",
        "category": "Testing",
        "parent": "",
        "content": "BPO fork ids ðŸ§µ",
        "created_at": "2025-07-03T15:34:01.661000+00:00",
        "attachments": null
    },
    {
        "author": "barnabasbusa",
        "category": "Testing",
        "parent": "",
        "content": "We had a lil issues with checking too frequently with dockerhub, so we dialed down the watchtower frequency from polling every 2 mins to poll every 15mins for new images.",
        "created_at": "2025-07-03T16:38:39.368000+00:00",
        "attachments": null
    }
]