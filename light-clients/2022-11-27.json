[
    {
        "author": "bridge-bot",
        "category": "Consensus R\u0026D",
        "parent": "",
        "content": "\u003cdapplion\u003e \u003e \u003cdapplion\u003e  How can you check against the block without proofs? (re @etan_status: You can req LC update from others, then check it against the backfilled block, no?)",
        "created_at": "2022-11-27T06:19:45.996000+00:00",
        "attachments": []
    },
    {
        "author": "bridge-bot",
        "category": "Consensus R\u0026D",
        "parent": "",
        "content": "\u003cdapplion\u003e \u003e \u003cdapplion\u003e  Spec must require participants to\n: \n- Backfill snapshots for past checkpoints, which can be derived from backfilling blocks\n- Backfill updates for past periods, which can be verified with the sync committee pubkeys of the snapshots\n\nThe range of epocs / periods to backfil snapshots and updates should be such that there exist at least one snapshot to verify the first update of the range.\n\nThen should that range be equal to the backfill requirement of blocks, or greater? (re @etan_status: You can req LC update from others, then check it against the backfilled block, no?)",
        "created_at": "2022-11-27T07:09:09.591000+00:00",
        "attachments": []
    },
    {
        "author": "bridge-bot",
        "category": "Consensus R\u0026D",
        "parent": "",
        "content": "\u003cetan_status\u003e \u003e \u003cetan_status\u003e  you just ask network for “best update for period X”, then hash_tree_root(update.attested_header) == hash_tree_root(backfilled block.message) and update.sync_aggregate == update.signature_slot backfilled block.message.body.sync_aggregate (re @dapplion: How can you check against the block without proofs?)",
        "created_at": "2022-11-27T08:29:33.605000+00:00",
        "attachments": []
    },
    {
        "author": "bridge-bot",
        "category": "Consensus R\u0026D",
        "parent": "",
        "content": "\u003cetan_status\u003e \u003e \u003cetan_status\u003e  Currently spec makes it a SHOULD to provide data for same retention period as blocks, because anything before that you cannot reliably verify without extra proof as you mention.\n\nIn practice, in nimbus we currently never prune either blocks nor light client data. I think pruning should be aligned with EIP4444 once that becomes relevant. An interesting use case would be to start from a block root that is ~6 month or ~12 month old. That one could be agreed-on by the community once in a while, and serve as a starting point to cross-check checkpointz.\n\nNimbus doesnt backfill LC data currently, the assumption is that over time enough data is collected by the network as a whole to serve the entire retention period. (re @dapplion: Spec must require participants to\n: \n- Backfill snapshots for past checkpoints, which can be derived from backfilling blocks\n- Backfill updates for past periods, which can be verified with the sync committee pubkeys of the snapshots\n\nThe range of epocs / periods to backfil snapshots and updates should be such that there exist at least one snapshot to verify the first update of the range.\n\nThen should that range be equal to the backfill requirement of blocks, or greater?)",
        "created_at": "2022-11-27T08:37:20.873000+00:00",
        "attachments": []
    },
    {
        "author": "bridge-bot",
        "category": "Consensus R\u0026D",
        "parent": "",
        "content": "\u003cdapplion\u003e \u003e \u003cdapplion\u003e  I think clients MUST backfill LC data or there will be gaps and UX will suffer, at least Nimbus and Lodestar which are aligned in pushing the ecosystem (re @etan_status: Currently spec makes it a SHOULD to provide data for same retention period as blocks, because anything before that you cannot reliably verify without extra proof as you mention.\n\nIn practice, in nimbus we currently never prune either blocks nor light client data. I think pruning should be aligned with EIP4444 once that becomes relevant. An interesting use case would be to start from a block root that is ~6 month or ~12 month old. That one could be agreed-on by the community once in a while, and serve as a starting point to cross-check checkpointz.\n\nNimbus doesnt backfill LC data currently, the assumption is that over time enough data is collected by the network as a whole to serve the entire retention period.)",
        "created_at": "2022-11-27T09:33:04.382000+00:00",
        "attachments": []
    },
    {
        "author": "bridge-bot",
        "category": "Consensus R\u0026D",
        "parent": "",
        "content": "\u003cdapplion\u003e \u003e \u003cdapplion\u003e  How can you proof that all pubkeys in the sync committee are correct? (re @etan_status: you just ask network for “best update for period X”, then hash_tree_root(update.attested_header) == hash_tree_root(backfilled block.message) and update.sync_aggregate == update.signature_slot backfilled block.message.body.sync_aggregate)",
        "created_at": "2022-11-27T09:33:26.923000+00:00",
        "attachments": []
    },
    {
        "author": "bridge-bot",
        "category": "Consensus R\u0026D",
        "parent": "",
        "content": "\u003cetan_status\u003e \u003e \u003cetan_status\u003e  gaps \u003c 1 day are alright though (re @dapplion: I think clients MUST backfill LC data or there will be gaps and UX will suffer, at least Nimbus and Lodestar which are aligned in pushing the ecosystem)",
        "created_at": "2022-11-27T09:39:16.058000+00:00",
        "attachments": []
    },
    {
        "author": "bridge-bot",
        "category": "Consensus R\u0026D",
        "parent": "",
        "content": "\u003cetan_status\u003e \u003e \u003cetan_status\u003e  same as the light client, by merkle proof that update.next_sync_committee is rooted in update.attested_header.state_root (re @dapplion: How can you proof that all pubkeys in the sync committee are correct?)",
        "created_at": "2022-11-27T09:39:58.783000+00:00",
        "attachments": []
    },
    {
        "author": "bridge-bot",
        "category": "Consensus R\u0026D",
        "parent": "",
        "content": "\u003cetan_status\u003e btw, do you have practical evidence of bad LC data availability? I’m still seeing slow peer discovery especially on testnets as the bigger issue . \n\nand yes, nimbus/lodestar doing backfill would be great.",
        "created_at": "2022-11-27T09:46:44.223000+00:00",
        "attachments": []
    },
    {
        "author": "bridge-bot",
        "category": "Consensus R\u0026D",
        "parent": "",
        "content": "\u003cdapplion\u003e \u003e \u003cdapplion\u003e  No practical evidence just speculation on a future with decent load (re @etan_status: btw, do you have practical evidence of bad LC data availability? I’m still seeing slow peer discovery especially on testnets as the bigger issue . \n\nand yes, nimbus/lodestar doing backfill would be great.)",
        "created_at": "2022-11-27T12:00:13.267000+00:00",
        "attachments": []
    }
]