[
    {
        "author": "bridge-bot",
        "category": "Execution Layer",
        "parent": "",
        "content": "\u003cdeveloperuche\u003e Hey @jordibaylina please can you throw more light to how this is done:\n\n\"The trick? Custom x86 assembly via ahead-of-time (AOT) compilation. 3 or 4 x86 instructions per RISC-V/ZisK instruction, plus 2 x86 instructions to segment the trace into correctly-sized chunks.\"\n\nsource: https://x.com/eth_proofs/status/1937083157519458687\n\nThis image, illustrates the flow \"From RISCV elf to Proof\".\n\nRiscv -\u003e ZiskRom -\u003e EmuTrace -\u003e Wit Gen -\u003e Proof gen\n\n\nThe EmuTrace is obtained by emulating this ZiskRom [here](https://github.com/0xPolygonHermez/zisk/blob/main/emulator/src/emu.rs), and this is the trace the constraints is created with;\n\nWhat's confusing is, looking at Zisk's ISA, it looks more like an extension of RISCV also adding some pre-complies.\n\nHow doe this happen? \n\"The trick? Custom x86 assembly via ahead-of-time (AOT) compilation. 3 or 4 x86 instructions per RISC-V/ZisK instruction, plus 2 x86 instructions to segment the trace into correctly-sized chunks.\"",
        "created_at": "2025-06-26T11:59:14.905000+00:00",
        "attachments": [
            {
                "type": "image/jpeg",
                "origin_name": "file_0.jpg",
                "content": "92da112333a048c4f11cc17841c1262f791e0dec2439f45a462cc17ce6ce8608"
            }
        ]
    },
    {
        "author": "bridge-bot",
        "category": "Execution Layer",
        "parent": "",
        "content": "\u003cdeveloperuche\u003e Hey @jordibaylina please can you throw more light to how this is done:\n\n\"The trick? Custom x86 assembly via ahead-of-time (AOT) compilation. 3 or 4 x86 instructions per RISC-V/ZisK instruction, plus 2 x86 instructions to segment the trace into correctly-sized chunks.\"\n\nsource: https://x.com/eth_proofs/status/1937083157519458687\n\nThis image, illustrates the flow \"From RISCV elf to Proof\".\n\nRiscv -\u003e ZiskRom -\u003e EmuTrace -\u003e Wit Gen -\u003e Proof gen\n\n\nThe EmuTrace is obtained by emulating this ZiskRom [here](https://github.com/0xPolygonHermez/zisk/blob/main/emulator/src/emu.rs), and this is the trace the constraints is created with;\n\nWhat's confusing is, looking at Zisk's ISA, it looks more like an extension of RISCV also adding some pre-complies.\n\nHow does this happen? \n\"The trick? Custom x86 assembly via ahead-of-time (AOT) compilation. 3 or 4 x86 instructions per RISC-V/ZisK instruction, plus 2 x86 instructions to segment the trace into correctly-sized chunks.\"",
        "created_at": "2025-06-26T12:02:32.250000+00:00",
        "attachments": [
            {
                "type": "image/jpeg",
                "origin_name": "file_0.jpg",
                "content": "92da112333a048c4f11cc17841c1262f791e0dec2439f45a462cc17ce6ce8608"
            }
        ]
    },
    {
        "author": "bridge-bot",
        "category": "Execution Layer",
        "parent": "",
        "content": "\u003cjordibaylina\u003e Do you have a concrete doubt?\n\nThe idea is just to take riscV instructions and translate the to x86 instructions. The translated instructions not only execute the code, but also generates a minimum trace, so that then you can reexecut any chunk of the code in parallel for creating the witness and generating the proofs.",
        "created_at": "2025-06-26T16:00:23.179000+00:00",
        "attachments": null
    },
    {
        "author": "mariusvanderwijden",
        "category": "Execution Layer",
        "parent": "",
        "content": "This transpilation step is not formally verified right? \nSo even if we formally verified the ZKevm and the riscv instruction set, we could still prove something thats not correct.\nAfaiu you need to execute the program once, then split up the intermediate states and then prove them in parallel, right?",
        "created_at": "2025-06-26T16:03:17.867000+00:00",
        "attachments": null
    },
    {
        "author": "bridge-bot",
        "category": "Execution Layer",
        "parent": "",
        "content": "\u003calexanderlhicks\u003e re: **@jordibaylina**\n\u003e Do you have a concrete doubt?\n\nThe idea is just to take riscV instructions and translate the to x86 instructions. The translated instructions not only execute the code, but also generates a minimum trace, so that then you can reexecut any chunk of the code in parallel for creating the witness and generating the proofs.\nOn that note, does this give you a better sense of how good risc-v hardware would have to be relative to x86/ARM hardware to be useful (years in the future)?",
        "created_at": "2025-06-26T16:05:31.656000+00:00",
        "attachments": null
    },
    {
        "author": "bridge-bot",
        "category": "Execution Layer",
        "parent": "",
        "content": "\u003cjordibaylina\u003e re: **@L1zkevm_bot**\n\u003e \u003cmariusvanderwijden This transpilation step is not formally verified right? \nSo even if we formally verified the ZKevm and the riscv instruction set, we could still prove something thats not correct.\nAfaiu you need to execute the program once, then split up the intermediate states and then prove them in parallel, right?\nNo, this is just a way to generate a witness faster, it has no relation with security.",
        "created_at": "2025-06-26T16:38:00.890000+00:00",
        "attachments": null
    },
    {
        "author": "bridge-bot",
        "category": "Execution Layer",
        "parent": "",
        "content": "\u003cjordibaylina\u003e re: **@alexanderlhicks**\n\u003e On that note, does this give you a better sense of how good risc-v hardware would have to be relative to x86/ARM hardware to be useful (years in the future)?\nIf we are already at 1.5GHz (may be 2GHz with overclocking) I don‚Äôt see a lot of margin for riskV hardware. It‚Äôs a huge investment for jus a 2x best case.   I think it‚Äôs better idea in investing i mutithread proving..",
        "created_at": "2025-06-26T16:40:21.893000+00:00",
        "attachments": null
    },
    {
        "author": "bridge-bot",
        "category": "Execution Layer",
        "parent": "",
        "content": "\u003calexanderlhicks\u003e re: **@jordibaylina**\n\u003e If we are already at 1.5GHz (may be 2GHz with overclocking) I don‚Äôt see a lot of margin for riskV hardware. It‚Äôs a huge investment for jus a 2x best case.   I think it‚Äôs better idea in investing i mutithread proving..\nYeah I was only wondering about this over a 5+ year period as the availability of risc-v hardware increases, not as something to focus on.",
        "created_at": "2025-06-26T17:58:49.128000+00:00",
        "attachments": null
    },
    {
        "author": "bridge-bot",
        "category": "Execution Layer",
        "parent": "",
        "content": "\u003calexanderlhicks\u003e re: **@jordibaylina**\n\u003e No, this is just a way to generate a witness faster, it has no relation with security.\nYou'd still want to ensure that the witness generator produces only witnesses that satisfy the constraints, or is the witness generation logic entirely separate from this?",
        "created_at": "2025-06-26T18:04:27.473000+00:00",
        "attachments": null
    },
    {
        "author": "bridge-bot",
        "category": "Execution Layer",
        "parent": "",
        "content": "\u003calexanderlhicks\u003e re: **@alexanderlhicks**\n\u003e Yeah I was only wondering about this over a 5+ year period as the availability of risc-v hardware increases, not as something to focus on.\nOne reason for thinking about this is that Qualcomm and Samsung are apparently increasingly at odds with ARM and looking more into risc-v as a result. Nvidia has also been shipping an increasing amount of risc-v cores (1B in 2024).",
        "created_at": "2025-06-26T18:06:15.605000+00:00",
        "attachments": null
    },
    {
        "author": "bridge-bot",
        "category": "Execution Layer",
        "parent": "",
        "content": "\u003cjordibaylina\u003e re: **@alexanderlhicks**\n\u003e You'd still want to ensure that the witness generator produces only witnesses that satisfy the constraints, or is the witness generation logic entirely separate from this?\nIt‚Äôs an enterally logic that is replaced. Before you had an emulator and now you replace for this compiled version. But the output is the same.\n\nIn general, the security is in the verifier side.  Once you have a verifier that‚Äôs ‚Äúsafe‚Äù you don‚Äôt care how you generate the proof if it is verified.",
        "created_at": "2025-06-26T18:09:43.281000+00:00",
        "attachments": null
    },
    {
        "author": "bridge-bot",
        "category": "Execution Layer",
        "parent": "",
        "content": "\u003cmratsim\u003e re: **@alexanderlhicks**\n\u003e One reason for thinking about this is that Qualcomm and Samsung are apparently increasingly at odds with ARM and looking more into risc-v as a result. Nvidia has also been shipping an increasing amount of risc-v cores (1B in 2024).\nIt's the same as interpreting a brainfuck program: https://github.com/mratsim/jitterland/blob/02febc47ce5267180e16a11351289b6900dcaf24/bfVM_v02.nim#L85\n\nvs compiling it to x86: https://github.com/mratsim/jitterland/blob/02febc47ce5267180e16a11351289b6900dcaf24/bfVM_v03_jit.nim#L51",
        "created_at": "2025-06-26T18:13:14.869000+00:00",
        "attachments": null
    },
    {
        "author": "bridge-bot",
        "category": "Execution Layer",
        "parent": "",
        "content": "\u003calexanderlhicks\u003e re: **@jordibaylina**\n\u003e It‚Äôs an enterally logic that is replaced. Before you had an emulator and now you replace for this compiled version. But the output is the same.\n\nIn general, the security is in the verifier side.  Once you have a verifier that‚Äôs ‚Äúsafe‚Äù you don‚Äôt care how you generate the proof if it is verified.\nCompleteness?",
        "created_at": "2025-06-26T18:26:56.313000+00:00",
        "attachments": null
    },
    {
        "author": "bridge-bot",
        "category": "Execution Layer",
        "parent": "",
        "content": "\u003cmoodlezoup\u003e iiuc it's not necessarily a completeness issue, but a liveness one. The proof system itself might be complete, i.e. there exists a witness, but the tracer may fail to generate the correct witness",
        "created_at": "2025-06-26T18:31:24.892000+00:00",
        "attachments": null
    },
    {
        "author": "bridge-bot",
        "category": "Execution Layer",
        "parent": "",
        "content": "\u003calexanderlhicks\u003e Yep",
        "created_at": "2025-06-26T18:39:22.663000+00:00",
        "attachments": null
    },
    {
        "author": "bridge-bot",
        "category": "Execution Layer",
        "parent": "",
        "content": "\u003cjordibaylina\u003e re: **@alexanderlhicks**\n\u003e One reason for thinking about this is that Qualcomm and Samsung are apparently increasingly at odds with ARM and looking more into risc-v as a result. Nvidia has also been shipping an increasing amount of risc-v cores (1B in 2024).\nAssuming that we have riscV procesors at the same speed the mainstream procesor (x86, arm, etc). We need to add the ‚Äúminimal trace‚Äù generation. I‚Äôm not sure if Qualcomm and co will add this functionality‚Ä¶ And doing this separatelly using the curring age IC tech, not sure if it‚Äôs possible and at whst costs..",
        "created_at": "2025-06-26T18:41:10.015000+00:00",
        "attachments": null
    },
    {
        "author": "bridge-bot",
        "category": "Execution Layer",
        "parent": "",
        "content": "\u003cjordibaylina\u003e Agree in the liveness issue. But this is true for the full prover, not only the execution part. A buggy prover may stop the proof generation.",
        "created_at": "2025-06-26T18:44:02.580000+00:00",
        "attachments": null
    },
    {
        "author": "bridge-bot",
        "category": "Execution Layer",
        "parent": "",
        "content": "\u003cmoodlezoup\u003e you could hypothetically have multiple trace/witness generation implementations that plug into the same prover implementation, just as you could have multiple prover implementations for a single verifier implementation. it's not dissimilar to consensus/execution client diversity",
        "created_at": "2025-06-26T18:45:24.102000+00:00",
        "attachments": null
    },
    {
        "author": "bridge-bot",
        "category": "Execution Layer",
        "parent": "",
        "content": "\u003calexanderlhicks\u003e I expect we will have this, but there's a practical question which depends on how the prover is integrated. If you imagine a prover that receives a block from a builder, with no option but to prove it, then these bugs matter more than if provers can choose what they prove (i.e. discard anything they fail to prove). Diversity mitigates this, but it's not a reason to not look at this.",
        "created_at": "2025-06-26T18:48:39.814000+00:00",
        "attachments": null
    },
    {
        "author": "bridge-bot",
        "category": "Execution Layer",
        "parent": "",
        "content": "\u003cjordibaylina\u003e Would be good to understand the liveness requirements from the protocol perspective. It‚Äôs not the same commiting and proving in one transacion that having two phases one for committing and another for proving.  The second option is more sensible to liveness..",
        "created_at": "2025-06-26T18:48:41.665000+00:00",
        "attachments": null
    },
    {
        "author": "bridge-bot",
        "category": "Execution Layer",
        "parent": "",
        "content": "\u003ckevaundray\u003e If the validity of the block depends on there being a proof, is it possible that provers can choose to not prove a block?",
        "created_at": "2025-06-26T19:06:02.420000+00:00",
        "attachments": null
    },
    {
        "author": "bridge-bot",
        "category": "Execution Layer",
        "parent": "",
        "content": "\u003ckevaundray\u003e re: **@jordibaylina**\n\u003e Would be good to understand the liveness requirements from the protocol perspective. It‚Äôs not the same commiting and proving in one transacion that having two phases one for committing and another for proving.  The second option is more sensible to liveness..\nwhat does committing mean here?",
        "created_at": "2025-06-26T19:06:23.050000+00:00",
        "attachments": null
    },
    {
        "author": "bridge-bot",
        "category": "Execution Layer",
        "parent": "",
        "content": "\u003calexanderlhicks\u003e re: **@kevaundray**\n\u003e If the validity of the block depends on there being a proof, is it possible that provers can choose to not prove a block?\nYou could define it that way, but then there's a question of sending back to the builders to produce another block with time to spare to still prove a block in that slot",
        "created_at": "2025-06-26T19:07:49.628000+00:00",
        "attachments": null
    },
    {
        "author": "bridge-bot",
        "category": "Execution Layer",
        "parent": "",
        "content": "\u003calexanderlhicks\u003e And the question of censorship",
        "created_at": "2025-06-26T19:08:18.250000+00:00",
        "attachments": null
    },
    {
        "author": "bridge-bot",
        "category": "Execution Layer",
        "parent": "",
        "content": "\u003csophiagold0\u003e I expect builders will run their own provers based on the comparable opex of each",
        "created_at": "2025-06-26T19:10:04.135000+00:00",
        "attachments": null
    },
    {
        "author": "bridge-bot",
        "category": "Execution Layer",
        "parent": "",
        "content": "\u003cbarnabemonnot\u003e re: **@alexanderlhicks**\n\u003e And the question of censorship\nwe're talking about censorship in the sense of not adding a non-FOCIL tx that is unfavourable in proving costs, if the tx doesn't repay at least that cost to the builder? or censorship that can be solved with FOCIL?",
        "created_at": "2025-06-26T19:10:38.454000+00:00",
        "attachments": null
    },
    {
        "author": "bridge-bot",
        "category": "Execution Layer",
        "parent": "",
        "content": "\u003cmratsim\u003e re: **@sophiagold0**\n\u003e I expect builders will run their own provers based on the comparable opex of each\nIt's completely different hardware. Current builder is a fast single-thread machine with low-latency and fast networking.\n\nA prover currently needs a cluster.",
        "created_at": "2025-06-26T19:12:01.102000+00:00",
        "attachments": null
    },
    {
        "author": "bridge-bot",
        "category": "Execution Layer",
        "parent": "",
        "content": "\u003calexanderlhicks\u003e re: **@sophiagold0**\n\u003e I expect builders will run their own provers based on the comparable opex of each\nI do too, incl because of this, but since that isn't settled (let alone defined in the protocol in some way) we need to make this part of the discussion.",
        "created_at": "2025-06-26T19:12:03.272000+00:00",
        "attachments": null
    },
    {
        "author": "bridge-bot",
        "category": "Execution Layer",
        "parent": "",
        "content": "\u003cmratsim\u003e What I expect is that we will still have infra teams like bloxroute and chainbound that will optimize latency between builders, relayers, validators and now provers.",
        "created_at": "2025-06-26T19:15:00.341000+00:00",
        "attachments": null
    },
    {
        "author": "bridge-bot",
        "category": "Execution Layer",
        "parent": "",
        "content": "\u003ckevaundray\u003e re: **@alexanderlhicks**\n\u003e You could define it that way, but then there's a question of sending back to the builders to produce another block with time to spare to still prove a block in that slot\nI'm not sure we could do this because if you imagine we have two builders, Builder A and Builder B. \n\nBuilder B is also a prover.\n\nIf Builder A builds a block and it has not been committed to, ie its not chosen by the proposer. \n\nThen Builder B who is also a prover, would receive the block and decide to not create a proof, but instead propose that block themselves",
        "created_at": "2025-06-26T19:15:49.371000+00:00",
        "attachments": null
    },
    {
        "author": "bridge-bot",
        "category": "Execution Layer",
        "parent": "",
        "content": "\u003calexanderlhicks\u003e re: **@barnabemonnot**\n\u003e we're talking about censorship in the sense of not adding a non-FOCIL tx that is unfavourable in proving costs, if the tx doesn't repay at least that cost to the builder? or censorship that can be solved with FOCIL?\nCensorship in the form of rejecting to prove a valid block produced by an honest builder, idk whether a refinement of FOCIL to take into account the role of prover solves this, as it depends on how you define the idea of a valid block (per Kev's comment)?",
        "created_at": "2025-06-26T19:16:06.669000+00:00",
        "attachments": null
    },
    {
        "author": "bridge-bot",
        "category": "Execution Layer",
        "parent": "",
        "content": "\u003ckevaundray\u003e re: **@kevaundray**\n\u003e I'm not sure we could do this because if you imagine we have two builders, Builder A and Builder B. \n\nBuilder B is also a prover.\n\nIf Builder A builds a block and it has not been committed to, ie its not chosen by the proposer. \n\nThen Builder B who is also a prover, would receive the block and decide to not create a proof, but instead propose that block themselves\nI think the only way to have many tries would be if the builder and the prover combine and the builder does it on the fly -- though proof creation would need to be a lot faster I think",
        "created_at": "2025-06-26T19:17:00.553000+00:00",
        "attachments": null
    },
    {
        "author": "bridge-bot",
        "category": "Execution Layer",
        "parent": "",
        "content": "\u003calexanderlhicks\u003e re: **@kevaundray**\n\u003e I'm not sure we could do this because if you imagine we have two builders, Builder A and Builder B. \n\nBuilder B is also a prover.\n\nIf Builder A builds a block and it has not been committed to, ie its not chosen by the proposer. \n\nThen Builder B who is also a prover, would receive the block and decide to not create a proof, but instead propose that block themselves\nYeah I'm not arguing for doing it that way, just that you could define a valid block that way if you wanted (and deal with whatever ramifications ensue)",
        "created_at": "2025-06-26T19:17:09.013000+00:00",
        "attachments": null
    },
    {
        "author": "bridge-bot",
        "category": "Execution Layer",
        "parent": "",
        "content": "\u003cmratsim\u003e Time for peerPAS: Proof Availability Sampling",
        "created_at": "2025-06-26T19:17:40.215000+00:00",
        "attachments": null
    },
    {
        "author": "bridge-bot",
        "category": "Execution Layer",
        "parent": "",
        "content": "\u003calexanderlhicks\u003e re: **@kevaundray**\n\u003e I think the only way to have many tries would be if the builder and the prover combine and the builder does it on the fly -- though proof creation would need to be a lot faster I think\nThat's one reason for integrating the prover/builder role (see also dealing with prover killers, ...)",
        "created_at": "2025-06-26T19:17:43.934000+00:00",
        "attachments": null
    },
    {
        "author": "bridge-bot",
        "category": "Execution Layer",
        "parent": "",
        "content": "\u003csophiagold0\u003e re: **@mratsim**\n\u003e It's completely different hardware. Current builder is a fast single-thread machine with low-latency and fast networking.\n\nA prover currently needs a cluster.\nI‚Äôm told it costs ~$100k/month to operate a builder",
        "created_at": "2025-06-26T19:17:47.394000+00:00",
        "attachments": null
    },
    {
        "author": "bridge-bot",
        "category": "Execution Layer",
        "parent": "",
        "content": "\u003cmratsim\u003e re: **@sophiagold0**\n\u003e I‚Äôm told it costs ~$100k/month to operate a builder\nBut I expect the cost is on networking, not CPU.\n\n10G networking in the cloud is expensive for example",
        "created_at": "2025-06-26T19:18:48.526000+00:00",
        "attachments": null
    },
    {
        "author": "bridge-bot",
        "category": "Execution Layer",
        "parent": "",
        "content": "\u003ckevaundray\u003e re: **@mratsim**\n\u003e What I expect is that we will still have infra teams like bloxroute and chainbound that will optimize latency between builders, relayers, validators and now provers.\nWhat is the incentive to minimize latency here if its not on the critical path for block production? (Assuming delayed execution)",
        "created_at": "2025-06-26T19:19:07.462000+00:00",
        "attachments": null
    },
    {
        "author": "bridge-bot",
        "category": "Execution Layer",
        "parent": "",
        "content": "\u003cmratsim\u003e re: **@kevaundray**\n\u003e What is the incentive to minimize latency here if its not on the critical path for block production? (Assuming delayed execution)\neven with delayed exec you still have a deadline no?\n\nAnd penalties if you miss it?",
        "created_at": "2025-06-26T19:20:10.739000+00:00",
        "attachments": null
    },
    {
        "author": "bridge-bot",
        "category": "Execution Layer",
        "parent": "",
        "content": "\u003ckevaundray\u003e re: **@mratsim**\n\u003e Time for peerPAS: Proof Availability Sampling\nWould be great if we could sample a proof üôÇ",
        "created_at": "2025-06-26T19:20:38.885000+00:00",
        "attachments": null
    },
    {
        "author": "bridge-bot",
        "category": "Execution Layer",
        "parent": "",
        "content": "\u003ckevaundray\u003e re: **@mratsim**\n\u003e even with delayed exec you still have a deadline no?\n\nAnd penalties if you miss it?\nYep, but the latency requirements are around 6-8 seconds, or roughly  SLOT_TIME - ATTESTATION_DEADLINE",
        "created_at": "2025-06-26T19:24:42.659000+00:00",
        "attachments": null
    },
    {
        "author": "bridge-bot",
        "category": "Execution Layer",
        "parent": "",
        "content": "\u003cdeveloperuche\u003e re: **@jordibaylina**\n\u003e Do you have a concrete doubt?\n\nThe idea is just to take riscV instructions and translate the to x86 instructions. The translated instructions not only execute the code, but also generates a minimum trace, so that then you can reexecut any chunk of the code in parallel for creating the witness and generating the proofs.\nNo concrete doubt at all, was reading through the codebase but got a little confused;\n\nyou mean, there are 3 stages;\n\n1. Take RISC-V instructions and translate them to x86 instructions.\nIt reads the entire RISC-V program before running it and translates every instruction into its fastest possible equivalent in x86_64 machine code. The result is a brand-new executable file that can be run directly by the CPU, eliminating the interpretation overhead. This is the source of the immense speed gain from 150 MHz to 1.5 GHz.\n\n2. generate a minimum trace\nthe translated x86 code is engineered to produce only a \"minimal trace\" or \"summary trace.\" This trace is like a set of high-level checkpoints. It does NOT contain the state of every register after every single instruction. Instead, it contains just enough information to enable parallel processing later. this trae would include `Initial State of Each Chunk`, storage/input reads and so on.\n\n3. re-execute any chunk of the code in parallel for creating the witness\n\nThe full execution witness is obtained by re-executing this chunks of the minimal trace, using this traces, witness is obtained and proof is generated;\n\n\nThis explanations is correct right? @jordibaylina\n\n\nPlease could you point me to the crate or module performing stage 1 and 2 @anyone",
        "created_at": "2025-06-26T20:54:56.448000+00:00",
        "attachments": null
    },
    {
        "author": "bridge-bot",
        "category": "Execution Layer",
        "parent": "",
        "content": "\u003cdeveloperuche\u003e re: **@developeruche**\n\u003e No concrete doubt at all, was reading through the codebase but got a little confused;\n\nyou mean, there are 3 stages;\n\n1. Take RISC-V instructions and translate them to x86 instructions.\nIt reads the entire RISC-V program before running it and translates every instruction into its fastest possible equivalent in x86_64 machine code. The result is a brand-new executable file that can be run directly by the CPU, eliminating the interpretation overhead. This is the source of the immense speed gain from 150 MHz to 1.5 GHz.\n\n2. generate a minimum trace\nthe translated x86 code is engineered to produce only a \"minimal trace\" or \"summary trace.\" This trace is like a set of high-level checkpoints. It does NOT contain the state of every register after every single instruction. Instead, it contains just enough information to enable parallel processing later. this trae would include Initial State of Each Chunk, storage/input reads and so on.\n\n3. re-execute any chunk of the code in parallel for creating the witness\n\nThe full execution witness is obtained by re-executing this chunks of the minimal trace, using this traces, witness is obtained and proof is generated;\n\n\nThis explanations is correct right? @jordibaylina\n\n\nPlease could you point me to the crate or module performing stage 1 and 2 @anyone\n@jordibaylina would the also mean the `pil` program and `state-machine's encoding the zkVM constraints is bounded to this `Trace``. This trace having essential props of the Zisk's ISA, regs ans so on?",
        "created_at": "2025-06-26T21:00:27.491000+00:00",
        "attachments": null
    },
    {
        "author": "bridge-bot",
        "category": "Execution Layer",
        "parent": "",
        "content": "\u003cjordibaylina\u003e re: **@developeruche**\n\u003e No concrete doubt at all, was reading through the codebase but got a little confused;\n\nyou mean, there are 3 stages;\n\n1. Take RISC-V instructions and translate them to x86 instructions.\nIt reads the entire RISC-V program before running it and translates every instruction into its fastest possible equivalent in x86_64 machine code. The result is a brand-new executable file that can be run directly by the CPU, eliminating the interpretation overhead. This is the source of the immense speed gain from 150 MHz to 1.5 GHz.\n\n2. generate a minimum trace\nthe translated x86 code is engineered to produce only a \"minimal trace\" or \"summary trace.\" This trace is like a set of high-level checkpoints. It does NOT contain the state of every register after every single instruction. Instead, it contains just enough information to enable parallel processing later. this trae would include Initial State of Each Chunk, storage/input reads and so on.\n\n3. re-execute any chunk of the code in parallel for creating the witness\n\nThe full execution witness is obtained by re-executing this chunks of the minimal trace, using this traces, witness is obtained and proof is generated;\n\n\nThis explanations is correct right? @jordibaylina\n\n\nPlease could you point me to the crate or module performing stage 1 and 2 @anyone\nYes, this is correct.",
        "created_at": "2025-06-26T21:08:11.259000+00:00",
        "attachments": null
    },
    {
        "author": "bridge-bot",
        "category": "Execution Layer",
        "parent": "",
        "content": "\u003cjordibaylina\u003e re: **@developeruche**\n\u003e @jordibaylina would the also mean the pil program and state-machine's encoding the zkVM constraints is bounded to this `Trace`. This trace having essential props of the Zisk's ISA, regs ans so on?\nNo, this is not correct. May be the problem is that we are using the term trace for 2 different things. \n\nThe minimal trace are mainly the memory reads in a normal execution of the program. Every time that you do a memory read you just apppend the read value to the ‚Äúminimal trace‚Äù.  For each chunk, you also store the stete of all the registers of the processor including the PC.  Now with this minimal trace you can reexecute each chunk without memory. You just recover the state of the registers at the begining of the chunk and every time you have a memory read, you just read the value from the minimal trace.\n\nThis second time of execution, can be done in parallel, and it‚Äôs in those executions where the ‚Äúwitness‚Äù/‚Äúnormal trace‚Äù/‚Äúevaluations of the polinomials‚Äù are build.\n\nActually, the minimal trace is evaluated in each node of the cluster, and there is a deterministic algorith that knows which chunks needs to build in each node.\n\nThis is what allows us to build the proof in a super-parallel way (many nodes building the proof).\n\nThe PIL is related to the witnes/‚Äúregular trace‚Äù/polinomial evaluations that are calculated in the second stage.  The minimal trace is asolutely unrelated to PIL, it‚Äôs just a trick that allows this parallelization on the witness generation.",
        "created_at": "2025-06-26T21:21:07.163000+00:00",
        "attachments": null
    },
    {
        "author": "bridge-bot",
        "category": "Execution Layer",
        "parent": "",
        "content": "\u003cdeveloperuche\u003e re: **@jordibaylina**\n\u003e No, this is not correct. May be the problem is that we are using the term trace for 2 different things. \n\nThe minimal trace are mainly the memory reads in a normal execution of the program. Every time that you do a memory read you just apppend the read value to the ‚Äúminimal trace‚Äù.  For each chunk, you also store the stete of all the registers of the processor including the PC.  Now with this minimal trace you can reexecute each chunk without memory. You just recover the state of the registers at the begining of the chunk and every time you have a memory read, you just read the value from the minimal trace.\n\nThis second time of execution, can be done in parallel, and it‚Äôs in those executions where the ‚Äúwitness‚Äù/‚Äúnormal trace‚Äù/‚Äúevaluations of the polinomials‚Äù are build.\n\nActually, the minimal trace is evaluated in each node of the cluster, and there is a deterministic algorith that knows which chunks needs to build in each node.\n\nThis is what allows us to build the proof in a super-parallel way (many nodes building the proof).\n\nThe PIL is related to the witnes/‚Äúregular trace‚Äù/polinomial evaluations that are calculated in the second stage.  The minimal trace is asolutely unrelated to PIL, it‚Äôs just a trick that allows this parallelization on the witness generation.\nOh this is very clear now... \n\nThank you very much!",
        "created_at": "2025-06-26T21:42:14.300000+00:00",
        "attachments": null
    },
    {
        "author": "bridge-bot",
        "category": "Execution Layer",
        "parent": "",
        "content": "\u003cbarnabemonnot\u003e re: **@alexanderlhicks**\n\u003e Censorship in the form of rejecting to prove a valid block produced by an honest builder, idk whether a refinement of FOCIL to take into account the role of prover solves this, as it depends on how you define the idea of a valid block (per Kev's comment)?\nIt sounds like this reduces to making ourselves very confident that we can never output a block that only a few parties could prove, and all these few parties refuse to prove it. I discuss such a scenario in the fifth bullet of this section https://ethresear.ch/t/decoupling-throughput-from-local-building/22004#p-53517-block-production-liveness-7\n\nActually it's a case where FOCIL could hurt, in the sense that it forces more inputs to the block. The only insurance really is to set the max throughput to a level where we have the property that one prover will step in with very high confidence. This way even if FOCIL fattens the block, it will always remain provable under that property. If a proof does not come, can the block simply be reorged then?",
        "created_at": "2025-06-26T22:33:32.238000+00:00",
        "attachments": null
    },
    {
        "author": "bridge-bot",
        "category": "Execution Layer",
        "parent": "",
        "content": "\u003calexanderlhicks\u003e re: **@barnabemonnot**\n\u003e It sounds like this reduces to making ourselves very confident that we can never output a block that only a few parties could prove, and all these few parties refuse to prove it. I discuss such a scenario in the fifth bullet of this section https://ethresear.ch/t/decoupling-throughput-from-local-building/22004#p-53517-block-production-liveness-7\n\nActually it's a case where FOCIL could hurt, in the sense that it forces more inputs to the block. The only insurance really is to set the max throughput to a level where we have the property that one prover will step in with very high confidence. This way even if FOCIL fattens the block, it will always remain provable under that property. If a proof does not come, can the block simply be reorged then?\nYes, the point I was trying to make at the start of this thread was basically this: although soundness bugs are what everyone thinks of with respect to zkVM security, issues with the witness generator or prover (intended or not) also matter once you consider integrating zkVMs into a system like the L1, so we shouldn't only care about soundness. Whilst we can formally verify circuits/verifiers, we're very unlikely to verify GPU provers, for example, so we need to deal with the case that a bug happens with probability p that prevents even an honest prover from proving an otherwise valid block.\nAs you put it: \"We should ensure that this reliance is as wide as possible, i.e., that there always exists a builder ready to deliver this block. This is not the case if we can find ourselves in a situation where only super computer-sized nodes are able to deliver, for some reason, but this can be easily mitigated by setting a network throughput limit to a level that guarantees a wide enough market, even if this limit exceeds the capabilities of local builders.\" Currently, however, we shouldn't assume that we can fall back on local provers, even w \u003cclipped message\u003e",
        "created_at": "2025-06-26T23:00:51.104000+00:00",
        "attachments": null
    },
    {
        "author": "bridge-bot",
        "category": "Execution Layer",
        "parent": "",
        "content": "\u003calexanderlhicks\u003e re: **@barnabemonnot**\n\u003e It sounds like this reduces to making ourselves very confident that we can never output a block that only a few parties could prove, and all these few parties refuse to prove it. I discuss such a scenario in the fifth bullet of this section https://ethresear.ch/t/decoupling-throughput-from-local-building/22004#p-53517-block-production-liveness-7\n\nActually it's a case where FOCIL could hurt, in the sense that it forces more inputs to the block. The only insurance really is to set the max throughput to a level where we have the property that one prover will step in with very high confidence. This way even if FOCIL fattens the block, it will always remain provable under that property. If a proof does not come, can the block simply be reorged then?\nI don't think the analogy makes sense here: the likelihood of being unable to prove a block does not depend on its size* (assuming you aren't running out of time, but this is better acknowledged and being dealt with via opcode repricing, single transaction size cap, ...), and assuming a bug rather than malicious prover, ignorance of the bug means being unable to filter out inputs that would trigger it.\n\n* bigger size =\u003e larger input space of course, but it's not the only factor",
        "created_at": "2025-06-26T23:03:31.972000+00:00",
        "attachments": null
    },
    {
        "author": "bridge-bot",
        "category": "Execution Layer",
        "parent": "",
        "content": "\u003calexanderlhicks\u003e re: **@barnabemonnot**\n\u003e It sounds like this reduces to making ourselves very confident that we can never output a block that only a few parties could prove, and all these few parties refuse to prove it. I discuss such a scenario in the fifth bullet of this section https://ethresear.ch/t/decoupling-throughput-from-local-building/22004#p-53517-block-production-liveness-7\n\nActually it's a case where FOCIL could hurt, in the sense that it forces more inputs to the block. The only insurance really is to set the max throughput to a level where we have the property that one prover will step in with very high confidence. This way even if FOCIL fattens the block, it will always remain provable under that property. If a proof does not come, can the block simply be reorged then?\nOnce proving is strictly required, would a block that has not been proven be part of the chain such that it could be reorged?",
        "created_at": "2025-06-26T23:08:22.671000+00:00",
        "attachments": null
    },
    {
        "author": "bridge-bot",
        "category": "Execution Layer",
        "parent": "",
        "content": "\u003csophiagold0\u003e re: **@alexanderlhicks**\n\u003e Yes, the point I was trying to make at the start of this thread was basically this: although soundness bugs are what everyone thinks of with respect to zkVM security, issues with the witness generator or prover (intended or not) also matter once you consider integrating zkVMs into a system like the L1, so we shouldn't only care about soundness. Whilst we can formally verify circuits/verifiers, we're very unlikely to verify GPU provers, for example, so we need to deal with the case that a bug happens with probability p that prevents even an honest prover from proving an otherwise valid block.\nAs you put it: \"We should ensure that this reliance is as wide as possible, i.e., that there always exists a builder ready to deliver this block. This is not the case if we can find ourselves in a situation where only super computer-sized nodes are able to deliver, for some reason, but this can be easily mitigated by setting a network throughput limit to a level that guarantees a wide enough market, even if this limit exceeds the capabilities of local builders.\" Currently, however, we shouldn't assume that we can fall back on local provers, even with the current throughput limit, until proving costs come down another 10x or more, and one reason to use zkVMs is to increase the throughput limit so proving time will likely always take up about as much time as possible unless we explicitly add a buffer. This will particularly be true early on, which is also when software will be less tested and more likely to contain bugs.\nI think we are assuming from the start that some of the types of people doing local building now will be doing local proving. That‚Äôs why we‚Äôre targeting 10kW",
        "created_at": "2025-06-26T23:29:41.302000+00:00",
        "attachments": null
    },
    {
        "author": "bridge-bot",
        "category": "Execution Layer",
        "parent": "",
        "content": "\u003calexanderlhicks\u003e re: **@sophiagold0**\n\u003e I think we are assuming from the start that some of the types of people doing local building now will be doing local proving. That‚Äôs why we‚Äôre targeting 10kW\nBut they'll be running the same prover (or one out of 3-4 provers that may share libraries), right?",
        "created_at": "2025-06-26T23:46:29.797000+00:00",
        "attachments": null
    },
    {
        "author": "bridge-bot",
        "category": "Execution Layer",
        "parent": "",
        "content": "\u003csophiagold0\u003e Yes, right",
        "created_at": "2025-06-26T23:46:54.069000+00:00",
        "attachments": null
    }
]