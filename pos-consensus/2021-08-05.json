[
    {
        "author": "dapplion",
        "category": "Consensus R\u0026D",
        "parent": "",
        "content": "Very late for altair design but we are experiencing a bit of performance issues compared to phase0 regarding hashing of state.balances.\n\nAccording to numerical tests for a network with 200_000 validators and a committee size of 512, we have to compute ~4000 hashes every slot. Re-hashing the entire tree costs about 100000 hashes. So, through the epoch then we'll have to compute 4000*32 = 128000, so a bit more than rehashing the entire tree. In phase0 with regular network conditions, state.balances may only change when validators join are or slashed, both rare events.",
        "created_at": "2021-08-05T09:09:51.490000+00:00",
        "attachments": []
    },
    {
        "author": "dapplion",
        "category": "Consensus R\u0026D",
        "parent": "",
        "content": "Probably not a great solution, but if we wanted to add a key to the state `state.syncCommitteeBalanceDeltas` with Gwei and max size 512, to be latter added into balances at the epoch transition, that would be 256 hashes per slot. 1 - 256 / 4000 = 93.6% reduction in hashing\nCC \u003c@!203220829473996800\u003e",
        "created_at": "2021-08-05T09:14:56.825000+00:00",
        "attachments": []
    },
    {
        "author": "protolambda",
        "category": "Consensus R\u0026D",
        "parent": "",
        "content": "~~You mean 92% left of hashing, 8% reduction per slot~~",
        "created_at": "2021-08-05T09:18:29.628000+00:00",
        "attachments": []
    },
    {
        "author": "potuz",
        "category": "Consensus R\u0026D",
        "parent": "",
        "content": "no, he really meant 92% reduction.",
        "created_at": "2021-08-05T10:16:17.478000+00:00",
        "attachments": []
    },
    {
        "author": "potuz",
        "category": "Consensus R\u0026D",
        "parent": "",
        "content": "it's about 92,58%",
        "created_at": "2021-08-05T10:17:30.419000+00:00",
        "attachments": []
    },
    {
        "author": "protolambda",
        "category": "Consensus R\u0026D",
        "parent": "",
        "content": "Oh nice, that's unexpected, may be worth the change then",
        "created_at": "2021-08-05T10:18:42.337000+00:00",
        "attachments": []
    },
    {
        "author": "potuz",
        "category": "Consensus R\u0026D",
        "parent": "",
        "content": "not to brag, but you should be looking at the issue of hardcoding the padding block which will give you 40% reduction until this is implemented",
        "created_at": "2021-08-05T10:19:44.599000+00:00",
        "attachments": []
    },
    {
        "author": "potuz",
        "category": "Consensus R\u0026D",
        "parent": "",
        "content": "\u003c@!688748669268132001\u003e",
        "created_at": "2021-08-05T10:20:08.009000+00:00",
        "attachments": []
    },
    {
        "author": "protolambda",
        "category": "Consensus R\u0026D",
        "parent": "",
        "content": "He's aware, definitely a good optimization, although not a reason to leave the spec slower than it could be",
        "created_at": "2021-08-05T10:20:49.115000+00:00",
        "attachments": []
    },
    {
        "author": "potuz",
        "category": "Consensus R\u0026D",
        "parent": "",
        "content": "Oh yes this looks like something that can actually get in time for Altair",
        "created_at": "2021-08-05T10:21:08.147000+00:00",
        "attachments": []
    },
    {
        "author": "potuz",
        "category": "Consensus R\u0026D",
        "parent": "",
        "content": "redoing all tests will be painful though",
        "created_at": "2021-08-05T10:21:20.040000+00:00",
        "attachments": []
    },
    {
        "author": "dapplion",
        "category": "Consensus R\u0026D",
        "parent": "",
        "content": "We have already implemented this, def a good improvement üëç",
        "created_at": "2021-08-05T10:43:35.967000+00:00",
        "attachments": []
    },
    {
        "author": "potuz",
        "category": "Consensus R\u0026D",
        "parent": "",
        "content": "oh that's great to hear, could I bug you to point me to the implementation and how to benchmark it? I'm collecting benchmarks. Originally I came to this to figure out if my implementation of the Merkle part was pretty bad. It turned out that the hashing algo was so much of a difference that I couldn't really infer anything about my implementation. If  you already have the same hashing algo, then I could benchmark my implementation against yours to see if I am too far behind.",
        "created_at": "2021-08-05T10:45:53.716000+00:00",
        "attachments": []
    },
    {
        "author": "dapplion",
        "category": "Consensus R\u0026D",
        "parent": "",
        "content": "Sure! This is the PR that implemented it https://github.com/ChainSafe/as-sha256/pull/51 it did not yield 40% perf improvement, different env registered 5-20%",
        "created_at": "2021-08-05T10:47:57.748000+00:00",
        "attachments": []
    },
    {
        "author": "potuz",
        "category": "Consensus R\u0026D",
        "parent": "",
        "content": "Thanks, it's weird that those constants are not the same I have though, I wonder if you are only including the W words there and thus not really saving the addition W + K.",
        "created_at": "2021-08-05T10:53:30.279000+00:00",
        "attachments": []
    },
    {
        "author": "potuz",
        "category": "Consensus R\u0026D",
        "parent": "",
        "content": "that assembly there is just too weird for me to read üôÇ",
        "created_at": "2021-08-05T10:53:52.319000+00:00",
        "attachments": []
    },
    {
        "author": "potuz",
        "category": "Consensus R\u0026D",
        "parent": "",
        "content": "Ah yeah \u003c@688748669268132001\u003e my reading of that code is that you are applying the same algorithm you had for the full block, just that you are using precomputed scheduled words. You can confirm this with the PR writer, but this is not the best you can do as at the very least there's an addition that you should not be making (namely the addition of the K constants in the SHA algo). The constants that you should be using are these: https://github.com/potuz/mammon/blob/main/ssz/sha256_shani.asm#L1000",
        "created_at": "2021-08-05T11:30:10.671000+00:00",
        "attachments": []
    },
    {
        "author": "dapplion",
        "category": "Consensus R\u0026D",
        "parent": "",
        "content": "Thanks for taking a look! Will review def we want to use the best approach possible",
        "created_at": "2021-08-05T11:37:31.694000+00:00",
        "attachments": []
    },
    {
        "author": "dapplion",
        "category": "Consensus R\u0026D",
        "parent": "",
        "content": "\u003c@!792822129019584562\u003e Please take a look, we can do even better on your as-sha256 optimization",
        "created_at": "2021-08-05T11:38:28.917000+00:00",
        "attachments": []
    },
    {
        "author": "potuz",
        "category": "Consensus R\u0026D",
        "parent": "",
        "content": "In any case I would be very very surprised doing any implementation that the benefits are less than 30%, I mean you are avoiding all computations except the few rounds in half of the message. I did not find less than 40% in all the CPUs I tried, and in all implementations I tried (SSE, AVX, AVX2 and SHA)",
        "created_at": "2021-08-05T11:39:40.401000+00:00",
        "attachments": []
    },
    {
        "author": "g11tech",
        "category": "Consensus R\u0026D",
        "parent": "",
        "content": "Tuyen's uint8 optimization has already squeezed 30% out of it and my guess is that the variance in the performances that we see might be because of the memory management performance on the individual machines",
        "created_at": "2021-08-05T11:48:00.352000+00:00",
        "attachments": []
    },
    {
        "author": "g11tech",
        "category": "Consensus R\u0026D",
        "parent": "",
        "content": "Our current optimization saves W for second block, but all in all I think that is 20% of the computation. So on some machines we did saw 20% performance",
        "created_at": "2021-08-05T11:53:18.809000+00:00",
        "attachments": []
    },
    {
        "author": "g11tech",
        "category": "Consensus R\u0026D",
        "parent": "",
        "content": "Because that W is again mixed with the previous blocks hash result to get the final hash",
        "created_at": "2021-08-05T11:54:09.955000+00:00",
        "attachments": []
    },
    {
        "author": "potuz",
        "category": "Consensus R\u0026D",
        "parent": "",
        "content": "yes, but you don't really need W, W only enters as W+K",
        "created_at": "2021-08-05T11:54:35.556000+00:00",
        "attachments": []
    },
    {
        "author": "potuz",
        "category": "Consensus R\u0026D",
        "parent": "",
        "content": "so you need to save W+K to save an addition and a memory lookup",
        "created_at": "2021-08-05T11:54:50.812000+00:00",
        "attachments": []
    },
    {
        "author": "g11tech",
        "category": "Consensus R\u0026D",
        "parent": "",
        "content": "Ummm let me have a look and come back on this.",
        "created_at": "2021-08-05T11:55:33.209000+00:00",
        "attachments": []
    },
    {
        "author": "nishant0",
        "category": "Consensus R\u0026D",
        "parent": "",
        "content": "Where are you getting the number 3450 from ?",
        "created_at": "2021-08-05T12:00:08.419000+00:00",
        "attachments": []
    },
    {
        "author": "dapplion",
        "category": "Consensus R\u0026D",
        "parent": "",
        "content": "Numerically with random indexes https://gist.github.com/dapplion/1d354becbd65f9db1b213a8ebe7653d7",
        "created_at": "2021-08-05T12:06:04.216000+00:00",
        "attachments": []
    },
    {
        "author": "dapplion",
        "category": "Consensus R\u0026D",
        "parent": "",
        "content": "I have a one-off typo, not including the leaf nodes. Then the number is ~4000",
        "created_at": "2021-08-05T12:11:51.288000+00:00",
        "attachments": []
    },
    {
        "author": "g11tech",
        "category": "Consensus R\u0026D",
        "parent": "",
        "content": "yea, W64 +K can be saved as new W64. not sure, how much perf gain it would do but worth trying! \u003c@!688748669268132001\u003e",
        "created_at": "2021-08-05T12:14:15.610000+00:00",
        "attachments": []
    },
    {
        "author": "nishant0",
        "category": "Consensus R\u0026D",
        "parent": "",
        "content": "Thanks for linking this, it also matches up with my mental math.\n2 ^ 9 + 2 ^ 8 + 2 ^ 7 .... = 1023 \n512 * 6 = 3072\nTogether it would also be roughly 4100 hashes per block. \n\nSome counter points \n- In the larger scheme of things 4000 hashes per slot isnt that much. \n- The beacon node does hashing of a lot of larger objects from gossip too in general.\n- This change permanently makes the state bigger, increasing the general storage costs of historical data.\n- Pyrmont's Altair fork will have to be pushed back further for this, and we would probably need a new devnet. \n- Also having a last minute change like this for a non security related issue might be setting the wrong precedent",
        "created_at": "2021-08-05T13:18:23.658000+00:00",
        "attachments": []
    },
    {
        "author": "dapplion",
        "category": "Consensus R\u0026D",
        "parent": "",
        "content": "Agree that the tradeoff is significant, and this would include data in the state that's technically redundant",
        "created_at": "2021-08-05T14:02:25.681000+00:00",
        "attachments": []
    }
]