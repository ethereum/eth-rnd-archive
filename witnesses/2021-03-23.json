[
    {
        "author": "sandra_johnson",
        "category": "Execution R\u0026D",
        "parent": "",
        "content": "Where could I find an estimate of the \"compression efficacy\" of the various approaches that have been proposed to reduce the size of witnesses? Even a range of say 10%-14% for one approach and 25% - 40% for another, or any vague indication of expected compression for various techniques would be awesome. If there are several approaches, e.g. binary trees, verkle trees/kate commitments, code merkelization .. any others? What is the expected reduction in witness size? Would people be using only one technique or more than one?",
        "created_at": "2021-03-23T05:07:57.321000+00:00",
        "attachments": null
    },
    {
        "author": "sandra_johnson",
        "category": "Execution R\u0026D",
        "parent": "",
        "content": "Another aspect I would appreciate some guidance on, is the expected computation effort for the various approaches. Even if it is just a ranking of which would take more time, or a % increase, or some way of getting a handle on \"computation effort\". The reason I am asking these questions is that I am using these two factors to supplement a Bayesian network model we have been developing for Stateless Ethereum, to include these type of qualitative factors alongside the quantitative factors.",
        "created_at": "2021-03-23T05:13:46.282000+00:00",
        "attachments": null
    },
    {
        "author": "sandra_johnson",
        "category": "Execution R\u0026D",
        "parent": "",
        "content": "\u003c@!555483069038198827\u003e \u003c@!353136597522448385\u003e Do you know if there are witness creation times available based on the current witness spec? Especially implementation of the various witness compression techniques, e.g. code merkleization, binary tree, verkle tree in terms of the reduction in witness size and witness creation times?",
        "created_at": "2021-03-23T21:47:25.893000+00:00",
        "attachments": null
    },
    {
        "author": ".vbuterin",
        "category": "Execution R\u0026D",
        "parent": "",
        "content": "We have numbers for Verkle trees \"in theory\":\n\nReading (prover time): 5000 reads = size-20000 Kate multiproof = size-20000 fast linear combination ~= 3000 ECMULs\nWriting (prover time): 2500 updates -\u003e 10000 polynomial commitment updates = 10000 EC-multiplications with a precomputed factor ~= 2000 ECMULs",
        "created_at": "2021-03-23T22:19:59.547000+00:00",
        "attachments": null
    },
    {
        "author": ".vbuterin",
        "category": "Execution R\u0026D",
        "parent": "",
        "content": "I think it was in the low seconds with a basic implementation but there's still a lot to optimize",
        "created_at": "2021-03-23T22:20:19.477000+00:00",
        "attachments": null
    },
    {
        "author": ".vbuterin",
        "category": "Execution R\u0026D",
        "parent": "",
        "content": "For a STARKed binary tree, I think the numbers are that a size-5000 witness would take ~100000 hashes which would take 10s to prove on a GPU",
        "created_at": "2021-03-23T22:20:51.226000+00:00",
        "attachments": null
    },
    {
        "author": ".vbuterin",
        "category": "Execution R\u0026D",
        "parent": "",
        "content": "Regular binary trees are not really under consideration because the witness sizes are too large compared to the other options",
        "created_at": "2021-03-23T22:23:26.291000+00:00",
        "attachments": null
    },
    {
        "author": ".vbuterin",
        "category": "Execution R\u0026D",
        "parent": "",
        "content": "As far as witness sizes go, for Verkle trees, the theoretical max is ~800 kB, and for a STARKed binary tree it's like 400 kB",
        "created_at": "2021-03-23T22:23:49.853000+00:00",
        "attachments": null
    },
    {
        "author": ".vbuterin",
        "category": "Execution R\u0026D",
        "parent": "",
        "content": "So in both cases, the theoretical max witness size is not larger than the theoretical max calldata, so either is fine",
        "created_at": "2021-03-23T22:24:09.803000+00:00",
        "attachments": null
    },
    {
        "author": ".vbuterin",
        "category": "Execution R\u0026D",
        "parent": "",
        "content": "Whereas with binary trees it goes up to like 4 MB",
        "created_at": "2021-03-23T22:24:16.603000+00:00",
        "attachments": null
    }
]