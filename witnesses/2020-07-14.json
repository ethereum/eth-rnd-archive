[
    {
        "author": "mandrigin",
        "category": "Execution R\u0026D",
        "parent": "",
        "content": "Okay, so here is my research on key-value witness format: https://medium.com/@mandrigin/kv-witness-8985168537f9?sk=5c832a497fd38f48cff9236126b53d24",
        "created_at": "2020-07-14T16:13:02.111000+00:00",
        "attachments": []
    },
    {
        "author": "pauld.9606",
        "category": "Execution R\u0026D",
        "parent": "",
        "content": "\u003c@!520564582196969472\u003e  great job. We are impressed that you can run such big experiments so quickly.",
        "created_at": "2020-07-14T23:48:16.798000+00:00",
        "attachments": []
    },
    {
        "author": "pauld.9606",
        "category": "Execution R\u0026D",
        "parent": "",
        "content": "Some feedback.",
        "created_at": "2020-07-14T23:48:27.166000+00:00",
        "attachments": []
    },
    {
        "author": "pauld.9606",
        "category": "Execution R\u0026D",
        "parent": "",
        "content": "1) I suspect that the proposed kv witness encoding is less size efficient than the current witness spec. This is because the proposed kv witness (as well as the article's \"opcode witness\", which is different from the current witness spec) requires 34 (or more?) bytes per hash node. On the other hand, the current spec requires 33 bytes per hash node (this can be improved by adding some complexity). And hash nodes are the biggest bottleneck. The situation is similar for the rest of the encoding, where there is also more overhead.\n\n\u003c@!520564582196969472\u003e are you convinced by this ^ hand-wavy overhead analysis? Do you think that we should compare witnesses side-by-side, say for specific ethereum block numbers? Or is this just an iteration that doesn't need comparison yet?",
        "created_at": "2020-07-14T23:52:52.877000+00:00",
        "attachments": []
    }
]