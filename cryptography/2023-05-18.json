[
    {
        "author": "paulmillr",
        "category": "Execution R\u0026D",
        "parent": "",
        "content": "\u003c@570268431522201601\u003e how’s the msm perf?",
        "created_at": "2023-05-18T05:53:18.723000+00:00",
        "attachments": null
    },
    {
        "author": "mratsim",
        "category": "Execution R\u0026D",
        "parent": "",
        "content": "with 256-bit integers in the EVM? Mmmh not really",
        "created_at": "2023-05-18T16:08:23.588000+00:00",
        "attachments": null
    },
    {
        "author": "mratsim",
        "category": "Execution R\u0026D",
        "parent": "",
        "content": "Faster than any other library out there: BLST, Barrentenberg, Arkworks, Bellman, ...\n\nOnly Gnark can reach similar speed (but 10% slower on the number of cores I benched).\n\n- SIngle-threaded benches: https://github.com/mratsim/constantine/pull/220\n- Multi-threaded on 8 cores: https://github.com/mratsim/constantine/pull/226#issuecomment-1505143179\n- Multi-threaded in 18 cores: https://github.com/mratsim/constantine/pull/227#issuecomment-1508372663\n\nNote that the Gnark team has been tuning on 96 cores and I don't have such a machine so I may be slower on very large core counts.",
        "created_at": "2023-05-18T16:11:19.630000+00:00",
        "attachments": null
    },
    {
        "author": "chfast",
        "category": "Execution R\u0026D",
        "parent": "",
        "content": "No, just x86-64 asm.",
        "created_at": "2023-05-18T16:32:16.865000+00:00",
        "attachments": null
    },
    {
        "author": "chfast",
        "category": "Execution R\u0026D",
        "parent": "",
        "content": "Or whatever is the fastest currently on x86-64.",
        "created_at": "2023-05-18T16:32:40.252000+00:00",
        "attachments": null
    },
    {
        "author": "mratsim",
        "category": "Execution R\u0026D",
        "parent": "",
        "content": "There is an optimization when you use at most 255 bits out of the 256 bits, it would work for BN254, it's 15% faster by saving some carries, or do you want the generic one?",
        "created_at": "2023-05-18T16:35:41.441000+00:00",
        "attachments": null
    },
    {
        "author": "mratsim",
        "category": "Execution R\u0026D",
        "parent": "",
        "content": "with the optim, this is the fastest: https://github.com/mratsim/constantine/blob/master/constantine/math/arithmetic/assembly/limbs_asm_mul_mont_x86_adx_bmi2.nim#L231-L240",
        "created_at": "2023-05-18T16:37:08.828000+00:00",
        "attachments": null
    },
    {
        "author": "mratsim",
        "category": "Execution R\u0026D",
        "parent": "",
        "content": "I don't have asm without the optim because all pairing curves (BN254, BLS12-381) have spare bits, unlike secp256k1 for example",
        "created_at": "2023-05-18T16:38:35.611000+00:00",
        "attachments": null
    },
    {
        "author": "mratsim",
        "category": "Execution R\u0026D",
        "parent": "",
        "content": "For generic one, here you go: https://github.com/mratsim/constantine/blob/master/constantine/math/arithmetic/limbs_montgomery.nim#L215-L305\n\nFIPS is faster than CIOS (unless you use MULX/ADOX/ADCX)",
        "created_at": "2023-05-18T16:41:15.627000+00:00",
        "attachments": null
    },
    {
        "author": "mratsim",
        "category": "Execution R\u0026D",
        "parent": "",
        "content": "\u003c@774033563732541451\u003e \u003c@750602516613431366\u003e I'm reading this https://ihagopian.com/posts/tonelli-shanks-with-precomputed-dlog-tables\n\nHave you tried https://eprint.iacr.org/2020/1407.pdf\n`Computing Square Roots Faster than the Tonelli-Shanks/Bernstein\nAlgorithm`",
        "created_at": "2023-05-18T16:57:14.983000+00:00",
        "attachments": null
    },
    {
        "author": "jsign",
        "category": "Execution R\u0026D",
        "parent": "",
        "content": "I'll defer having a good answer to that to \u003c@750602516613431366\u003e  or \u003c@761645159095599144\u003e . I basically reverse engineered how the idea work by reading \u003c@761645159095599144\u003e original implementation, so I might not have the exact reference of the paper the idea is based.\n\nI remember reading a chat between \u003c@750602516613431366\u003e  and \u003c@761645159095599144\u003e  about that particular paper, and _I think_ wouldn't improve the performance that much for the Bandersnatch case at least. But don't take my word... probably they can confirm!",
        "created_at": "2023-05-18T17:13:28.459000+00:00",
        "attachments": null
    },
    {
        "author": "chfast",
        "category": "Execution R\u0026D",
        "parent": "",
        "content": "Does the \"sparse\" mean the top bit is unused? We can use non-generic impl because EVMMAX can pick different implementation on modulus param.",
        "created_at": "2023-05-18T17:15:56.529000+00:00",
        "attachments": null
    },
    {
        "author": "chfast",
        "category": "Execution R\u0026D",
        "parent": "",
        "content": "We can use ADOX. I want to make a performance baseline (how fast we can go with the best montgomery multiplication and very simple EVMMAX-like API)",
        "created_at": "2023-05-18T17:19:28.299000+00:00",
        "attachments": null
    },
    {
        "author": "mratsim",
        "category": "Execution R\u0026D",
        "parent": "",
        "content": "spare, yes",
        "created_at": "2023-05-18T17:24:05.306000+00:00",
        "attachments": null
    },
    {
        "author": "chfast",
        "category": "Execution R\u0026D",
        "parent": "",
        "content": "Is this nim code direct implementation or it generates asm code?",
        "created_at": "2023-05-18T17:33:48.865000+00:00",
        "attachments": null
    },
    {
        "author": "jsign",
        "category": "Execution R\u0026D",
        "parent": "",
        "content": "\u003c@570268431522201601\u003e , very interesting work https://github.com/mratsim/constantine \nDo you have an idea how much performance (and where) is left on the table due to the design decision of having constant-time algorithms?",
        "created_at": "2023-05-18T17:39:22.260000+00:00",
        "attachments": null
    },
    {
        "author": "paulmillr",
        "category": "Execution R\u0026D",
        "parent": "",
        "content": "That’s great. Which batch size is going to be used in eth? 128?",
        "created_at": "2023-05-18T18:36:27.737000+00:00",
        "attachments": null
    }
]