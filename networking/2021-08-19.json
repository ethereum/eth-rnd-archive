[
    {
        "author": "agemanning",
        "category": "Consensus Layer",
        "parent": "",
        "content": "\u003c@!825130769902731284\u003e - I think you may be missing duplicate filtering. \nIn order to spam gossipsub, you cannot send the same message many times. Doing so will just get filtered (if we have seen it before) without any extensive processing. If you want to send mesages with slight modifications, most of the time the messages are signed and you'd need to be a valid validator to have a valid signature of the modified message. If you give bad signatures, you'll get kicked, if you are a validator and you provide valid signatures but your messages are junk, you'll also get kicked. \n\nDo you have a specific example of what messages you would be spamming? If they are non-unique they will get filtered. Perhaps a specific example of which messages you are spamming, i could help pinpoint the exact rules which may handle it.",
        "created_at": "2021-08-19T05:52:52.151000+00:00",
        "attachments": []
    },
    {
        "author": "agemanning",
        "category": "Consensus Layer",
        "parent": "",
        "content": "The gossipsub scoring parameters have been proposed amongst clients, but ultimately each client will tweak and modify their parameters based on the network. We are currently re-adjusting ours as we see some changes in the network behaviour with higher validator counts",
        "created_at": "2021-08-19T05:54:19.333000+00:00",
        "attachments": []
    },
    {
        "author": "bd_0",
        "category": "Consensus Layer",
        "parent": "",
        "content": "\u003c@!498009160982724610\u003e thanks for the detailed reply. I am not concerned about the duplicates as as you mention those are filtered out, but junk messages with slight modifications in the scenario where the message producer is an active validator (thus the messages are signed properly). Could you explain the \"kicking\" part in more details? \n\nMy concern is what happens if a lot of active validators (let's assume coordination) start producing unique messages which are signed properly, but when 'Extended Validator' logic is applied for their processing they result in IGNORE (as specified here: https://github.com/ethereum/consensus-specs/blob/master/specs/phase0/p2p-interface.md#the-gossip-domain-gossipsub). So the messages are being flagged as IGNORE on gossipsub level, thus they are not propagated on higher level and the consensus rules for slashing are not triggered.\nAs an example, let's say the topic is `beacon_block` (global topic) and the message is containing a block from a future slot, but every time the block is different (thus message is unique). \nIs there a mechanism to kick out such validators, and is this a concern for network congestion? This is purely at gossipsub network level.\nBasically what is blurry for me is what is the protection against such validators.\n\nLet's ignore the questions if this is a reasonable attack from game theory perspective and why would someone do this, but view this purely from a practical feasibility perspective.\n\nAlso don't you think there should be more details about the gossipsub peer scoring params on the spec level (at least some reasonable defaults)? Maybe just for the purposes to give more context and their purpose.",
        "created_at": "2021-08-19T12:21:59.522000+00:00",
        "attachments": []
    },
    {
        "author": "bd_0",
        "category": "Consensus Layer",
        "parent": "",
        "content": "Also are the spam protection measures offered by gossipsub-v1.1 enough for the eth2 network or more robust spam measures are needed? The peer scoring that gossipsub-v1.1 provides is local (each peer manages it's own scoring list which is not shared)",
        "created_at": "2021-08-19T12:25:30.834000+00:00",
        "attachments": []
    },
    {
        "author": "arnetheduck",
        "category": "Consensus Layer",
        "parent": "",
        "content": "you can, to a certain extent, craft messages that are unique and spam these to your neighbours - but you cannot really do much more - the cost to you is about equal to the cost for the rest of the network - you do not even have to be a validator to do this kind of spamming (the signature check confirming that you're a validator is done last because it's generally the most expensive one), but the important point to understand is that you need to spend an equal amount of sending bandwidth as the amount of \"damage\" you can cause - there's no amplification factor to exploit (per IGNORE)",
        "created_at": "2021-08-19T14:06:01.160000+00:00",
        "attachments": []
    },
    {
        "author": "arnetheduck",
        "category": "Consensus Layer",
        "parent": "",
        "content": "\u003e As an example, let's say the topic is beacon_block (global topic) and the message is containing a block from a future slot, but every time the block is different (thus message is unique). \nspecifically to this example, a block with a future slot will be ignored - the only thing you've accomplished is that you've wasted a bit of bandwidth sending the block data to someone else causing them to throw it away and ignore it - \"the network\" as a whole will never see it.",
        "created_at": "2021-08-19T14:10:48.137000+00:00",
        "attachments": []
    },
    {
        "author": "bd_0",
        "category": "Consensus Layer",
        "parent": "",
        "content": "thanks for the response, but I guess the amplification comes in when group of validators coordinate (again not implying if it is profitable or any specific reasons), obviously just sending messages as a single peer to the local peers doesn't mean anything",
        "created_at": "2021-08-19T21:02:36.798000+00:00",
        "attachments": []
    }
]