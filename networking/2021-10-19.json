[
    {
        "author": "nashatyrev",
        "category": "Consensus Layer",
        "parent": "",
        "content": "On merge event we hit the issue when Teku was regularly disconnecting Lodestar due to exceeding block request rate limit. \nIn chat with \u003c@!688748669268132001\u003e we found out that there are no any limits settled in the spec and each client limits inbound/outbound requests (or does not limit at all) according to its internal options.\n\nFrom my perspective it makes sense adding ReqResp rate limiting rules to the networking spec.",
        "created_at": "2021-10-19T14:35:14.478000+00:00",
        "attachments": []
    },
    {
        "author": "nashatyrev",
        "category": "Consensus Layer",
        "parent": "",
        "content": "However instead of hardcoding rate limits I would suggest to add a ReqResp error code `RateLimitExceeded` which would allow more flexible traffic limiting. I.e. a serving node could dynamically limit the traffic according to it's current load while a requesting node may dynamically adopt its request rate without a risk of being disconnected and downscored",
        "created_at": "2021-10-19T14:41:14.610000+00:00",
        "attachments": []
    },
    {
        "author": "nashatyrev",
        "category": "Consensus Layer",
        "parent": "",
        "content": "That approach could also be helpful for small networks when a number of peers low, but they could serve requests at higher rates. E.g. due to Teku conservative rate limits a test net with just 2 nodes syncs very slowly",
        "created_at": "2021-10-19T14:44:44.380000+00:00",
        "attachments": []
    },
    {
        "author": "nashatyrev",
        "category": "Consensus Layer",
        "parent": "",
        "content": "There are possible options of how `RateLimitExceeded` could work:\n- either per ReqResp message type or globally across all types. I would prefer the first option here since e.g. ping/metadata messages are expected to be less frequent than e.g. block requests\n- error message may contain a cool down time period after which messages could be sent again (I've seen a couple of stock exchange trading protocols which utilize this option)\n- If `RateLimitExceeded` errors are ignored by the requesting side (e.g. \u003e `N` errors were sent during some time frame) then the peer could be disconnected and downscored",
        "created_at": "2021-10-19T14:56:13.338000+00:00",
        "attachments": []
    },
    {
        "author": "nashatyrev",
        "category": "Consensus Layer",
        "parent": "",
        "content": "A different possible option for rate limiting is the maximum number of concurrent requests. \nE.g. if this number is `1`  then requester must not send a new request until receives response to the previous one (I believe this is how RLPx works)",
        "created_at": "2021-10-19T15:05:59.120000+00:00",
        "attachments": []
    }
]