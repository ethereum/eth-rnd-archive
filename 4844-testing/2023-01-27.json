[
    {
        "author": "acolytec3",
        "category": "Channel Graveyard",
        "parent": "",
        "content": "hmm, I guess I see what you're saying but when it comes to the \"total cost\" of the transaction, the data gas paid (data gas * blobs in txn * data gas fee for the block) is included there but not reported in the receipt so there's no simple way to derive a total balance change/state transition for the sending account based on just the transaction and transaction receipt now , unless I'm not thinking clearly here.  I don't know that it's mission critical for 4844 but seems like a missing data point that takes a fair amount of legwork to identify",
        "created_at": "2023-01-27T02:19:10.258000+00:00",
        "attachments": null
    },
    {
        "author": "inphi",
        "category": "Channel Graveyard",
        "parent": "",
        "content": "Blobscan/xplorer is up - https://blobscan.eip4844-devnet-4.ethpandaops.io/",
        "created_at": "2023-01-27T08:39:05.737000+00:00",
        "attachments": null
    },
    {
        "author": "inphi",
        "category": "Channel Graveyard",
        "parent": "",
        "content": "This is the way to go. Though computing this introduces an additional lookup for the parent header. But maybe we should add a new `includeExcessDataGas` param to the JSON-RPC control this.",
        "created_at": "2023-01-27T08:42:10.789000+00:00",
        "attachments": null
    },
    {
        "author": "__flcl",
        "category": "Channel Graveyard",
        "parent": "",
        "content": "Blobscan",
        "created_at": "2023-01-27T08:59:47.178000+00:00",
        "attachments": null
    },
    {
        "author": "roberto.bayardo",
        "category": "Channel Graveyard",
        "parent": "",
        "content": "no this is correct, you need the data gas fee from the block to compute this. I think putting this in the receipt is best since if we change the computation later, then all clients that need to compute this need to update.",
        "created_at": "2023-01-27T09:19:34.519000+00:00",
        "attachments": null
    },
    {
        "author": "mandrigin",
        "category": "Channel Graveyard",
        "parent": "",
        "content": "Any news/updates on that Lighthouse issue? I know \u003c@898563924440543283\u003e is using Prysm for testing/developing, so I wanted to use LH for devnet.",
        "created_at": "2023-01-27T09:46:23.607000+00:00",
        "attachments": null
    },
    {
        "author": "realbigsean",
        "category": "Channel Graveyard",
        "parent": "",
        "content": "Yea so when I run lighthouse with this geth commit, I can sync the first 5 or so epochs https://github.com/mdehoog/go-ethereum/commit/2e2980d1cc67ab5772208a32540f288183329499\n\nWhen I run with this commit https://github.com/mdehoog/go-ethereum/commit/20d3ce887b3c16a7f9ba44613ccc7ebe0a83addc -- which I think the devnet nodes are currently running, geth rejects the payloads lighthouse syncs. So this generally seems like there might be a discrepancy between these two versions and that the devnet finalized something that's not valid anymore? sneaky hard fork on the execution side? \n\nBut we should be seeing similar in all consensus clients if this is the actual issue",
        "created_at": "2023-01-27T09:56:25.178000+00:00",
        "attachments": null
    },
    {
        "author": "mandrigin",
        "category": "Channel Graveyard",
        "parent": "",
        "content": "yeah, \u003c@898563924440543283\u003e if you are here, until what block can you sync Prysm with Erigon?",
        "created_at": "2023-01-27T10:13:29.978000+00:00",
        "attachments": null
    },
    {
        "author": "inphi",
        "category": "Channel Graveyard",
        "parent": "",
        "content": "Looking into this. The changes introduced added stricter block validity checks to geth to this fits.",
        "created_at": "2023-01-27T10:18:47.739000+00:00",
        "attachments": null
    },
    {
        "author": "bridge-bot",
        "category": "Channel Graveyard",
        "parent": "",
        "content": "\u003ctimbeiko\u003e 4844 precompile benchmarks: https://github.com/imapp-pl/benchmarking/tree/precompiles_benchmark/shanghai (https://github.com/imapp-pl/benchmarking/tree/precompiles_benchmark/shanghai)",
        "created_at": "2023-01-27T10:19:21.048000+00:00",
        "attachments": null
    },
    {
        "author": "bridge-bot",
        "category": "Channel Graveyard",
        "parent": "",
        "content": "\u003ctimbeiko\u003e cc: @kevaundray",
        "created_at": "2023-01-27T10:19:35.337000+00:00",
        "attachments": null
    },
    {
        "author": "bridge-bot",
        "category": "Channel Graveyard",
        "parent": "",
        "content": "\u003ctimbeiko\u003e \u003c@555483069038198827\u003e",
        "created_at": "2023-01-27T10:19:49.755000+00:00",
        "attachments": null
    },
    {
        "author": "inphi",
        "category": "Channel Graveyard",
        "parent": "",
        "content": "~~ok. figured out the issue. Good news is we don't have to redo the devnet. There is a bug in the new geth  and fixing this will allow you to sync.~~",
        "created_at": "2023-01-27T10:25:04.209000+00:00",
        "attachments": null
    },
    {
        "author": "roberto.bayardo",
        "category": "Channel Graveyard",
        "parent": "",
        "content": "yep I'm here, I think I just fixed the last bug preventing interop tests from passing. I do see however some invocation of the tx replay code in the txpool which I don't quite understand... shouldn't that only happen from reorgs?  (Right now we can't replay blob transactions since at the time of replay we've discarded the blob data ... this is also the case for Geth right now.)",
        "created_at": "2023-01-27T10:48:31.415000+00:00",
        "attachments": null
    },
    {
        "author": "roberto.bayardo",
        "category": "Channel Graveyard",
        "parent": "",
        "content": "(BTW I'm testing standalone testnet not on devnet ... I will try devnet in a bit and let you know how far it gets.)",
        "created_at": "2023-01-27T10:50:08.257000+00:00",
        "attachments": null
    },
    {
        "author": "axic3354",
        "category": "Channel Graveyard",
        "parent": "",
        "content": "Where can I find test cases for the pointeval precompile? https://github.com/ethereum/tests/search?q=4844 yields no results",
        "created_at": "2023-01-27T13:28:44.061000+00:00",
        "attachments": null
    },
    {
        "author": "axic3354",
        "category": "Channel Graveyard",
        "parent": "",
        "content": "Found one test case in this: https://github.com/imapp-pl/benchmarking/blob/precompiles_benchmark/shanghai/spec.md#point-evaluation",
        "created_at": "2023-01-27T13:32:51.526000+00:00",
        "attachments": null
    },
    {
        "author": "realbigsean",
        "category": "Channel Graveyard",
        "parent": "",
        "content": "\u003c@504202741933932544\u003e We're getting `ResourceUnavailable` as a response to `BlobsByRange` from Teku in the first epoch after the 4844 fork (epoch 5) on the devnet\n\n```\nJan 27 17:17:57.230 DEBG Requesting batch                        start_slot: 160, end_slot: 191, downloaded: 2, processed: 0, processed_no_penalty: 0, state: Downloading(16Uiu2HAmUUw5hbSpk21MwtF9SmnQ4uhvFJsVs8qcwuS3AefRCW4E, 0 blocks, 17), batch_ty: blocks_and_blobs, epoch: 5, chain: 9598337991019099848, service: sync\nJan 27 17:17:57.244 DEBG RPC Error                               direction: Outgoing, score: 0, peer_id: 16Uiu2HAmUUw5hbSpk21MwtF9SmnQ4uhvFJsVs8qcwuS3AefRCW4E, client: Teku: version: vUNKNOWN+gb77016c, os_version: linux-x86_64, err: RPC response was an error: Resource unavailable with reason: Requested blobs sidecars are not available., protocol: blobs_sidecars_by_range, service: libp2p\n```",
        "created_at": "2023-01-27T17:58:51.654000+00:00",
        "attachments": null
    },
    {
        "author": "tbenr",
        "category": "Channel Graveyard",
        "parent": "",
        "content": "Thanks for sharing. We'll check the pruner",
        "created_at": "2023-01-27T18:01:32.104000+00:00",
        "attachments": null
    },
    {
        "author": "tbenr",
        "category": "Channel Graveyard",
        "parent": "",
        "content": "are you receiving more recent blobs?",
        "created_at": "2023-01-27T18:06:29.313000+00:00",
        "attachments": null
    },
    {
        "author": "realbigsean",
        "category": "Channel Graveyard",
        "parent": "",
        "content": "right now we insta-ban when this happens within the DA period so not sure if it works ðŸ˜†",
        "created_at": "2023-01-27T18:08:20.116000+00:00",
        "attachments": null
    },
    {
        "author": "acolytec3",
        "category": "Channel Graveyard",
        "parent": "",
        "content": "Not sure if you need more but \u003c@427491045308235776\u003e pointed me to this repo of his. https://github.com/crate-crypto/proto-danksharding-fuzzy-test/blob/master/nodejs-ckzg/src/index.ts I generated a couple of test vectors from there for our unit tests in ethereumjs",
        "created_at": "2023-01-27T18:34:12.045000+00:00",
        "attachments": null
    }
]