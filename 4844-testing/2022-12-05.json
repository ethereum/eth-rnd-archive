[
    {
        "author": "arnetheduck",
        "category": "Channel Graveyard",
        "parent": "",
        "content": "regarding coupled gossip, what's a good reference to the discussion points? since data streaming  is starting to appear as an issue (ie the time it takes to transmit bytes for each hop), it would seem that a decoupled gossip will be better at propagating blocks throughout the network because the two parts can travel in parallel cc \u003c@363800010518822915\u003e \u003c@607055410104500244\u003e",
        "created_at": "2022-12-05T10:04:31.004000+00:00",
        "attachments": null
    },
    {
        "author": "m.kalinin",
        "category": "Channel Graveyard",
        "parent": "",
        "content": "I was always curious how big of an overhead can additionally streamed data impose. Say you propagate 100KB vs 1MB, what will the time diff be?",
        "created_at": "2022-12-05T10:08:59.114000+00:00",
        "attachments": null
    },
    {
        "author": "bridge-bot",
        "category": "Channel Graveyard",
        "parent": "",
        "content": "\u003chenridf\u003e If the transfer is bandwidth-constrained then sending in parallel vs sequential should be roughly similar. If it's latency-constrained, then parallel would result in a speed up, the multiple depends on RTT, but assuming connections are already open, then gains probably not that high.",
        "created_at": "2022-12-05T10:31:40.593000+00:00",
        "attachments": null
    },
    {
        "author": "bridge-bot",
        "category": "Channel Graveyard",
        "parent": "",
        "content": "\u003chenridf\u003e Actually aren't all gossip topics multiplexed over a single TCP connection?",
        "created_at": "2022-12-05T10:33:38.353000+00:00",
        "attachments": null
    },
    {
        "author": "arnetheduck",
        "category": "Channel Graveyard",
        "parent": "",
        "content": "well, the basic idea is that one can verify then re-transmit each part independently - that means that if you stream first block then blob, the receiver can verify the block and repropagate it while waiting for the blob - in a coupled design, all streaming must happen first, then validation of the two parts together (so the latency introduced is the worst of the blob and block), then repropagation",
        "created_at": "2022-12-05T11:01:04.149000+00:00",
        "attachments": null
    },
    {
        "author": "arnetheduck",
        "category": "Channel Graveyard",
        "parent": "",
        "content": "this means even in a bandwidth-bound scenario, others (presumably with more bandwidth) can start repropagating parts earlier",
        "created_at": "2022-12-05T11:05:40.444000+00:00",
        "attachments": null
    },
    {
        "author": "arnetheduck",
        "category": "Channel Graveyard",
        "parent": "",
        "content": "early on we also discussed more advanced distribution patterns, ie propagating block header via gossip (which is expensive) then fetching contents via p2p (which is cheaper) - we dismissed it because the overhead was negligible for 10kb-blocks vs the complexity it introduced - but the math is a bit different now",
        "created_at": "2022-12-05T11:08:17.284000+00:00",
        "attachments": null
    },
    {
        "author": "arnetheduck",
        "category": "Channel Graveyard",
        "parent": "",
        "content": "https://notes.ethereum.org/lQ_75o64R9q8ddt3M9M3tg?view= - I'm curious if anyone has looked into this for example?",
        "created_at": "2022-12-05T11:09:23.809000+00:00",
        "attachments": null
    },
    {
        "author": "m.kalinin",
        "category": "Channel Graveyard",
        "parent": "",
        "content": "You can't propagate header unless you downloaded a body. Otherwise, you can disseminate unavailable block",
        "created_at": "2022-12-05T11:09:50.489000+00:00",
        "attachments": null
    },
    {
        "author": "arnetheduck",
        "category": "Channel Graveyard",
        "parent": "",
        "content": "you can, optimistically, just like we optimistically assume blocks will pass state validation",
        "created_at": "2022-12-05T11:10:17.849000+00:00",
        "attachments": null
    },
    {
        "author": "henridf",
        "category": "Channel Graveyard",
        "parent": "",
        "content": "Agreed! (Hence my second question on multiplexing. So separating topics doesn't lead to parallel transfer, but allows to parallelize processing with transfer.)",
        "created_at": "2022-12-05T11:10:21.214000+00:00",
        "attachments": null
    },
    {
        "author": "m.kalinin",
        "category": "Channel Graveyard",
        "parent": "",
        "content": "Remote peer may not yet download a body when your node is asking it for because it may not yet be downloaded by that peer. That's complicated",
        "created_at": "2022-12-05T11:11:32.647000+00:00",
        "attachments": null
    },
    {
        "author": "arnetheduck",
        "category": "Channel Graveyard",
        "parent": "",
        "content": "multiplexing does indeed happen at the socket/libp2p level, but that's a design choice in the libp2p library - it can just as well choose to prio one stream over another",
        "created_at": "2022-12-05T11:11:35.557000+00:00",
        "attachments": null
    },
    {
        "author": "arnetheduck",
        "category": "Channel Graveyard",
        "parent": "",
        "content": "well, yes - that's why we discarded it for early versions - nonetheless - the problem is more complex now and might warrant a more complex solution",
        "created_at": "2022-12-05T11:12:33.222000+00:00",
        "attachments": null
    },
    {
        "author": "m.kalinin",
        "category": "Channel Graveyard",
        "parent": "",
        "content": "In the parallel design a client may ~~process a block~~ verify proposer's signature while the blob is yet being streamed. Is this the optimisation that we can get?",
        "created_at": "2022-12-05T11:13:03.924000+00:00",
        "attachments": null
    },
    {
        "author": "m.kalinin",
        "category": "Channel Graveyard",
        "parent": "",
        "content": "Can you read a block from SSZ stream, pass it to sig verification and then start reading a blob?",
        "created_at": "2022-12-05T11:30:31.594000+00:00",
        "attachments": null
    },
    {
        "author": "arnetheduck",
        "category": "Channel Graveyard",
        "parent": "",
        "content": "eh, possible, but I'm guessing quite tricky - the blobs as compressed so you'd have to do partial decompression (and you still can't start sending the block to others)",
        "created_at": "2022-12-05T11:54:15.660000+00:00",
        "attachments": null
    },
    {
        "author": "arnetheduck",
        "category": "Channel Graveyard",
        "parent": "",
        "content": "verify sig and start sending to others",
        "created_at": "2022-12-05T11:54:57.850000+00:00",
        "attachments": null
    },
    {
        "author": "m.kalinin",
        "category": "Channel Graveyard",
        "parent": "",
        "content": "Not sending a block to others may be fine if sig verification takes longer than streaming a blob",
        "created_at": "2022-12-05T12:19:06.278000+00:00",
        "attachments": null
    },
    {
        "author": "arnetheduck",
        "category": "Channel Graveyard",
        "parent": "",
        "content": "assuming a 10mbit line, it takes 1s to stream 1mb (not counting overhead, compression and so on) - on a 100mbit line, that's ~0.8s to stream to the 8 peers typically in your mesh",
        "created_at": "2022-12-05T12:21:57.727000+00:00",
        "attachments": null
    },
    {
        "author": "arnetheduck",
        "category": "Channel Graveyard",
        "parent": "",
        "content": "I hope we're doing better than that on the sig verification front ðŸ˜‰",
        "created_at": "2022-12-05T12:22:39.495000+00:00",
        "attachments": null
    },
    {
        "author": "m.kalinin",
        "category": "Channel Graveyard",
        "parent": "",
        "content": "I feel like sig verification is about 1ms + computing the sate if needed which I don't know the numbers about. It looks like disseminating data would be the main overhead while sig verification is a tip of an iceberg. And doesn't sound like something worth care about",
        "created_at": "2022-12-05T12:25:31.473000+00:00",
        "attachments": null
    },
    {
        "author": "arnetheduck",
        "category": "Channel Graveyard",
        "parent": "",
        "content": "well, the advantage is to be able to start sending the block to the next peer earlier - the sig verification is  cream on top",
        "created_at": "2022-12-05T12:27:56.198000+00:00",
        "attachments": null
    },
    {
        "author": "arnetheduck",
        "category": "Channel Graveyard",
        "parent": "",
        "content": "this is, as they call it, an \"embarrassingly parallel\" problem - in the coupled design, we more or less force serialization, which maybe is reasonable for \"complexity\" reasons - but it's worth keeping in view, specially if we want to increase blob sizes or do multiple blobs",
        "created_at": "2022-12-05T12:30:45.793000+00:00",
        "attachments": null
    },
    {
        "author": "m.kalinin",
        "category": "Channel Graveyard",
        "parent": "",
        "content": "The spec states that a block can't be applied unless availability of the corresponding blob is verified. The outcome of parallel design is a node finishes processing a block before a blob is received if blob is bigger than a block. Considering execution payload verification it may actually be a good increase. But with 4844 I don't think we will sidecars bigger than 128KB, this is the limitation that 4844 design can't overcome, it is aimed to be removed by the full sharding.",
        "created_at": "2022-12-05T12:42:58.396000+00:00",
        "attachments": null
    },
    {
        "author": "m.kalinin",
        "category": "Channel Graveyard",
        "parent": "",
        "content": "I think we need more accurate numbers and consider the complexity which parallel dissemination comes with. Probably, it's really worth to unbundle them",
        "created_at": "2022-12-05T12:44:39.865000+00:00",
        "attachments": null
    },
    {
        "author": "realbigsean",
        "category": "Channel Graveyard",
        "parent": "",
        "content": "This is probably the best reference: https://notes.ethereum.org/RLOGb1hYQ0aWt3hcVgzhgQ?#Gossip",
        "created_at": "2022-12-05T14:56:21.466000+00:00",
        "attachments": null
    },
    {
        "author": "realbigsean",
        "category": "Channel Graveyard",
        "parent": "",
        "content": "Yes this is currently being worked on but I don't think we have results yet. It could reveal that decoupling is necessary.",
        "created_at": "2022-12-05T15:06:14.144000+00:00",
        "attachments": null
    },
    {
        "author": "inphi",
        "category": "Channel Graveyard",
        "parent": "",
        "content": "I'm not opposed to making a V3 version since this is causing some confusion. But couldn't clients avoid adding 4844 fields (or make them optional) in the V2 payload when processing Capella blocks?",
        "created_at": "2022-12-05T19:44:11.966000+00:00",
        "attachments": null
    },
    {
        "author": "terence0083",
        "category": "Channel Graveyard",
        "parent": "",
        "content": "It can be done, but that'll take longer for Prysm to implement. We match the type with versioning. Harder to handle two types under the same version. Also, making them v3 gets us closer to the future, since it's unlikely to be v2 at this point",
        "created_at": "2022-12-05T19:49:57.895000+00:00",
        "attachments": null
    },
    {
        "author": "inphi",
        "category": "Channel Graveyard",
        "parent": "",
        "content": "eh, it didn't take long to do this on devnet v[12]; using the engine API V1 types for the bellatrix -\u003e 4844 upgrade. But I admit that it was messy code change.\nThanks for bringing this up, I'll update the spec to use V3.",
        "created_at": "2022-12-05T19:53:22.367000+00:00",
        "attachments": null
    },
    {
        "author": "inphi",
        "category": "Channel Graveyard",
        "parent": "",
        "content": "\u003c@607055410104500244\u003e are you OK with having V3 methods to match the new `ExecutionPayloadV3`?",
        "created_at": "2022-12-05T20:05:13.915000+00:00",
        "attachments": null
    },
    {
        "author": "realbigsean",
        "category": "Channel Graveyard",
        "parent": "",
        "content": "My understandings that the execution endpoints are meant to function across forks.  So if the V3 method serves V1 + V2 + V3 structs depending on the fork, thatâ€™d be what we currently expect.\n\u2028The point about having the V2 and V3 *structs* separate is that we want to make sure a populated V3 field is invalid for a V2 object. If weâ€™re sent a non-null `excessDataGas` during cappella weâ€™ll fail.",
        "created_at": "2022-12-05T20:33:24.143000+00:00",
        "attachments": null
    },
    {
        "author": "inphi",
        "category": "Channel Graveyard",
        "parent": "",
        "content": "This isn't always the case. We have V2 APIs that do not support V1 structures because those APIs have withdrawals specific behavior. I originally thought we could overload the V2 methods for 4844 since we don't need special handling for 4844 payloads. Now I'd rather keep things consistent with the V3 payloads.",
        "created_at": "2022-12-05T20:38:11.863000+00:00",
        "attachments": null
    },
    {
        "author": "terence0083",
        "category": "Channel Graveyard",
        "parent": "",
        "content": "Yes, I would prefer V3 structs to V3 end points. I dont think we need V3 to function across forks for devnet purpose",
        "created_at": "2022-12-05T20:41:02.752000+00:00",
        "attachments": null
    },
    {
        "author": "realbigsean",
        "category": "Channel Graveyard",
        "parent": "",
        "content": "Yea I mean I don't think it's very clearly spec'd out.. but this PR essentially does this by making V2 objects able to represent V1 objects with null fields https://github.com/ethereum/execution-apis/pull/332\n\nOn the withdrawals testnet we query the same endpoints across forks now, but the execution spec versioning is a bit confusing to me so I'm OK with just working with \u003c@363800010518822915\u003e's suggestion for now.. especially if that's already what's implemented for 4844 in geth",
        "created_at": "2022-12-05T20:51:54.868000+00:00",
        "attachments": null
    }
]