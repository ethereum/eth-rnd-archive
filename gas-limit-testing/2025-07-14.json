[
    {
        "author": "bridge-bot",
        "category": "Execution Layer",
        "parent": "",
        "content": "\u003cchfast\u003e re: **@KamilChNethermind**\n\u003e @kevaundray Did two Geth branches:\n1. With GO Implementation improvements\n2. With 1 + Switch Lib to GMP\n\nSeems like 1 (GO) help quite a bit with One Cacheable scenario from Guido and generally feels like giving about 5% improvement to some worse cases (which are below 65 bits in exponent). Some results on table one - biggest improvement at 56%. No regression here, only better results.\n\nGMP switch (2) seems like give HUGE boost in general (seems like from 70 up to 400% better results for all our modexp scenarios).\nCurrent worst case with it is at 23.3 MGas/s (NOTE - it is different, weaker hardware than used on main dashboard so numbers may be even better).\n\nOne thing is that there seems to be some sort of regression for Cachable guido scenario (From 547 to 23.7 Mgas/s - need to be checked) and scenario called \"Modexp5461base1024UNCACHABLE2\" - from 111 to 67.3 MGas/s.\nDo not know these scenarios so need to spend some time analyzing those, can give bytecodes for it and maybe need to wait for Marcin to give some insights.\n\nTL;DR:\nGO tweak improves Geth perf just a little bit.\nGMP gives huge up to 5x improvement and bumping worst case scenario on Pectra spec from 13.5 to 23.5 MGas/s but comes with some regression which needs to be analyzed.\nWhere are these branches?",
        "created_at": "2025-07-14T07:23:13.779000+00:00",
        "attachments": null
    },
    {
        "author": "bridge-bot",
        "category": "Execution Layer",
        "parent": "",
        "content": "\u003cCPerezz\u003e re: **@KamilChNethermind**\n\u003e New version from Kev fixed the biggest regression.\nThe second scenario seems like is actually some bottleneck in GMP - without performs around 110Mgas, after around 70 and seems like nethermind/reth also have around 70 for this scenario. So we need to dig a little bit into that direction as may be unexplored ground for modexp.\n\nThis precompile just keeps on giving...\n@kevaundray what is your Go PR doing? Is it any similar to the one in the thread with Gotti? Or are you doing idfferent stuff?",
        "created_at": "2025-07-14T07:24:16.776000+00:00",
        "attachments": null
    },
    {
        "author": "bridge-bot",
        "category": "Execution Layer",
        "parent": "",
        "content": "\u003cKamilChNethermind\u003e re: **@chfast**\n\u003e Where are these branches?\nhttps://github.com/ethereum/go-ethereum/pull/32184\nhttps://github.com/ethereum/go-ethereum/pull/32187",
        "created_at": "2025-07-14T08:57:32.794000+00:00",
        "attachments": null
    },
    {
        "author": "bridge-bot",
        "category": "Execution Layer",
        "parent": "",
        "content": "\u003cchfast\u003e re: **@KamilChNethermind**\n\u003e https://github.com/ethereum/go-ethereum/pull/32184\nhttps://github.com/ethereum/go-ethereum/pull/32187\n@kevaundray The \"GO improvements\" only optimize gas calculation?",
        "created_at": "2025-07-14T09:33:14.166000+00:00",
        "attachments": null
    },
    {
        "author": "bridge-bot",
        "category": "Execution Layer",
        "parent": "",
        "content": "\u003ckevaundray\u003e re: **@CPerezz**\n\u003e @kevaundray what is your Go PR doing? Is it any similar to the one in the thread with Gotti? Or are you doing idfferent stuff?\nIt was just doing basic optimizations to early exit on edge cases and truncate padding.\n\nKamil was benchmarking the latter to see if it made any difference IIRC",
        "created_at": "2025-07-14T09:37:14.395000+00:00",
        "attachments": null
    },
    {
        "author": "bridge-bot",
        "category": "Execution Layer",
        "parent": "",
        "content": "\u003ckevaundray\u003e re: **@chfast**\n\u003e @kevaundray The \"GO improvements\" only optimize gas calculation?\nYeah,\n\n(1) optimizes gas calculation because it was doing a lot of big.Int allocations \n\n(2) bases off of 1 and Adds GMP plus edge cases handling that was present in the big.Int code plus truncating of input",
        "created_at": "2025-07-14T09:39:26.595000+00:00",
        "attachments": null
    },
    {
        "author": "bridge-bot",
        "category": "Execution Layer",
        "parent": "",
        "content": "\u003ckevaundray\u003e The GMP branch is now 2x faster on the edge case that initially regressed because it doesn’t need to allocate big.Ints in order to compute the result\n\nSee: https://github.com/ethereum/go-ethereum/blob/bdb4f47532e7362ca66f666189ea32b20fd2a4b5/crypto/modexp/gmp/gmp.go#L60",
        "created_at": "2025-07-14T09:41:00.632000+00:00",
        "attachments": null
    },
    {
        "author": "bridge-bot",
        "category": "Execution Layer",
        "parent": "",
        "content": "\u003cFunnyGiulio\u003e re: **@kevaundray**\n\u003e The GMP branch is now 2x faster on the edge case that initially regressed because it doesn’t need to allocate big.Ints in order to compute the result\n\nSee: https://github.com/ethereum/go-ethereum/blob/bdb4f47532e7362ca66f666189ea32b20fd2a4b5/crypto/modexp/gmp/gmp.go#L60\nGreat work",
        "created_at": "2025-07-14T16:00:00.674000+00:00",
        "attachments": null
    }
]