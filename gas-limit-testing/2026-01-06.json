[
    {
        "author": "bridge-bot",
        "category": "Execution Layer",
        "parent": "",
        "content": "\u003cmattyevans\u003e re: **@KamilChNethermind**\n\u003e which ones we should look at? I see nodes with prefix \"utility\" and \"sigma\"\nWe've made some further UI tweaks to more clearly distinguish reference vs non-reference nodes, and to surface more detailed hardware specs for both clusters.\n\nThe util cluster had history expiry enabled across all clients, while sigma did not. These are now aligned with it disabled on both.\n\nWe've also started pushing OTLP traces for reth today. I can do the same for Nethermind if support is there(?) and you think it'd be useful.",
        "created_at": "2026-01-06T01:51:34.314000+00:00",
        "attachments": null
    },
    {
        "author": "bridge-bot",
        "category": "Execution Layer",
        "parent": "",
        "content": "\u003csiladu\u003e re: **@mattyevans**\n\u003e We've made some further UI tweaks to more clearly distinguish reference vs non-reference nodes, and to surface more detailed hardware specs for both clusters.\n\nThe util cluster had history expiry enabled across all clients, while sigma did not. These are now aligned with it disabled on both.\n\nWe've also started pushing OTLP traces for reth today. I can do the same for Nethermind if support is there(?) and you think it'd be useful.\n\"history expiry enabled\" is a bit slippery. This should be the default for all clients using snap sync I believe. At least for Besu, \"enabling\" it is only really relevant if you have an existing node to prune. I think the cleanest thing is to use freshly snap synced nodes.",
        "created_at": "2026-01-06T02:21:26.429000+00:00",
        "attachments": null
    },
    {
        "author": "bridge-bot",
        "category": "Execution Layer",
        "parent": "",
        "content": "\u003cpintolu\u003e re: **@marcin_d_s**\n\u003e According to current benchmarks (https://grafana.observability.ethpandaops.io/d/feo4ronhsqv40d/opcodes-benchmarking) with fixed number of instructions (and without precompiles), these are operations performing below 100MGas/s. \n\nI excluded cases where Besu was the only underperforming client, it was just too often and we likely need to improve the process.\n\nKeccak in underperforming in all clients so I propose 2x repricing, in all other cases there is at least one client performing above 100MGas/s, so it is theoretically possible to improve without repricing.\n\nJust FYI, there is already an EIP for tripling price of Point Evaluation precompile (https://github.com/ethereum/EIPs/pull/10864) and likely we will need to reprice also EcRecover, but we need to wait for accurate benchmark data for that.\nonly getting around to discuss this internally within the team. MOD and SMOD share most of the code on our side, though MOD is much slower. SMOD additional work has to do with sign inversion at the start and end so it should actually be the slowest and not the fastest (on the worst case). This looks fishy to me. I wonder what inputs are you using for MOD and SMOD or question what's actually going on there.",
        "created_at": "2026-01-06T10:38:17.127000+00:00",
        "attachments": null
    },
    {
        "author": "bridge-bot",
        "category": "Execution Layer",
        "parent": "",
        "content": "\u003cchfast\u003e re: **@pintolu**\n\u003e only getting around to discuss this internally within the team. MOD and SMOD share most of the code on our side, though MOD is much slower. SMOD additional work has to do with sign inversion at the start and end so it should actually be the slowest and not the fastest (on the worst case). This looks fishy to me. I wonder what inputs are you using for MOD and SMOD or question what's actually going on there.\nYou need to prepare a special chain of values for MOD to keep the results within a specific range as long as possible (every MOD operation reduces the value). Maybe this approach doesn't resonate with your SMOD implementation.",
        "created_at": "2026-01-06T17:16:50.799000+00:00",
        "attachments": null
    }
]