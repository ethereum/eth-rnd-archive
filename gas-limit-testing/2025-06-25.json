[
    {
        "author": "bridge-bot",
        "category": "Execution Layer",
        "parent": "",
        "content": "\u003cKamilChNethermind\u003e @amezianehamlat \nBesu definitely better after repricing :)\n\nCan you make separate branch with repricing? Like performance-modexp?\n\nSo we will prepare two dashboards - one running Pectra Spec, one running Fusaka spec.",
        "created_at": "2025-06-25T05:39:35.759000+00:00",
        "attachments": [
            {
                "type": "image/jpeg",
                "origin_name": "file_55.jpg",
                "content": "37e30a2c3f4f068daae1befeca9adb14af175f80c2ec53913093d7c14612319d"
            }
        ]
    },
    {
        "author": "bridge-bot",
        "category": "Execution Layer",
        "parent": "",
        "content": "\u003cKamilChNethermind\u003e But what worries me that even after repricing there is scenario which performs at 32 MGas/s. And it is not the one we expected to be the slowest (Pawel4 which theoretically makes worst case after repricing).",
        "created_at": "2025-06-25T05:41:32.488000+00:00",
        "attachments": null
    },
    {
        "author": "bridge-bot",
        "category": "Execution Layer",
        "parent": "",
        "content": "\u003cKamilChNethermind\u003e Today will merge warming PR so we will see warm results so may affect Besu",
        "created_at": "2025-06-25T05:42:52.852000+00:00",
        "attachments": null
    },
    {
        "author": "bridge-bot",
        "category": "Execution Layer",
        "parent": "",
        "content": "\u003camezianehamlat\u003e re: **@KamilChNethermind**\n\u003e @amezianehamlat \nBesu definitely better after repricing :)\n\nCan you make separate branch with repricing? Like performance-modexp?\n\nSo we will prepare two dashboards - one running Pectra Spec, one running Fusaka spec.\nWill do this morning, thanks for the update",
        "created_at": "2025-06-25T07:24:35.335000+00:00",
        "attachments": null
    },
    {
        "author": "bridge-bot",
        "category": "Execution Layer",
        "parent": "",
        "content": "\u003camezianehamlat\u003e So, now we have the performance branch without the new pricing on modexp and performance-modexp branch with new pricing on modexp forced for Cancun",
        "created_at": "2025-06-25T07:46:56.095000+00:00",
        "attachments": null
    },
    {
        "author": "bridge-bot",
        "category": "Execution Layer",
        "parent": "",
        "content": "\u003cKamilChNethermind\u003e Great! Thank you!\n\n@vdWijden @gakonst @shekhirin Can you do the same as above?",
        "created_at": "2025-06-25T07:48:38.226000+00:00",
        "attachments": null
    },
    {
        "author": "bridge-bot",
        "category": "Execution Layer",
        "parent": "",
        "content": "\u003cvdWijden\u003e Our master branch has fusaka repricing in already",
        "created_at": "2025-06-25T08:09:24.699000+00:00",
        "attachments": null
    },
    {
        "author": "bridge-bot",
        "category": "Execution Layer",
        "parent": "",
        "content": "\u003cKamilChNethermind\u003e re: **@vdWijden**\n\u003e Our master branch has fusaka repricing in already\nFor the sake of gas-benchmarks testing and verification we need it to be enabled on Dencun so we can test it in isolation on separate machine",
        "created_at": "2025-06-25T08:18:09.126000+00:00",
        "attachments": null
    },
    {
        "author": "bridge-bot",
        "category": "Execution Layer",
        "parent": "",
        "content": "\u003cvdWijden\u003e On cancun or on prague?",
        "created_at": "2025-06-25T08:25:10.581000+00:00",
        "attachments": null
    },
    {
        "author": "bridge-bot",
        "category": "Execution Layer",
        "parent": "",
        "content": "\u003cvdWijden\u003e https://github.com/ethereum/go-ethereum/tree/performance-modexp",
        "created_at": "2025-06-25T08:26:32.745000+00:00",
        "attachments": null
    },
    {
        "author": "bridge-bot",
        "category": "Execution Layer",
        "parent": "",
        "content": "\u003cvdWijden\u003e (enabled it on both)",
        "created_at": "2025-06-25T08:26:40.510000+00:00",
        "attachments": null
    },
    {
        "author": "bridge-bot",
        "category": "Execution Layer",
        "parent": "",
        "content": "\u003cKamilChNethermind\u003e Cancun - we have some things to be worked out still in our test and stuck on cancun for now - but not affecting anything as there was no major repricing in prague",
        "created_at": "2025-06-25T08:26:49.954000+00:00",
        "attachments": null
    },
    {
        "author": "bridge-bot",
        "category": "Execution Layer",
        "parent": "",
        "content": "\u003cKamilChNethermind\u003e Thank you!",
        "created_at": "2025-06-25T08:27:06.139000+00:00",
        "attachments": null
    },
    {
        "author": "bridge-bot",
        "category": "Execution Layer",
        "parent": "",
        "content": "\u003cKamilChNethermind\u003e So for now I have:\nNethermind: performance-repriced\nGeth: performance-modexp\nBesu: performance-modexp\nErigon: performance-modexp\nReth: missing for now\n\nWill create a separate Dashboard on Performance directory which will use above ones and only trigger modexp scenarios - so we can observe and in case of any EIP adjustments make sure to push your changes also in there.\n\nmid-term will transition it into \"Fusaka-enabled\" mode but we need probably to first figure it out with EEST integration as will be two things at once rather than doing that custom way on our end",
        "created_at": "2025-06-25T09:06:31.270000+00:00",
        "attachments": null
    },
    {
        "author": "bridge-bot",
        "category": "Execution Layer",
        "parent": "",
        "content": "\u003cKamilChNethermind\u003e @shekhirin If you can stick to the naming used by geth/besu/erigon it will be automatically done for you as I presumed you will use same one ;D If not will make adjustments",
        "created_at": "2025-06-25T09:12:08.875000+00:00",
        "attachments": null
    },
    {
        "author": "bridge-bot",
        "category": "Execution Layer",
        "parent": "",
        "content": "\u003cKamilChNethermind\u003e Hi @chiragparmarme Can you create a NimbusEL version of branch called \"performance-modexp\" which will have modexp repricing enabled on Cancun fork?",
        "created_at": "2025-06-25T09:26:13.950000+00:00",
        "attachments": null
    },
    {
        "author": "bridge-bot",
        "category": "Execution Layer",
        "parent": "",
        "content": "\u003camezianehamlat\u003e @vdWijden related to the Ec Add use case you shared, could you confirm that it is related to the EC Points below ?\n```\n\nPoint 1 (1581d9d4d7eb0e3cdc75739f7098479097d579573f23e70b07cbd40a5d97bbc1, 18da69b1d2cb7b89fdb3bba2524bf135453ce828faea190d8f4d48d572cbe3fe)\nPoint 2 (2034b5942fbdd612f2553a9fd9fa5eb4c3e5ce6a34ed100f62de0e380f4e67f8, 016027893e1f5082bdc48651667776e2b1e32a85edd33ff430eef15e8e68b3d4)\n```\n\nWhen I added logs in Nethermind benchmark that was running this use case, I saw different values for the EccAdd precmpile inputs, but maybe I'm missing something",
        "created_at": "2025-06-25T10:14:04.553000+00:00",
        "attachments": null
    },
    {
        "author": "bridge-bot",
        "category": "Execution Layer",
        "parent": "",
        "content": "\u003cvdWijden\u003e The test continuously overwrites the first point with the result, thus the input of the precompile is different every call.\ne.g. add(1,2), add(3,2), add(5,2) etc",
        "created_at": "2025-06-25T10:15:42.192000+00:00",
        "attachments": null
    },
    {
        "author": "bridge-bot",
        "category": "Execution Layer",
        "parent": "",
        "content": "\u003camezianehamlat\u003e re: **@vdWijden**\n\u003e The test continuously overwrites the first point with the result, thus the input of the precompile is different every call.\ne.g. add(1,2), add(3,2), add(5,2) etc\nI need to double check but from the inputs I gathered the second point was the same for few calls. Below is the input of the 3 EccAdd calls, the second point didn't change\n```\n\n1f69350cfea1bdf51ecec3a0bdf57732411418502904eb86c10901af310b9ca0291547261fc8bbcf961534f3f3d282d4ab3bfa0b9f3b5ecb3e575d42fd13e25c\n2034b5942fbdd612f2553a9fd9fa5eb4c3e5ce6a34ed100f62de0e380f4e67f8016027893e1f5082bdc48651667776e2b1e32a85edd33ff430eef15e8e68b3d4\n\n03adc0948243eac87e40fd1d4a3b5693c651abd30a88b93f3dbe3f571791c4120e9f7fa4c9ae503399c7a4f0ee0e91961b759d94e49c8ea0d04b448dbc6f3d16\n2034b5942fbdd612f2553a9fd9fa5eb4c3e5ce6a34ed100f62de0e380f4e67f8016027893e1f5082bdc48651667776e2b1e32a85edd33ff430eef15e8e68b3d4\n\n012b7638324563dc328b870d414807ed27426354bc83f22c42690f717ae7137e19dffc74cd0183d631cb39f5f58d2846744119913519373ebb95f2654a989390\n2034b5942fbdd612f2553a9fd9fa5eb4c3e5ce6a34ed100f62de0e380f4e67f8016027893e1f5082bdc48651667776e2b1e32a85edd33ff430eef15e8e68b3d4```",
        "created_at": "2025-06-25T10:20:43.257000+00:00",
        "attachments": null
    },
    {
        "author": "bridge-bot",
        "category": "Execution Layer",
        "parent": "",
        "content": "\u003cvdWijden\u003e Yep, 03a is the result of the first addition, 012 is the result of the second addition",
        "created_at": "2025-06-25T10:21:29.600000+00:00",
        "attachments": null
    },
    {
        "author": "bridge-bot",
        "category": "Execution Layer",
        "parent": "",
        "content": "\u003cKamilChNethermind\u003e I think @marcin_d_s did some improvement to that case to make it 5% worse by making more performant loop in C# code when egenrating scenario",
        "created_at": "2025-06-25T10:21:30.657000+00:00",
        "attachments": null
    },
    {
        "author": "bridge-bot",
        "category": "Execution Layer",
        "parent": "",
        "content": "\u003cvdWijden\u003e The second parameter stays the same",
        "created_at": "2025-06-25T10:21:43.801000+00:00",
        "attachments": null
    },
    {
        "author": "bridge-bot",
        "category": "Execution Layer",
        "parent": "",
        "content": "\u003cKamilChNethermind\u003e It is called ECAddMarius1Flat or sth",
        "created_at": "2025-06-25T10:21:48.321000+00:00",
        "attachments": null
    },
    {
        "author": "bridge-bot",
        "category": "Execution Layer",
        "parent": "",
        "content": "\u003camezianehamlat\u003e re: **@vdWijden**\n\u003e The second parameter stays the same\nI just noticed that we're saying the same üëç",
        "created_at": "2025-06-25T10:22:31.790000+00:00",
        "attachments": null
    },
    {
        "author": "bridge-bot",
        "category": "Execution Layer",
        "parent": "",
        "content": "\u003cmarcin_d_s\u003e EcAddMarius1Flat is doing the same calcs as EcAddMarius1, it just saves on JUMPs (doing 1000 iterations as a flat code and then jump instead of jumping in every iteration)",
        "created_at": "2025-06-25T10:50:56.792000+00:00",
        "attachments": null
    },
    {
        "author": "bridge-bot",
        "category": "Execution Layer",
        "parent": "",
        "content": "\u003cmarcin_d_s\u003e jump costs 8 and EcAdd costs 150 so it is saving ~5%",
        "created_at": "2025-06-25T10:51:49.636000+00:00",
        "attachments": null
    },
    {
        "author": "bridge-bot",
        "category": "Execution Layer",
        "parent": "",
        "content": "\u003cvdWijden\u003e If you unroll the loop, you could set the out offset for every other call to 64, so you overwrite the second parameter. This will stop any cpu/branch prediction of the unmarshaling of the second argument",
        "created_at": "2025-06-25T10:58:43.325000+00:00",
        "attachments": null
    },
    {
        "author": "bridge-bot",
        "category": "Execution Layer",
        "parent": "",
        "content": "\u003cmarcin_d_s\u003e We have first results from branches with repricing",
        "created_at": "2025-06-25T12:12:11.360000+00:00",
        "attachments": null
    },
    {
        "author": "bridge-bot",
        "category": "Execution Layer",
        "parent": "",
        "content": "\u003cmarcin_d_s\u003e Geth - worst case at 23.8",
        "created_at": "2025-06-25T12:12:53.012000+00:00",
        "attachments": [
            {
                "type": "image/jpeg",
                "origin_name": "file_56.jpg",
                "content": "3c3bf77718c7f1f3d2e4078ec976f752969b51018f29ced02a0f11f3ca417351"
            }
        ]
    },
    {
        "author": "bridge-bot",
        "category": "Execution Layer",
        "parent": "",
        "content": "\u003cmarcin_d_s\u003e Erigon - 26.3",
        "created_at": "2025-06-25T12:13:21.563000+00:00",
        "attachments": [
            {
                "type": "image/jpeg",
                "origin_name": "file_57.jpg",
                "content": "c5ab376318e5080a3d20bfc9c3c99a4e7305bc8c03727662fd49236ceca4d1bd"
            }
        ]
    },
    {
        "author": "bridge-bot",
        "category": "Execution Layer",
        "parent": "",
        "content": "\u003cvdWijden\u003e Uff",
        "created_at": "2025-06-25T12:13:36.154000+00:00",
        "attachments": null
    },
    {
        "author": "bridge-bot",
        "category": "Execution Layer",
        "parent": "",
        "content": "\u003cmarcin_d_s\u003e Besu - 47.3",
        "created_at": "2025-06-25T12:13:49.660000+00:00",
        "attachments": [
            {
                "type": "image/jpeg",
                "origin_name": "file_58.jpg",
                "content": "44d9237a63483690a02db0732717f46073402230e5fd35be84c78a0e6159da60"
            }
        ]
    },
    {
        "author": "bridge-bot",
        "category": "Execution Layer",
        "parent": "",
        "content": "\u003cmarcin_d_s\u003e Neth - 81.8",
        "created_at": "2025-06-25T12:14:22.018000+00:00",
        "attachments": [
            {
                "type": "image/jpeg",
                "origin_name": "file_59.jpg",
                "content": "3a4b131736586f1e2652b72ad329fe317e6d7d0e4c53a848e8b33c5e97baa827"
            }
        ]
    },
    {
        "author": "bridge-bot",
        "category": "Execution Layer",
        "parent": "",
        "content": "\u003cvdWijden\u003e What are the worst cases doing?",
        "created_at": "2025-06-25T12:14:26.215000+00:00",
        "attachments": null
    },
    {
        "author": "bridge-bot",
        "category": "Execution Layer",
        "parent": "",
        "content": "\u003cmarcin_d_s\u003e Pawel4 is a scenario with base equal 32bytes and exponent 96bit, cost is slightly above 500 (new minimal value)",
        "created_at": "2025-06-25T12:15:01.526000+00:00",
        "attachments": null
    },
    {
        "author": "bridge-bot",
        "category": "Execution Layer",
        "parent": "",
        "content": "\u003cmarcin_d_s\u003e 677 (it's old price, before repricing) is base/modulo 32bytes and exp 128bit",
        "created_at": "2025-06-25T12:15:58.878000+00:00",
        "attachments": null
    },
    {
        "author": "bridge-bot",
        "category": "Execution Layer",
        "parent": "",
        "content": "\u003cmarcin_d_s\u003e hmm but actually the price will be the same, as this scenario is not repriced (base 32bytes so no price increase, exp below 32bytes so no increase as well, overall cost \u003e500 so not triggered by new minimum)",
        "created_at": "2025-06-25T12:17:53.678000+00:00",
        "attachments": null
    },
    {
        "author": "bridge-bot",
        "category": "Execution Layer",
        "parent": "",
        "content": "\u003cmarcin_d_s\u003e 1360 is base/modulo 32bytes and exp 256bit",
        "created_at": "2025-06-25T12:18:17.927000+00:00",
        "attachments": null
    },
    {
        "author": "bridge-bot",
        "category": "Execution Layer",
        "parent": "",
        "content": "\u003cmarcin_d_s\u003e exp 256bit (32bytes) is the max value which is not repriced. Above 256bit there is 2x increase for exp",
        "created_at": "2025-06-25T12:19:07.578000+00:00",
        "attachments": null
    },
    {
        "author": "bridge-bot",
        "category": "Execution Layer",
        "parent": "",
        "content": "\u003camezianehamlat\u003e re: **@marcin_d_s**\n\u003e Besu - 47.3\nAre these results with the new warmup that Kamil talked about or not ?",
        "created_at": "2025-06-25T12:24:49.827000+00:00",
        "attachments": null
    },
    {
        "author": "bridge-bot",
        "category": "Execution Layer",
        "parent": "",
        "content": "\u003cmarcin_d_s\u003e Summarizing, we already covered test case scenarios (base/modulo below 32bytes is priced as 32byte, min price is increased from 200 to 500 which is covering cheap underperforming scenarios, there is also a cost increase for base/modulo/exp above 32bytes which are not commonly used).\nNew worst cases (including 1360 scenario which is a common case) are performing similar. Now the question is - if Geth and Erigon are able (or at least wants to try) improve modexp libraries? If so, would be great to make an attempt. Otherwise, we need to increase the prices even more. As edge-cases are already covered, it would require general cost increase, without aiming any specific scenarios",
        "created_at": "2025-06-25T12:25:13.924000+00:00",
        "attachments": null
    },
    {
        "author": "bridge-bot",
        "category": "Execution Layer",
        "parent": "",
        "content": "\u003cmarcin_d_s\u003e I think it already has new warmup. Machine with standard branches has for sure, this one has it too, right @KamilChNethermind ?",
        "created_at": "2025-06-25T12:28:07.910000+00:00",
        "attachments": null
    },
    {
        "author": "bridge-bot",
        "category": "Execution Layer",
        "parent": "",
        "content": "\u003cKamilChNethermind\u003e re: **@marcin_d_s**\n\u003e I think it already has new warmup. Machine with standard branches has for sure, this one has it too, right @KamilChNethermind ?\nYes",
        "created_at": "2025-06-25T12:28:21.112000+00:00",
        "attachments": null
    },
    {
        "author": "bridge-bot",
        "category": "Execution Layer",
        "parent": "",
        "content": "\u003cnotnotstorm_p\u003e re: **@marcin_d_s**\n\u003e Summarizing, we already covered test case scenarios (base/modulo below 32bytes is priced as 32byte, min price is increased from 200 to 500 which is covering cheap underperforming scenarios, there is also a cost increase for base/modulo/exp above 32bytes which are not commonly used).\nNew worst cases (including 1360 scenario which is a common case) are performing similar. Now the question is - if Geth and Erigon are able (or at least wants to try) improve modexp libraries? If so, would be great to make an attempt. Otherwise, we need to increase the prices even more. As edge-cases are already covered, it would require general cost increase, without aiming any specific scenarios\neven for neth + besu it seems like some of the modexp cases remain underpriced in fusaka",
        "created_at": "2025-06-25T12:29:35.336000+00:00",
        "attachments": null
    },
    {
        "author": "bridge-bot",
        "category": "Execution Layer",
        "parent": "",
        "content": "\u003cnotnotstorm_p\u003e re: **@marcin_d_s**\n\u003e Summarizing, we already covered test case scenarios (base/modulo below 32bytes is priced as 32byte, min price is increased from 200 to 500 which is covering cheap underperforming scenarios, there is also a cost increase for base/modulo/exp above 32bytes which are not commonly used).\nNew worst cases (including 1360 scenario which is a common case) are performing similar. Now the question is - if Geth and Erigon are able (or at least wants to try) improve modexp libraries? If so, would be great to make an attempt. Otherwise, we need to increase the prices even more. As edge-cases are already covered, it would require general cost increase, without aiming any specific scenarios\n(awesome data btw)",
        "created_at": "2025-06-25T12:29:52.627000+00:00",
        "attachments": null
    },
    {
        "author": "bridge-bot",
        "category": "Execution Layer",
        "parent": "",
        "content": "\u003cKamilChNethermind\u003e re: **@notnotstorm_p**\n\u003e even for neth + besu it seems like some of the modexp cases remain underpriced in fusaka\nIMO at least 60Mgas/s should be there after Fusaka - but seems like we can tackle that not only from a pricing perspective but also from pure engineering side to see if there are some better ways handling that in ELs.\n\nBut also kind of agree that we could affect it a bit more from pricing standpoint - eventually with constant gas limit increases we have in plans it will become our bottleneck in a year or so again - so maybe better to revise it once more a bit and see if we can make it at least 100MGas/s+ not to be bothered with that as a threat anytime soon.",
        "created_at": "2025-06-25T12:32:14.562000+00:00",
        "attachments": null
    },
    {
        "author": "bridge-bot",
        "category": "Execution Layer",
        "parent": "",
        "content": "\u003cKamilChNethermind\u003e But first things first - would love to hear from Geth/Erigon/Besu if there are any chances they can see on their end to bump the numbers a bit from some code optimization perspective + maybe lib changes to make it better.\n\nExtra outcome from that - maybe we will make 60MGas limit prior fusaka safe enough",
        "created_at": "2025-06-25T12:33:26.400000+00:00",
        "attachments": null
    },
    {
        "author": "bridge-bot",
        "category": "Execution Layer",
        "parent": "",
        "content": "\u003cparithoshj\u003e I think post fusaka we need to be sure we can get to 100M, so yeah we'd need to hear from the teams by end of the week if we need to reprice or if we can get by with optimisations. Lets say ACDT monday is the deadline for the decision? that way changes can still make it to the devnet-3 scope",
        "created_at": "2025-06-25T12:35:32.798000+00:00",
        "attachments": null
    },
    {
        "author": "bridge-bot",
        "category": "Execution Layer",
        "parent": "",
        "content": "\u003cFunnyGiulio\u003e i dont think you can ever set an hard deadline if you want it by Fusaka unless you are fine not getting to 100M",
        "created_at": "2025-06-25T12:36:19.924000+00:00",
        "attachments": null
    },
    {
        "author": "bridge-bot",
        "category": "Execution Layer",
        "parent": "",
        "content": "\u003cmarcin_d_s\u003e re: **@notnotstorm_p**\n\u003e even for neth + besu it seems like some of the modexp cases remain underpriced in fusaka\nAll edge-cases are already covered, now we can only change the general pricing, for all cases, including common ones. In the modexp pricing formula, at the very end result is divided by 3. We can easily achieve +50% in prices by changing the variable from 3 to 2, or potentially 200% increase by changing it to 1",
        "created_at": "2025-06-25T12:36:20.791000+00:00",
        "attachments": null
    },
    {
        "author": "bridge-bot",
        "category": "Execution Layer",
        "parent": "",
        "content": "\u003cparithoshj\u003e re: **@FunnyGiulio**\n\u003e i dont think you can ever set an hard deadline if you want it by Fusaka unless you are fine not getting to 100M\nah i mean the evaluation, not the result - i.e if it looks like there are possible optimisation paths to take or if its clear there's no safe way forward",
        "created_at": "2025-06-25T12:37:49.947000+00:00",
        "attachments": null
    },
    {
        "author": "bridge-bot",
        "category": "Execution Layer",
        "parent": "",
        "content": "\u003cvdWijden\u003e re: **@KamilChNethermind**\n\u003e But first things first - would love to hear from Geth/Erigon/Besu if there are any chances they can see on their end to bump the numbers a bit from some code optimization perspective + maybe lib changes to make it better.\n\nExtra outcome from that - maybe we will make 60MGas limit prior fusaka safe enough\nWe're using go's standard library, so we would need to ship updates to go std lib in order to change the algorithm to something closer to gmp",
        "created_at": "2025-06-25T12:39:38.410000+00:00",
        "attachments": null
    },
    {
        "author": "bridge-bot",
        "category": "Execution Layer",
        "parent": "",
        "content": "\u003cmarcin_d_s\u003e From strategic point of view, we have modexp heavily underpriced, then ecadd/ecmul/ecpairing/ecrecover with potential of 50-60Mgas/s and then we ale close to 80-100 with other opcodes/precompiles.\nSo IMO we should aim in having modexp after repricing at least at the performance level of reth and nethermind. If other clients are not able to achieve at least 80-90, we shouldn't go with 30, 40 or even 60 as it will require another repricing soon",
        "created_at": "2025-06-25T12:40:18.262000+00:00",
        "attachments": null
    },
    {
        "author": "bridge-bot",
        "category": "Execution Layer",
        "parent": "",
        "content": "\u003cKamilChNethermind\u003e re: **@marcin_d_s**\n\u003e From strategic point of view, we have modexp heavily underpriced, then ecadd/ecmul/ecpairing/ecrecover with potential of 50-60Mgas/s and then we ale close to 80-100 with other opcodes/precompiles.\nSo IMO we should aim in having modexp after repricing at least at the performance level of reth and nethermind. If other clients are not able to achieve at least 80-90, we shouldn't go with 30, 40 or even 60 as it will require another repricing soon\nMarcin I recall that current repricing affects mostly edge cases and in total it was around 1,4% of all modexp usages.\nChanging the formula to not be divided by 3 but by 2 will affect basically each modexp use case, right?",
        "created_at": "2025-06-25T12:42:12.063000+00:00",
        "attachments": null
    },
    {
        "author": "bridge-bot",
        "category": "Execution Layer",
        "parent": "",
        "content": "\u003cnotnotstorm_p\u003e re: **@marcin_d_s**\n\u003e All edge-cases are already covered, now we can only change the general pricing, for all cases, including common ones. In the modexp pricing formula, at the very end result is divided by 3. We can easily achieve +50% in prices by changing the variable from 3 to 2, or potentially 200% increase by changing it to 1\nit's also possible to modify the pricing formula itself rather than just the parameters in the formula\n\nthe slow modexp edge cases...what do they all share in common?",
        "created_at": "2025-06-25T12:42:44.403000+00:00",
        "attachments": null
    },
    {
        "author": "bridge-bot",
        "category": "Execution Layer",
        "parent": "",
        "content": "\u003cmarcin_d_s\u003e Kamil this small % was about cases with base/modulo/exp above 32bytes. Cases with cost 200 are common and it will be affected by increasing to 500",
        "created_at": "2025-06-25T12:43:21.915000+00:00",
        "attachments": null
    },
    {
        "author": "bridge-bot",
        "category": "Execution Layer",
        "parent": "",
        "content": "\u003cKamilChNethermind\u003e re: **@notnotstorm_p**\n\u003e it's also possible to modify the pricing formula itself rather than just the parameters in the formula\n\nthe slow modexp edge cases...what do they all share in common?\nQuestion is if we really feel like formula is bad or we are too conservative with repricings.",
        "created_at": "2025-06-25T12:48:40.698000+00:00",
        "attachments": null
    },
    {
        "author": "bridge-bot",
        "category": "Execution Layer",
        "parent": "",
        "content": "\u003cKamilChNethermind\u003e But also if there is a 3-4x difference between clients it should be tackled at first place",
        "created_at": "2025-06-25T12:49:01.286000+00:00",
        "attachments": null
    },
    {
        "author": "bridge-bot",
        "category": "Execution Layer",
        "parent": "",
        "content": "\u003cmarcin_d_s\u003e re: **@notnotstorm_p**\n\u003e it's also possible to modify the pricing formula itself rather than just the parameters in the formula\n\nthe slow modexp edge cases...what do they all share in common?\nModexp pricing formula has 2 main parts - base/modulo and exp. Edge cases are the ones with one part cheap and the other expensive. With current pricing it is possible to craft a scenario with base 8bytes and exponent 648bit which costs only 215 gas, or base 8bytes and exp 896bit with cost 298 gas.\nAll of it is a theoretical edge-case, as commonly are used only cases with 32byte base/modulo and exp lower than 256bit (with cost 200 or about 1360).\nWhat we did, is:\n1) increased min price from 200 to 500 as common cases with cost 200 were underperforming\n2) if base/modulo is smaller than 32bytes, we are calculating it as it will be 32bytes. We are eliminating underpriced cases with minimal base and superlarge exp\n3) increasing cost significantly if base/modulo/exp is bigger than 32bytes (which is not commonly used)",
        "created_at": "2025-06-25T12:51:31.703000+00:00",
        "attachments": null
    },
    {
        "author": "bridge-bot",
        "category": "Execution Layer",
        "parent": "",
        "content": "\u003cmarcin_d_s\u003e What I see as one more potential small change with big impact is this:\n\u003e In the modexp pricing formula, at the very end result is divided by 3. We can easily achieve +50% in prices by changing the variable from 3 to 2, or potentially 200% increase by changing it to 1 (not dividing at all)",
        "created_at": "2025-06-25T12:53:15.383000+00:00",
        "attachments": null
    },
    {
        "author": "bridge-bot",
        "category": "Execution Layer",
        "parent": "",
        "content": "\u003cmarcin_d_s\u003e There are 2 groups of common cases:\n1) with base/modulo/exp equal 32bytes, but actually small exp - cost 200. Will be affected by repricing to 500\n2) with base/modulo/exp equal 32bytes - cost about 1360 (depending on exact bit length of exp). Not affected by repricing.\n\nThe second group is performing above 90 in neth/reth and below 45 in geth/erigon.",
        "created_at": "2025-06-25T12:56:40.442000+00:00",
        "attachments": null
    },
    {
        "author": "bridge-bot",
        "category": "Execution Layer",
        "parent": "",
        "content": "\u003cmarcin_d_s\u003e After 7883 in current version worst performing are cases with base/modulo equal 32bytes and exponent between 96 and 256 bit (lower costs below 500 so are covered by min price, higher are covered by cost increase for size above 32bytes)",
        "created_at": "2025-06-25T13:07:10.380000+00:00",
        "attachments": null
    },
    {
        "author": "bridge-bot",
        "category": "Execution Layer",
        "parent": "",
        "content": "\u003crkrasiuk\u003e re: **@KamilChNethermind**\n\u003e So for now I have:\nNethermind: performance-repriced\nGeth: performance-modexp\nBesu: performance-modexp\nErigon: performance-modexp\nReth: missing for now\n\nWill create a separate Dashboard on Performance directory which will use above ones and only trigger modexp scenarios - so we can observe and in case of any EIP adjustments make sure to push your changes also in there.\n\nmid-term will transition it into \"Fusaka-enabled\" mode but we need probably to first figure it out with EEST integration as will be two things at once rather than doing that custom way on our end\ndone, branch `performance-modexp`",
        "created_at": "2025-06-25T13:11:00.487000+00:00",
        "attachments": null
    },
    {
        "author": "bridge-bot",
        "category": "Execution Layer",
        "parent": "",
        "content": "\u003cmarcin_d_s\u003e re: **@marcin_d_s**\n\u003e What I see as one more potential small change with big impact is this:\n\u003e In the modexp pricing formula, at the very end result is divided by 3. We can easily achieve +50% in prices by changing the variable from 3 to 2, or potentially 200% increase by changing it to 1 (not dividing at all)\nWith current libraries changing variable from 3 to 2 will not be enough, as worst cases will perform at about 42 instead of 28. So fine for going to 100M, but not higher than 120-130M. If we skip dividing at all, then we are about 80 MGas/s.\nThe disadvantage is that it will mean for common cases to cost 3x (4080 instead of 1360).\nBut we will be able to forget about modexp for years :D",
        "created_at": "2025-06-25T13:19:36.287000+00:00",
        "attachments": null
    },
    {
        "author": "bridge-bot",
        "category": "Execution Layer",
        "parent": "",
        "content": "\u003cchiragparmarme\u003e re: **@KamilChNethermind**\n\u003e Hi @chiragparmarme Can you create a NimbusEL version of branch called \"performance-modexp\" which will have modexp repricing enabled on Cancun fork?\nYessir",
        "created_at": "2025-06-25T13:21:12.304000+00:00",
        "attachments": null
    },
    {
        "author": "bridge-bot",
        "category": "Execution Layer",
        "parent": "",
        "content": "\u003cmarcin_d_s\u003e It is performance of Geth excluding Modexp. As you can see, if we reprice Modexp in Fusaka and ecadd/ecpairing/ecmul/ecrecover in future (Glamsterdam?), we will be at 75MGas/s.\nSo IMO we need to improve libraries/increase pricing/both to have modexp above 75 in Geth.\nIn other clients it looks similar (with individual blockers - Blake2 for Reth, Address and Caller for Erigon, Keccak and a few more for Besu)",
        "created_at": "2025-06-25T13:41:26.107000+00:00",
        "attachments": [
            {
                "type": "image/jpeg",
                "origin_name": "file_60.jpg",
                "content": "d224086758f0c4a8e9ae2a5df08de8d1480ae9b3362058f82121c1c1295daa11"
            }
        ]
    },
    {
        "author": "bridge-bot",
        "category": "Execution Layer",
        "parent": "",
        "content": "\u003cnotnotstorm_p\u003e re: **@vdWijden**\n\u003e We're using go's standard library, so we would need to ship updates to go std lib in order to change the algorithm to something closer to gmp\n@FunnyGiulio mentioned exploring a GMP adapter that erigon and geth could share\n\nwhat do you think about that?",
        "created_at": "2025-06-25T13:45:12.107000+00:00",
        "attachments": null
    },
    {
        "author": "bridge-bot",
        "category": "Execution Layer",
        "parent": "",
        "content": "\u003cnotnotstorm_p\u003e merging significant upstream changes to go's std seams unlikely before fusaka",
        "created_at": "2025-06-25T13:45:17.737000+00:00",
        "attachments": null
    },
    {
        "author": "bridge-bot",
        "category": "Execution Layer",
        "parent": "",
        "content": "\u003cCPerezz\u003e re: **@vdWijden**\n\u003e We're using go's standard library, so we would need to ship updates to go std lib in order to change the algorithm to something closer to gmp\nCheck our discord. I already told Felix I optimized your worst cases 2.5x and the solution could even avoid forking go stdlib",
        "created_at": "2025-06-25T13:47:52.539000+00:00",
        "attachments": null
    },
    {
        "author": "bridge-bot",
        "category": "Execution Layer",
        "parent": "",
        "content": "\u003cmarcin_d_s\u003e Potential next steps - after modexp/ecrecover/bn254, reprice Blake2 and Keccak and we are flying at 120 MGas/s and hitting 300M as expected in Berlinterop opening ;)",
        "created_at": "2025-06-25T13:48:00.208000+00:00",
        "attachments": [
            {
                "type": "image/jpeg",
                "origin_name": "file_61.jpg",
                "content": "502b26d3751cc1b32a59823c25e8ce74ecfd9a2a7367f641da7396ee2b56f6c1"
            }
        ]
    },
    {
        "author": "bridge-bot",
        "category": "Execution Layer",
        "parent": "",
        "content": "\u003cCPerezz\u003e re: **@CPerezz**\n\u003e Check our discord. I already told Felix I optimized your worst cases 2.5x and the solution could even avoid forking go stdlib\nLMK if there's interest. The fork is just to showcase it: https://github.com/CPerezz/go/commit/dba388691d6bca664a5d365f6c0bdbb1955af5a6",
        "created_at": "2025-06-25T13:48:23.607000+00:00",
        "attachments": null
    },
    {
        "author": ".fjl",
        "category": "Execution Layer",
        "parent": "",
        "content": "Hey \u003c@703742742135570499\u003e we will check out your implementation soon!",
        "created_at": "2025-06-25T14:32:18.237000+00:00",
        "attachments": null
    },
    {
        "author": "bridge-bot",
        "category": "Execution Layer",
        "parent": "",
        "content": "\u003cCPerezz\u003e re: **@gas_limit_testing_bot**\n\u003e \u003c.fjl\u003e Hey @cperezz.eth we will check out your implementation soon!\nNo rush at all. Was just for Marius to be aware there's a fix üôÇ",
        "created_at": "2025-06-25T14:36:15.741000+00:00",
        "attachments": null
    },
    {
        "author": "bridge-bot",
        "category": "Execution Layer",
        "parent": "",
        "content": "\u003camezianehamlat\u003e re: **@vdWijden**\n\u003e The test continuously overwrites the first point with the result, thus the input of the precompile is different every call.\ne.g. add(1,2), add(3,2), add(5,2) etc\n@vdWijden What makes this case a worst case scenario ?",
        "created_at": "2025-06-25T15:52:17.584000+00:00",
        "attachments": null
    },
    {
        "author": "bridge-bot",
        "category": "Execution Layer",
        "parent": "",
        "content": "\u003cvdWijden\u003e re: **@amezianehamlat**\n\u003e @vdWijden What makes this case a worst case scenario ?\nYou can't cache it. The input points itself are purely random, not any sophisticated math behind it to optimize the runtime. You might be able to make it a bit worse",
        "created_at": "2025-06-25T15:55:19.731000+00:00",
        "attachments": null
    },
    {
        "author": "bridge-bot",
        "category": "Execution Layer",
        "parent": "",
        "content": "\u003camezianehamlat\u003e re: **@vdWijden**\n\u003e You can't cache it. The input points itself are purely random, not any sophisticated math behind it to optimize the runtime. You might be able to make it a bit worse\nSo it can be even worse with a flat format if we have both points random, right ? I think you said it before but would like to double check",
        "created_at": "2025-06-25T15:56:25.892000+00:00",
        "attachments": null
    },
    {
        "author": "bridge-bot",
        "category": "Execution Layer",
        "parent": "",
        "content": "\u003cvdWijden\u003e Yes it might be a bit worse",
        "created_at": "2025-06-25T15:56:48.296000+00:00",
        "attachments": null
    },
    {
        "author": "bridge-bot",
        "category": "Execution Layer",
        "parent": "",
        "content": "\u003cKamilChNethermind\u003e @marcin_d_s do you think then we can further adjust this Flat ECAdd?",
        "created_at": "2025-06-25T17:47:37.277000+00:00",
        "attachments": null
    },
    {
        "author": "bridge-bot",
        "category": "Execution Layer",
        "parent": "",
        "content": "\u003cmarcin_d_s\u003e yes I can try to make it worse tomorrow",
        "created_at": "2025-06-25T17:56:51.090000+00:00",
        "attachments": null
    }
]