[
    {
        "author": "bridge-bot",
        "category": "Execution Layer",
        "parent": "",
        "content": "\u003cvdWijden\u003e How do y'all feel about adding a unified metric to the engine API (like we have for getBlobsV2 now) that measures the execution time for NewPL and FCU.\nI would propose\n`engine/newpayload/process` and `engine/forkchoiceupdated/process` for the time it takes these methods to process a block (excluding JSON marshaling, block reconstruction) cc @lightclient @lrozmej",
        "created_at": "2025-06-24T07:27:32.027000+00:00",
        "attachments": null
    },
    {
        "author": "bridge-bot",
        "category": "Execution Layer",
        "parent": "",
        "content": "\u003clrozmej\u003e re: **@vdWijden**\n\u003e How do y'all feel about adding a unified metric to the engine API (like we have for getBlobsV2 now) that measures the execution time for NewPL and FCU.\nI would propose\nengine/newpayload/process and engine/forkchoiceupdated/process for the time it takes these methods to process a block (excluding JSON marshaling, block reconstruction) cc @lightclient @lrozmej\nwell easy to say but:\n- How this metric should behave on bulk new payloads (which do happen)\n- Why exclude JSON marshaling and block reconstruction? JSON and RLP deserialization are a part of block processing to some extent.",
        "created_at": "2025-06-24T07:44:03.015000+00:00",
        "attachments": null
    },
    {
        "author": "bridge-bot",
        "category": "Execution Layer",
        "parent": "",
        "content": "\u003clrozmej\u003e This is why the extenral in-between proxy tool was created to measure this reliably",
        "created_at": "2025-06-24T07:44:50.381000+00:00",
        "attachments": null
    },
    {
        "author": "bridge-bot",
        "category": "Execution Layer",
        "parent": "",
        "content": "\u003clrozmej\u003e as it is easy to compare apples to oranges",
        "created_at": "2025-06-24T07:45:18.506000+00:00",
        "attachments": null
    },
    {
        "author": "bridge-bot",
        "category": "Execution Layer",
        "parent": "",
        "content": "\u003cparithoshj\u003e We have this tool that we wanted to add more capabilities to, one could be metrics\n\nhttps://github.com/ethpandaops/rpc-snooper",
        "created_at": "2025-06-24T07:46:55.662000+00:00",
        "attachments": null
    },
    {
        "author": "bridge-bot",
        "category": "Execution Layer",
        "parent": "",
        "content": "\u003cKamilChNethermind\u003e This is the one made by Dmytro for rpc proxy with metrics - so either we can expand that or move some logic to share in both\nhttps://github.com/NethermindEth/jrpc-interceptor",
        "created_at": "2025-06-24T09:13:14.910000+00:00",
        "attachments": null
    },
    {
        "author": "bridge-bot",
        "category": "Execution Layer",
        "parent": "",
        "content": "\u003cKamilChNethermind\u003e Both written in GO as I can see",
        "created_at": "2025-06-24T09:13:28.056000+00:00",
        "attachments": null
    },
    {
        "author": "bridge-bot",
        "category": "Execution Layer",
        "parent": "",
        "content": "\u003cparithoshj\u003e re: **@KamilChNethermind**\n\u003e Both written in GO as I can see\nTime for a merge :D",
        "created_at": "2025-06-24T09:29:20.277000+00:00",
        "attachments": null
    },
    {
        "author": "bridge-bot",
        "category": "Execution Layer",
        "parent": "",
        "content": "\u003cben_a_adams\u003e Note: example from other ecosystems 60M block; 1.4M tx cap https://www.helius.dev/blog/agave-v22-update--all-you-need-to-know",
        "created_at": "2025-06-24T11:00:35.122000+00:00",
        "attachments": [
            {
                "type": "image/jpeg",
                "origin_name": "file_52.jpg",
                "content": "0a89697701afa4f9569b336896f337119ab7e7a4a527dd937ab860ee3a4cf3ba"
            }
        ]
    },
    {
        "author": "bridge-bot",
        "category": "Execution Layer",
        "parent": "",
        "content": "\u003cfede_intern\u003e hi, i'm pretty new to the chat, is there any other similar repo like this one https://github.com/NethermindEth/gas-benchmarks/?",
        "created_at": "2025-06-24T11:04:56.799000+00:00",
        "attachments": null
    },
    {
        "author": "bridge-bot",
        "category": "Execution Layer",
        "parent": "",
        "content": "\u003cfede_intern\u003e we are merging most of our performance related PRs and we started yesterday working on a new database and we want to have a standard suite of performance benchmarks. is there any other similar repo to the one created by nethermind?",
        "created_at": "2025-06-24T11:07:11.937000+00:00",
        "attachments": null
    },
    {
        "author": "bridge-bot",
        "category": "Execution Layer",
        "parent": "",
        "content": "\u003cKamilChNethermind\u003e Above one is most heavily used right now but there is also EEST zkevm benchmarks.\n\nShort/mid term we agreed on standardizing everything in a EEST format so all the tests from gas-benchmarks repo will be moved to EEST with all our dashboards etc.\n\nFeel free if you want to push a PR to gas-benchmarks to add Ethrex support so then it will be automatically propagated to our infra and and tested well.\nWe have all EL clients here and example of how Nimbus did great job pushing support for it very swiftly and worked after first commit: https://github.com/NethermindEth/gas-benchmarks/pull/27",
        "created_at": "2025-06-24T11:17:09.702000+00:00",
        "attachments": null
    },
    {
        "author": "bridge-bot",
        "category": "Execution Layer",
        "parent": "",
        "content": "\u003camezianehamlat\u003e @KamilChNethermind How do we plan to test new princing on ModExp as it should be triggered for Fusaka ? I mean, is it triggered by the test or we need to make it available for current fork, like change the code to make it available for current fork ?",
        "created_at": "2025-06-24T12:03:05.107000+00:00",
        "attachments": null
    },
    {
        "author": "bridge-bot",
        "category": "Execution Layer",
        "parent": "",
        "content": "\u003cKamilChNethermind\u003e What we did in nethermind and Erigon already preapred also is we enaled Modexp EIP On Dencun on custom branch - will add Erigon today to verify if it works fine but this is thet fastest way for now to check it performance wise",
        "created_at": "2025-06-24T12:06:43.840000+00:00",
        "attachments": null
    },
    {
        "author": "bridge-bot",
        "category": "Execution Layer",
        "parent": "",
        "content": "\u003cKamilChNethermind\u003e Functional tests to ensure same pricing will be covered in EEST",
        "created_at": "2025-06-24T12:07:02.583000+00:00",
        "attachments": null
    },
    {
        "author": "bridge-bot",
        "category": "Execution Layer",
        "parent": "",
        "content": "\u003camezianehamlat\u003e re: **@KamilChNethermind**\n\u003e What we did in nethermind and Erigon already preapred also is we enaled Modexp EIP On Dencun on custom branch - will add Erigon today to verify if it works fine but this is thet fastest way for now to check it performance wise\nI just pushed the new modexp pricing for cancun (that is scheduled for Fusaka) to besu performance branch as well, if you can integrate it in the next run",
        "created_at": "2025-06-24T13:34:45.055000+00:00",
        "attachments": null
    },
    {
        "author": "bridge-bot",
        "category": "Execution Layer",
        "parent": "",
        "content": "\u003cKamilChNethermind\u003e Spent some time reviving warmup as wasn't good enough last time I approached it but now made a proper experiment with nethermind besu and reth as representatives. Very dummy results but showing how much does it affect performance of clients when I isolated only one scenario (Origin).\n\nWhen running multiple tests at once results are not as clear but when only executing one we were veery surprised.\n\nThis kind of result still makes me a bit unsure but results are very accurate with expectations - just way above expectations in terms of poor perf without warming for Nethermind.",
        "created_at": "2025-06-24T14:47:59.148000+00:00",
        "attachments": [
            {
                "type": "image/jpeg",
                "origin_name": "file_53.jpg",
                "content": "35ecf873c1ee167bd13690a020729d4b564a26096a06f20cc36be5632503be81"
            }
        ]
    },
    {
        "author": "bridge-bot",
        "category": "Execution Layer",
        "parent": "",
        "content": "\u003cKamilChNethermind\u003e Doing another one now on all clients on Coinbase to see if results will be similar",
        "created_at": "2025-06-24T14:52:19.614000+00:00",
        "attachments": null
    },
    {
        "author": "bridge-bot",
        "category": "Execution Layer",
        "parent": "",
        "content": "\u003cfede_intern\u003e re: **@KamilChNethermind**\n\u003e Spent some time reviving warmup as wasn't good enough last time I approached it but now made a proper experiment with nethermind besu and reth as representatives. Very dummy results but showing how much does it affect performance of clients when I isolated only one scenario (Origin).\n\nWhen running multiple tests at once results are not as clear but when only executing one we were veery surprised.\n\nThis kind of result still makes me a bit unsure but results are very accurate with expectations - just way above expectations in terms of poor perf without warming for Nethermind.\ndo you have the code to replicate this? thanks!",
        "created_at": "2025-06-24T15:43:07.427000+00:00",
        "attachments": null
    },
    {
        "author": "bridge-bot",
        "category": "Execution Layer",
        "parent": "",
        "content": "\u003cKamilChNethermind\u003e re: **@fede_intern**\n\u003e do you have the code to replicate this? thanks!\nThis expeirment is in gas-benchmarks on branch \"feat/add-scenarios-warmup-single-file-mode\" where I added filtering of scenarios + warmingu up configurable",
        "created_at": "2025-06-24T15:43:55.728000+00:00",
        "attachments": null
    },
    {
        "author": "bridge-bot",
        "category": "Execution Layer",
        "parent": "",
        "content": "\u003cfede_intern\u003e thanks!",
        "created_at": "2025-06-24T15:44:43.527000+00:00",
        "attachments": null
    },
    {
        "author": "bridge-bot",
        "category": "Execution Layer",
        "parent": "",
        "content": "\u003cfede_intern\u003e great work by the way, the repo is very cool",
        "created_at": "2025-06-24T15:44:55.639000+00:00",
        "attachments": null
    },
    {
        "author": "bridge-bot",
        "category": "Execution Layer",
        "parent": "",
        "content": "\u003cKamilChNethermind\u003e Similar test now without vs Single Warmup on CoinBase",
        "created_at": "2025-06-24T15:48:38.379000+00:00",
        "attachments": [
            {
                "type": "image/jpeg",
                "origin_name": "file_54.jpg",
                "content": "b826cd2f713bf617c2d519a63fee9279e484da3311070816bb637ea49e610435"
            }
        ]
    },
    {
        "author": "bridge-bot",
        "category": "Execution Layer",
        "parent": "",
        "content": "\u003cKamilChNethermind\u003e BTW - wanted to learn about readiness of each EL for 45Mgas limit.\n\nin nethermind we fight with some regressions now but probably release will be ready by the end of this week with 45MGas default. What about the others?\n@amezianehamlat @FunnyGiulio @vdWijden @shekhirin",
        "created_at": "2025-06-24T15:52:02.670000+00:00",
        "attachments": null
    },
    {
        "author": "bridge-bot",
        "category": "Execution Layer",
        "parent": "",
        "content": "\u003cvdWijden\u003e We will have out a release this week with 45M",
        "created_at": "2025-06-24T16:00:21.776000+00:00",
        "attachments": null
    },
    {
        "author": "bridge-bot",
        "category": "Execution Layer",
        "parent": "",
        "content": "\u003camezianehamlat\u003e re: **@KamilChNethermind**\n\u003e BTW - wanted to learn about readiness of each EL for 45Mgas limit.\n\nin nethermind we fight with some regressions now but probably release will be ready by the end of this week with 45MGas default. What about the others?\n@amezianehamlat @FunnyGiulio @vdWijden @shekhirin\nAlready merged into main on besu side just after Interop",
        "created_at": "2025-06-24T16:01:15.817000+00:00",
        "attachments": null
    },
    {
        "author": "bridge-bot",
        "category": "Execution Layer",
        "parent": "",
        "content": "\u003cKamilChNethermind\u003e re: **@amezianehamlat**\n\u003e Already merged into main on besu side just after Interop\nWhat about release with it? :)",
        "created_at": "2025-06-24T16:01:57.386000+00:00",
        "attachments": null
    },
    {
        "author": "bridge-bot",
        "category": "Execution Layer",
        "parent": "",
        "content": "\u003cKamilChNethermind\u003e Hopefully - with all of the recent great performance fixes",
        "created_at": "2025-06-24T16:02:10.120000+00:00",
        "attachments": null
    },
    {
        "author": "bridge-bot",
        "category": "Execution Layer",
        "parent": "",
        "content": "\u003camezianehamlat\u003e re: **@KamilChNethermind**\n\u003e What about release with it? :)\nNot released yet, it should be in the next few days, I will update here.",
        "created_at": "2025-06-24T17:11:11.465000+00:00",
        "attachments": null
    }
]