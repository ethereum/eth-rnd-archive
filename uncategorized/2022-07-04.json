[
    {
        "author": "sky.cactus",
        "category": "general",
        "parent": "",
        "content": "We shouldn't assume that capital distribution remains as it is.  When designing the protocol, we generally try to design for worst case scenarios, and in this case the worst case scenario is that everyone has increments of 32 ETH.",
        "created_at": "2022-07-04T01:04:27.714000+00:00",
        "attachments": null
    },
    {
        "author": "sky.cactus",
        "category": "general",
        "parent": "",
        "content": "Money can consolidate very quickly.  Imagine you had a 100,000,000 ETH, but you stored them all in wallets with 10 ETH each per wallet (so 10,000,000 wallets).  It would cost you 210B gas to consolidate all of that into one account, which would take ~168,0000 blocks (2800 minutes, 46 hours, ~2 days).  That isn't enough time for us to \"quickly get a patch out\".",
        "created_at": "2022-07-04T08:28:50.180000+00:00",
        "attachments": null
    },
    {
        "author": "sky.cactus",
        "category": "general",
        "parent": "",
        "content": "Pragmatically no, but we need to design a system that is resilient against the worst case scenario to ensure that an attack vector isn't created.",
        "created_at": "2022-07-04T10:02:46.655000+00:00",
        "attachments": null
    },
    {
        "author": "sky.cactus",
        "category": "general",
        "parent": "",
        "content": "Any number we choose *other* than the worst case scenario will be arbitrary.  It is far simpler to just build against the worst case scenario than to try to pick a number that is \"a bit more risky, but not risky enough to worry about\".",
        "created_at": "2022-07-04T10:36:44.011000+00:00",
        "attachments": null
    },
    {
        "author": "sky.cactus",
        "category": "general",
        "parent": "",
        "content": "I think the right solution is to engineer things such that we can support more simultaneous validators, but that takes time.",
        "created_at": "2022-07-04T10:48:11.934000+00:00",
        "attachments": null
    },
    {
        "author": "sky.cactus",
        "category": "general",
        "parent": "",
        "content": "For example, one could *imagine* a hypothetical world where we support pre-aggregation (offline) so many smaller validators could coordinate on some secondary gossip network to aggregate their signatures, then submit a batch of votes at once or something (note: this is just brainstorming, likely won't actually work as described).",
        "created_at": "2022-07-04T10:49:15.271000+00:00",
        "attachments": null
    },
    {
        "author": "potuz",
        "category": "general",
        "parent": "",
        "content": "I think the functionality of this is the same as that of a SSV, which by the way completely solves the complain of im.",
        "created_at": "2022-07-04T11:10:46.348000+00:00",
        "attachments": null
    },
    {
        "author": "sky.cactus",
        "category": "general",
        "parent": "",
        "content": "SSV?",
        "created_at": "2022-07-04T11:11:10.710000+00:00",
        "attachments": null
    },
    {
        "author": "potuz",
        "category": "general",
        "parent": "",
        "content": "Secret shared validator: you can get a few people with less than 32ETH to run one validator if they collectively hold 32 eth",
        "created_at": "2022-07-04T11:11:59.841000+00:00",
        "attachments": null
    },
    {
        "author": "potuz",
        "category": "general",
        "parent": "",
        "content": "Their stake is socialized so they are collectively liable and their vote is also collectively counted, so this is effectively like aggregating a bunch of signatures off line",
        "created_at": "2022-07-04T11:12:58.061000+00:00",
        "attachments": null
    },
    {
        "author": "potuz",
        "category": "general",
        "parent": "",
        "content": "With the advantage that each part is slashable",
        "created_at": "2022-07-04T11:13:12.231000+00:00",
        "attachments": null
    },
    {
        "author": "potuz",
        "category": "general",
        "parent": "",
        "content": "But only as a whole",
        "created_at": "2022-07-04T11:13:24.316000+00:00",
        "attachments": null
    },
    {
        "author": "potuz",
        "category": "general",
        "parent": "",
        "content": "1-  no, individuals cannot leave/join, only the full validator can leave/join when the signature threshold has been achieved. \n2- offline people are not individually punished, only as a whole when they are enough to make the validator offline.\nCaveat to 1 and 2: other members achieving threshold can remove individuals from the shared signature. \n3- consensus is defined by the Shamir Secret Sharing threshold the group chooses. \n4- Same as for a full validator. \n5- depending on the consensus mechanism, if you choose 90% then yes, you can have 9% to be honest and still be slashed. \nIn general I see your discussion as completely pointless cause it does not matter what capital distrubution we have now: we cannot handle full validators with less than 32 ETH, period. There is nothing we can do at the moment.",
        "created_at": "2022-07-04T11:42:50.145000+00:00",
        "attachments": null
    },
    {
        "author": "sky.cactus",
        "category": "general",
        "parent": "",
        "content": "Ah, shared secret validator is quite different IMO.  It requires you trust the other parties you are sharing with.  Some kind of signature aggregation scheme wouldn't require any trust.",
        "created_at": "2022-07-04T11:48:44.621000+00:00",
        "attachments": null
    },
    {
        "author": "sky.cactus",
        "category": "general",
        "parent": "",
        "content": "When I say signature aggregation, I mean a bunch of people who don't know each other aggregate their signatures offline (on some secondary gossip network) and then the batch of signatures is submitted at once.  You don't need to know/trust any of the other parties, you just need *someone* to pool your signature with to reach some threshold (e.g., 32 ETH) collectively.",
        "created_at": "2022-07-04T11:50:08.216000+00:00",
        "attachments": null
    },
    {
        "author": "sky.cactus",
        "category": "general",
        "parent": "",
        "content": "You could make it so you can only pool with people who sign the same way as you, then you would just gossip on this secondary network what you are signing over and you would find others signing over the same thing to pool with.",
        "created_at": "2022-07-04T11:50:39.442000+00:00",
        "attachments": null
    },
    {
        "author": "sky.cactus",
        "category": "general",
        "parent": "",
        "content": "Would need special consideration for block building (maybe these validators don't get block production opportunity?).  My point here isn't to provide a full solution, only to argue that I think the solution is \"do engineering work that will result in lower overhead per validator so we can support more validators\".",
        "created_at": "2022-07-04T11:51:37.896000+00:00",
        "attachments": null
    },
    {
        "author": "potuz",
        "category": "general",
        "parent": "",
        "content": "yeah I understood what you wanted, but when I started to think about implementations of this the natural result is some form of L2 for staking. And then the analog of the sequencer, or whomever sends the aggregation, can be slashed. Then there are a couple of options, either we socialize the loses and you end up effectively with an SSV, or you have a way of charging the individual parties for the slashing, but this latter is impossible if you want to allow individuals with very little stake.",
        "created_at": "2022-07-04T11:57:04.673000+00:00",
        "attachments": null
    },
    {
        "author": "sky.cactus",
        "category": "general",
        "parent": "",
        "content": "Oh, I am suggesting this is built-in to L1, not that we develop some purely L2 solution.",
        "created_at": "2022-07-04T11:58:40.688000+00:00",
        "attachments": null
    },
    {
        "author": "sky.cactus",
        "category": "general",
        "parent": "",
        "content": "Meaning, the consensus layer actually understands these aggregate signatures and how to reward/punish individual validators in the group (or if we require everyone signs the same, then rewards the group as a whole).",
        "created_at": "2022-07-04T11:59:09.703000+00:00",
        "attachments": null
    },
    {
        "author": "sky.cactus",
        "category": "general",
        "parent": "",
        "content": "I am relatively against multiple distinct actors getting together and pooling ETH to stake, this doesn't help us achieve the goal of as many independent actors participating in staking as possible.",
        "created_at": "2022-07-04T11:59:38.212000+00:00",
        "attachments": null
    },
    {
        "author": "sky.cactus",
        "category": "general",
        "parent": "",
        "content": "I hypothesize that we can achieve this by requiring people to pool *per vote*, but they wouldn't need to pool and then all vote as a block.",
        "created_at": "2022-07-04T12:00:19.411000+00:00",
        "attachments": null
    },
    {
        "author": "sky.cactus",
        "category": "general",
        "parent": "",
        "content": "So each time I sign something, I throw my signature in with a bunch of other people who signed the same way (totaling to 32 ETH or something) and then we cast a collective vote, but then 12 seconds later I could aggregate my vote with a totally different set of people.",
        "created_at": "2022-07-04T12:01:01.672000+00:00",
        "attachments": null
    },
    {
        "author": "potuz",
        "category": "general",
        "parent": "",
        "content": "Yeah so a second layer of aggregation has been proposed in the past I think, sort of having aggregators of aggregators. The problem with this if I recall correctly is that finding peers becomes impossible",
        "created_at": "2022-07-04T12:01:03.468000+00:00",
        "attachments": null
    },
    {
        "author": "sky.cactus",
        "category": "general",
        "parent": "",
        "content": "Hmm, that *feels* like a solvable problem to me, but I haven't thought much about it.",
        "created_at": "2022-07-04T12:01:24.703000+00:00",
        "attachments": null
    },
    {
        "author": "sky.cactus",
        "category": "general",
        "parent": "",
        "content": "Most of the time, everyone agrees and there are lots of people to aggregate with.",
        "created_at": "2022-07-04T12:01:53.411000+00:00",
        "attachments": null
    },
    {
        "author": "potuz",
        "category": "general",
        "parent": "",
        "content": "I think the problem was to shuffle the aggregators: you'd have a subset of validators that are aggregating say for the first layer, and if you are attesting in a committe N, you need to reach these aggregators. The number of committees increases a lot with these schemes, so finding the aggregators becomes harder. But I stop here since  this is a topic that I don't know anything about.",
        "created_at": "2022-07-04T12:04:06.612000+00:00",
        "attachments": null
    },
    {
        "author": "sky.cactus",
        "category": "general",
        "parent": "",
        "content": "I was imagining a permissionless system where anyone could aggregate, though I can see how that could be tricky since two partial-validators could end up getting aggregated by two different aggregators.  Certainly a non-trivial problem.",
        "created_at": "2022-07-04T12:06:32.676000+00:00",
        "attachments": null
    }
]