[
    {
        "author": "pdobacz",
        "category": "Testing",
        "parent": "",
        "content": "Hey, I'm thinking about tackling adding EEST tests for interactions between RJUMPx and CALLF-family of instructions, from the PoV of stack validation mainly. I think we're missing this coverage right now (if I missed it, LMK)\n\nI'm toying with the idea of generating the validated containers automatically from \"puzzles\" of different code blocks and code sections, calling each other and r-jumping in different constellations. I'm wondering if this is feasible at all (compared to just working interesting edge cases out by hand).\n\nAlso, I'm wondering if it would be an option to have generators like `eof_test(no_expectations_on_validity=True)`, whereby the validity/exception is not checked during filling, but rather taken from the fill result? There would then be some (manual or automatic) post-check that some of the codes generated were actually valid. For example, the check could check that for each test parameter value, there would exist at least one test coming out valid, in other words there are no param values which never make sense. Such approach would make it easier to explore exotic codes without reasoning too much about validity of each individual case.",
        "created_at": "2024-09-11T17:01:35.913000+00:00",
        "attachments": null
    },
    {
        "author": "_shemnon",
        "category": "Testing",
        "parent": "",
        "content": "For besu, validation is always part of container parsing, `no_expectations_on_validity=True` would require code changes.  If validation proves to be a measurable performance hit we will split layout parsing from validation, but at curent limits it's not worth the effort.",
        "created_at": "2024-09-11T18:08:51.308000+00:00",
        "attachments": null
    }
]