[
    {
        "author": "bridge-bot",
        "category": "general",
        "parent": "",
        "content": "\u003cdjaganche\u003e from my perspective 3 things that could happen:\n\n1. Have validity proof in production and secure with existing MPT with keccak very performant (less than 12 seconds for 30M gas block) with proof systems like the one you just shared (binius) - (keeps everything the same)\n\n2. Simply change keccak to something like poseidon but considered safe and well-tested(keep the 2 tries structure (account trie and storage trie) but very zk-friendly hash - in case of poseidon there's parameters debate). \n\n3. Together work towards having better docs and understanding for verkle for both ethereum and L2s. (verkle roadmap with 1 trie and banderwagon EC add and mul). Which includes adding BLS12-381 precompile as a good first step. This also helps having \"stateless verification of the chain\" with very well tested software like geth, besu, nethermind etc.\n\n\nI don't see binary trie or sparse MPT as an option since that would mean not doing the verkle and most time costly thing when developing new trie in ethereum client is not the trie itself but changes to the interfaces (p2p, database, block headers ... whatever, i'm not an expert on this, but Guillaume Ballet mentioned that)",
        "created_at": "2023-11-23T00:07:28.192000+00:00",
        "attachments": null
    },
    {
        "author": "bridge-bot",
        "category": "general",
        "parent": "",
        "content": "\u003cdjaganche\u003e consider my comments biased towards verkle since i've worked on it past 6 months",
        "created_at": "2023-11-23T00:09:58.198000+00:00",
        "attachments": null
    },
    {
        "author": "bridge-bot",
        "category": "general",
        "parent": "",
        "content": "\u003cmratsim\u003e verkle was motivated by space use. I.e. running a node should be possible on consumer hardware.\n\nWe need 2TB SSDs these days.\n\nAlso having verkle means we get more flexibility to augment frequency or gas limit, leaving mostly bandwidth as the bottleneck. (re @djaganche: from my perspective 3 things that could happen:\n\n1. Have validity proof in production and secure with existing MPT with keccak very performant (less than 12 seconds for 30M gas block) with proof systems like the one you just shared (binius) - (keeps everything the same)\n\n2. Simply change keccak to something like poseidon but considered safe and well-tested(keep the 2 tries structure (account trie and storage trie) but very zk-friendly hash - in case of poseidon there's parameters debate). \n\n3. Together work towards having better docs and understanding for verkle for both ethereum and L2s. (verkle roadmap with 1 trie and banderwagon EC add and mul). Which includes adding BLS12-381 precompile as a good first step. This also helps having \"stateless verification of the chain\" with very well tested software like geth, besu, nethermind etc.\n\n\nI don't see binary trie or sparse MPT as an option since that would mean not doing the verkle and most time costly thing when developing new trie in ethereum client is not the trie itself but changes to the interfaces (p2p, database, block headers ... whatever, i'm not an expert on this, but Guillaume Ballet mentioned that))",
        "created_at": "2023-11-23T00:12:46.027000+00:00",
        "attachments": null
    },
    {
        "author": "bridge-bot",
        "category": "general",
        "parent": "",
        "content": "\u003casqyzeron\u003e \u003e Also some of the considerations that existed in the past:\n\u003e - not enough production grade BLS12-381 implementations\n\u003e - EVM384 (or eWASM or Weierstrudel) obsoleting the need of cryptography precompiles\n\u003e\n\u003e are not true anymore.\n\nEVMMAX is still very much a topic, eventhough it doesn't attract a lot of attention at the moment.\n\nAlso, the BLS precompile was rejected at the time because of its complexity. That problem hasn't gone away, and even though it was implemented in many (but not all) clients, it never met the quality standards to be included.\n\nNone of that means the BLS precompile shouldn't be added (I think it should), but this isn't going to be part of a simple, quick fork. (re @mratsim: We had a discussion during ProgCrypto of the impact of Verkle Tries for zkEVM.\n\nDiscussion with at least:\n\n- \u003c@427491045308235776\u003e\n- @adietrichs \n- Onur Kilic\n- @dankrad \n- Mary Maller\n- @CPerezz \n\nAnd I'm missing some names.\n\nBasically, introducing the BLS precompiles (https://eips.ethereum.org/EIPS/eip-2537, note they might need a refresh) could significantly ease their proving cost if zkEVMs switch to BLS12-381 curves.\n\nAlso some of the considerations that existed in the past:\n- not enough production grade BLS12-381 implementations\n- EVM384 (or eWASM or Weierstrudel) obsoleting the need of cryptography precompiles\n\nare not true anymore.\n\nFurthermore the precompile has been implemented but not activated since Berlin hardfork (except for OpenEthereum who activated it by mistake and took down Etherscan for 36h))",
        "created_at": "2023-11-23T06:47:09.645000+00:00",
        "attachments": null
    },
    {
        "author": "bridge-bot",
        "category": "general",
        "parent": "",
        "content": "\u003casqyzeron\u003e \u003e A smaller fork with few changes before (maybe) verkle\n\nPressing the point: it's not a small change (it would have been included in a previous fork otherwise).\n\nI also don't think we should hurry  to add this precompile before verkle: unless L2 decide they want to adopt verkle, and at the same time as L1 (neither seem the consensus to me at the moment), it can be pushed back instead of delaying a time-sensitive fork. (re @CarlBeek: To add to this, I think there's scope to potentially include EIP-2537 in the L1 EL fork after Dencun. A smaller fork with few changes before (maybe) verkle)",
        "created_at": "2023-11-23T06:54:32.218000+00:00",
        "attachments": null
    },
    {
        "author": "bridge-bot",
        "category": "general",
        "parent": "",
        "content": "\u003cmratsim\u003e \u003e The precompile seems to me like a small change because there is no backward compat considerations, do you know what decided people to delay it? or maybe roughly the ACD where it was decided? (re @asqyzeron: \u003e A smaller fork with few changes before (maybe) verkle\n\nPressing the point: it's not a small change (it would have been included in a previous fork otherwise).\n\nI also don't think we should hurry  to add this precompile before verkle: unless L2 decide they want to adopt verkle, and at the same time as L1 (neither seem the consensus to me at the moment), it can be pushed back instead of delaying a time-sensitive fork.)",
        "created_at": "2023-11-23T07:52:03.820000+00:00",
        "attachments": null
    },
    {
        "author": "bridge-bot",
        "category": "general",
        "parent": "",
        "content": "\u003cmratsim\u003e Overhead seems to be about 1.66x slower with BLS12-81 with my benches for MSM on G1 (re @icemelon: verification is definitely expensive withou bls12-381 precopmile. proving cost with bls12-381 and recursion / aggregation cost will also become higher than bn254 because the curve field operation has more bits (381 vs 254). we need to do more performance benchmark to understand the overhead of switching over to bls12-381 curve)",
        "created_at": "2023-11-23T07:52:48.492000+00:00",
        "attachments": null
    },
    {
        "author": "bridge-bot",
        "category": "general",
        "parent": "",
        "content": "\u003cmratsim\u003e BN254 on G1",
        "created_at": "2023-11-23T07:53:01.500000+00:00",
        "attachments": [
            {
                "type": "image/jpeg",
                "origin_name": "file_1.jpg",
                "content": "73113359d76732404fa396df9b7d316789f399261ea167f822365b4c5b3675b8"
            }
        ]
    },
    {
        "author": "bridge-bot",
        "category": "general",
        "parent": "",
        "content": "\u003cmratsim\u003e BLS12-381 on G1",
        "created_at": "2023-11-23T07:53:13.680000+00:00",
        "attachments": [
            {
                "type": "image/jpeg",
                "origin_name": "file_2.jpg",
                "content": "0cd41a111dd1c3e516f9d1ab34a5369cddbafb8bea18ed1b4d1abb94d741bc6d"
            }
        ]
    },
    {
        "author": "bridge-bot",
        "category": "general",
        "parent": "",
        "content": "\u003cmratsim\u003e comparing without multithreading",
        "created_at": "2023-11-23T07:53:25.396000+00:00",
        "attachments": null
    },
    {
        "author": "bridge-bot",
        "category": "general",
        "parent": "",
        "content": "\u003cCPerezz\u003e Hey all!\n\nI'll be trying to meet with all of the L2's (from PSE standpoint) to gather all the tradeoffs, difficulties and to get a better understanding about the Verkle tree integration.\n\nSome things I've discussed so far:\n- For STARK-based ZKEVMS, they seem to only need to impl the BLS-Precompile and, change their last aggregation stark to run over BLS12-381 field instead of BN.\n- Reduce keccak costs can be significative enough to desire the change to Verkle for type-1 ZKEVMs or Proof of Validity.\n- For non-type1 ZKEVMs, they simply don't care that much aside from the BLS Precompile. As for the slowdown in MSM (blst is fast as hell anyways)\n\nI hope to gather feedback from everyone and get back to you in the next Verkle Implementors call as discussed with @asqyzeron (re @asqyzeron: \u003e A smaller fork with few changes before (maybe) verkle\n\nPressing the point: it's not a small change (it would have been included in a previous fork otherwise).\n\nI also don't think we should hurry  to add this precompile before verkle: unless L2 decide they want to adopt verkle, and at the same time as L1 (neither seem the consensus to me at the moment), it can be pushed back instead of delaying a time-sensitive fork.)",
        "created_at": "2023-11-23T07:57:00.676000+00:00",
        "attachments": null
    },
    {
        "author": "bridge-bot",
        "category": "general",
        "parent": "",
        "content": "\u003cmratsim\u003e Reproducing, install clang and nim v1.6.16 (regression in integer generic, fix scheduled in v2.0.2 for the v2 series)\n```\ngit clone https://github.com/mratsim/constantine\ncd constantine\nCC=clang nimble bench_ec_msm_bn254_snarks_g1\nCC=clang nimble bench_ec_msm_bls12_381_g1```",
        "created_at": "2023-11-23T07:57:00.847000+00:00",
        "attachments": null
    },
    {
        "author": "bridge-bot",
        "category": "general",
        "parent": "",
        "content": "\u003cCPerezz\u003e Is Bls12-381 based on Blst?? (re @mratsim: Reproducing, install clang and nim v1.6.16 (regression in integer generic, fix scheduled in v2.0.2 for the v2 series)\ngit clone https://github.com/mratsim/constantine\ncd constantine\nCC=clang nimble bench_ec_msm_bn254_snarks_g1\nCC=clang nimble bench_ec_msm_bls12_381_g1)",
        "created_at": "2023-11-23T07:57:22.796000+00:00",
        "attachments": null
    },
    {
        "author": "bridge-bot",
        "category": "general",
        "parent": "",
        "content": "\u003cmratsim\u003e My impl is significantly faster than BLST (re @CPerezz: Is Bls12-381 based on Blst??)",
        "created_at": "2023-11-23T07:57:42.823000+00:00",
        "attachments": null
    },
    {
        "author": "bridge-bot",
        "category": "general",
        "parent": "",
        "content": "\u003cmratsim\u003e you have detailed serial benchmarks vs blst and gnark here: https://github.com/mratsim/constantine/pull/220 (re @CPerezz: Is Bls12-381 based on Blst??)",
        "created_at": "2023-11-23T07:59:04.564000+00:00",
        "attachments": null
    },
    {
        "author": "bridge-bot",
        "category": "general",
        "parent": "",
        "content": "\u003cCPerezz\u003e Unsure if 1.66x slowdonw in MSM pays off for all the keccak reductions. \nStill we need to consider Type 2/3s where they can simply not support Verkle and have still binary trees they will just loose performance as they don't support keccak either (re @mratsim: My impl is significantly faster than BLST)",
        "created_at": "2023-11-23T07:59:36.177000+00:00",
        "attachments": null
    },
    {
        "author": "bridge-bot",
        "category": "general",
        "parent": "",
        "content": "\u003cmratsim\u003e And for pasta-msm (from Supranational as well): https://github.com/mratsim/constantine/pull/243#issuecomment-1570232834",
        "created_at": "2023-11-23T07:59:41.337000+00:00",
        "attachments": null
    },
    {
        "author": "bridge-bot",
        "category": "general",
        "parent": "",
        "content": "\u003cmratsim\u003e there is also the security angle, 98~110 bit of security for BN254.\n\nBut adding the precompiles does not remove the option to use BN254.\n\nUnless we're talking about not shipping Verkle at all? (re @CPerezz: Unsure if 1.66x slowdonw in MSM pays off for all the keccak reductions. \nStill we need to consider Type 2/3s where they can simply not support Verkle and have still binary trees they will just loose performance as they don't support keccak either)",
        "created_at": "2023-11-23T08:01:31.718000+00:00",
        "attachments": null
    },
    {
        "author": "bridge-bot",
        "category": "general",
        "parent": "",
        "content": "\u003cmratsim\u003e An alternative would be to stay on BN254 and use Goblin Plonk, though I can't read their Elliptic Curve Virtual Machine article here https://hackmd.io/@aztec-network/BkGNaHUJn/%2FPJWE1lpSQqaWKQbYajwf1g (cc \u003c@427491045308235776\u003e )",
        "created_at": "2023-11-23T08:05:07.763000+00:00",
        "attachments": null
    },
    {
        "author": "bridge-bot",
        "category": "general",
        "parent": "",
        "content": "\u003cmratsim\u003e Besides type-1 zkEVM, coprocessors companies (Axiom, Lagrange, ...) are probably the most impacted by the Verkle Trees change because they have no choice but to follow L1 (re @CPerezz: Unsure if 1.66x slowdonw in MSM pays off for all the keccak reductions. \nStill we need to consider Type 2/3s where they can simply not support Verkle and have still binary trees they will just loose performance as they don't support keccak either)",
        "created_at": "2023-11-23T08:09:04.800000+00:00",
        "attachments": null
    },
    {
        "author": "bridge-bot",
        "category": "general",
        "parent": "",
        "content": "\u003cCPerezz\u003e Fair point. But they are suffering from keccak quite a lot. In any case, agree it would be a pain. I'll also chat to them to gather more feedback!\n\nWe will always find reasons not to do somehting ofc. But it's about finding out if it benefits most of the ecosystem I assume. And how to make it less painful for the rest who aren't benefited. (re @mratsim: Besides type-1 zkEVM, coprocessors companies (Axiom, Lagrange, ...) are probably the most impacted by the Verkle Trees change because they have no choice but to follow L1)",
        "created_at": "2023-11-23T08:11:03.842000+00:00",
        "attachments": null
    },
    {
        "author": "bridge-bot",
        "category": "general",
        "parent": "",
        "content": "\u003cmratsim\u003e Note that for 2^16 = 65536 and 2^18 - 262k points,\nConstantine BLS12-381G1 MSM is between 2x faster to 1.5x faster halo2curves BN254 MSM",
        "created_at": "2023-11-23T08:55:49.735000+00:00",
        "attachments": [
            {
                "type": "image/jpeg",
                "origin_name": "file_3.jpg",
                "content": "9f9a6b1fa6495c0288f6c4a405f985c966e30f808aa6a4d13299bfacaf5dca44"
            }
        ]
    },
    {
        "author": "bridge-bot",
        "category": "general",
        "parent": "",
        "content": "\u003cmratsim\u003e Note that for 2^16 = 65536 and 2^18 - 262k points,\nConstantine BLS12-381G1 MSM is between 1.9x faster to 1.5x faster halo2curves BN254 MSM",
        "created_at": "2023-11-23T08:56:19.279000+00:00",
        "attachments": [
            {
                "type": "image/jpeg",
                "origin_name": "file_3.jpg",
                "content": "9f9a6b1fa6495c0288f6c4a405f985c966e30f808aa6a4d13299bfacaf5dca44"
            }
        ]
    },
    {
        "author": "bridge-bot",
        "category": "general",
        "parent": "",
        "content": "\u003cmratsim\u003e Adding Advaita and Agnish who are implementing Verkle Trees as part as EF Fellowship program and found an interesting Verkle Trees in circuit impl.",
        "created_at": "2023-11-23T12:03:41.573000+00:00",
        "attachments": null
    },
    {
        "author": "bridge-bot",
        "category": "general",
        "parent": "",
        "content": "\u003cagnxsh\u003e https://github.com/nikkolasg/halo2-circuits although this uses Pasta with Blake2 in transcript afaik",
        "created_at": "2023-11-23T12:12:38.247000+00:00",
        "attachments": null
    },
    {
        "author": "bridge-bot",
        "category": "general",
        "parent": "",
        "content": "\u003casqyzeron\u003e I asked that question during our team meeting today, and here is what came out of it:\n\n- these BLS precompiles are outdated, but upgrading them should not be a problem\n- if kilic can still be used, then we have done a lot of fuzzing and we are quite confident that this could be part of a small fork\n- we need to have a backup library, because none of us are crypto experts and if something goes wrong, we must be able to have a fallback. This is what we do with the kzg library.\n- we didn't proceed with these BLS precompiles because EVMMAX was making progress with great strides back then, and that is still our favorite option.\n- the risk with adding these precompiles in a smaller fork is that there is no such thing as a small fork and it's a slippery slope\n\nTLDR the feedback is that the BLS precompiles shouldn't be too much work for us after all, but great care has to be taken that this doesn't turn into a major fork. (re @mratsim: \u003e The precompile seems to me like a small change because there is no backward compat considerations, do you know what decided people to delay it? or maybe roughly the ACD where it was decided?)",
        "created_at": "2023-11-23T12:31:51.741000+00:00",
        "attachments": null
    },
    {
        "author": "bridge-bot",
        "category": "general",
        "parent": "",
        "content": "\u003cCPerezz\u003e Onur is in PSE with me. So no issues (I assume) on helping with anything needed there. (re @asqyzeron: I asked that question during our team meeting today, and here is what came out of it:\n\n- these BLS precompiles are outdated, but upgrading them should not be a problem\n- if kilic can still be used, then we have done a lot of fuzzing and we are quite confident that this could be part of a small fork\n- we need to have a backup library, because none of us are crypto experts and if something goes wrong, we must be able to have a fallback. This is what we do with the kzg library.\n- we didn't proceed with these BLS precompiles because EVMMAX was making progress with great strides back then, and that is still our favorite option.\n- the risk with adding these precompiles in a smaller fork is that there is no such thing as a small fork and it's a slippery slope\n\nTLDR the feedback is that the BLS precompiles shouldn't be too much work for us after all, but great care has to be taken that this doesn't turn into a major fork.)",
        "created_at": "2023-11-23T12:45:05.240000+00:00",
        "attachments": null
    },
    {
        "author": "bridge-bot",
        "category": "general",
        "parent": "",
        "content": "\u003cmratsim\u003e \u003e - we need to have a backup library, because none of us are crypto experts and if something goes wrong, we must be able to have a fallback. This is what we do with the kzg library.\n\nThe same concern was on the Consensus side, and if BLST / BLS12-381, consensus clients are also SOL.\n\nThat said:\n\n- Milagro-crypto / Miracl, the OG backend is still usable for precompiles, way to slow for consensus with 900k validators but for pairings here and there for rollups, it's possible. The Rust version is maintained by Sigma Prime and the Nim/C version is tested in CI by Nimbus.\n- MCL has been audited in 2020 and has dedicated Go API and I still see people using it. The main audit issue, doubt on JIT compiler, has been addressed by ASM generated statically through LLVM IR. Furthermore, the JIT backend (xbyak) has been in production for 6+ years at Intel for their large scale machine learning project oneDNN (https://github.com/oneapi-src/oneDNN/tree/master/src/cpu/x64/xbyak). Also MCL has been used extensibly in libff and libsnark, the original SNARK library. MCL has also been fuzzed by cryptofuzz.\nIt was the backend of Prysm for a while iirc.\n- BLST has been used in production by Ethereum Consensus, Filecoin (original sponsors), Algorand, Chia, Dfinity, Tezos, ...\n  It has been formally transcribed and tested by Galois, fuzzed extensively through cryptofuzz\n- Constantine (my own impl) has been fuzzed extensively through cryptofuzz and integrated in Google 24/7 OSS-fuzz, with @justindrake , there was talk in 2021 to go through Galois for formal verification as well.\n- Gnark-crypto has been fuzzed extensively for EIP4844 / KZG and has been audited by Kudelski for use in Algorand, iirc either coinbase or binance were also looking for a go library. Iirc, the only issue is that their map_to_g1 / map_to_g2 is using the generic method instead of the optimized one (svdw instead of swu), that gives different results.\n\nS \u003cclipped message\u003e",
        "created_at": "2023-11-23T13:11:21.842000+00:00",
        "attachments": null
    },
    {
        "author": "bridge-bot",
        "category": "general",
        "parent": "",
        "content": "\u003cadietrichs\u003e I'm not super close to the Verkle effort, so just a meta comment: Clearly L2s and L1 have somewhat different requirements. (e.g. stateless execution might not matter / matter differently for L2, total state size in L2 might be much larger, zk, bridge proofs, etc.). I think in case most L2s want to end up adopting Verkle, we should very much avoid this being yet another feature optimized for L1 and only \"good enough\" for L2s. If anything, it should be the other way around. I think the window before L1 commits to a specific path on this is ~3 months, so if there are any changes that would make Verkle more L2 optimized, that would be super high value to figure out asap.",
        "created_at": "2023-11-23T13:24:00.082000+00:00",
        "attachments": null
    }
]