[
    {
        "author": "bridge-bot",
        "category": "general",
        "parent": "",
        "content": "\u003cdcposch\u003e I'm experimenting with bundle compression. Avoids the \"rollups can't easily offer a discount for compressible calldata\" issue. The goal is cheaper 4337 on L2.\n\nTLDR; instead of calling EntryPoint directly, bundler calls via a proxy which inflates a compressed bundle.\n\nWrote a POC last night: https://github.com/daimo-eth/bulk\n\n(In this draftâ€”early, not yet deployed even on testnet-â€”apps can register their own inflator functions.)\n\nJust templating gets us from ~1600 bytes to ~400 bytes calldata for our common case = a singleton bundle containing a stablecoin transfer. I think we could go further. (re @vb271828: My understanding as to why is twofold:\n\n1. There are technical challenges with doing stateful compression, namely that it would require nodes to have a larger internal state, and there's a lot of work in doing this well\n2. Stateless compression is totally possible, but we haven't figured out a good way to *incentivize* compression at the app level. And so even though in reality that infamous \"1400 byte ERC4337 op\" is actually much much smaller on-chain, the sender doesn't benefit from the compression, because they still get charged for the full 1400 bytes. And the fact that you can't save gas in your dapp by compressing means that no one bothers to compress.)",
        "created_at": "2023-12-04T01:50:18.773000+00:00",
        "attachments": []
    },
    {
        "author": "bridge-bot",
        "category": "general",
        "parent": "",
        "content": "\u003cdcposch\u003e Curious if we're on the right track.",
        "created_at": "2023-12-04T01:51:38.767000+00:00",
        "attachments": []
    },
    {
        "author": "bridge-bot",
        "category": "general",
        "parent": "",
        "content": "\u003cjessepollak\u003e This seems like a very smart approach - I like how it composes with the 4337 standard. Good example of how us having standardization in the stack enables us to layer on additional functionality. Curious for others takes. (re @dcposch: Curious if we're on the right track.)",
        "created_at": "2023-12-04T02:23:01.141000+00:00",
        "attachments": []
    },
    {
        "author": "bridge-bot",
        "category": "general",
        "parent": "",
        "content": "\u003cthegaram33\u003e Scroll is also experimenting with general-purpose compression (implementing decompression in the circuits), combined with some common stateful compression approaches (re @EdFelten: Our experience with Arbitrum has favored batching transactions, followed by a good general-purpose compression algorithm like brotli.  This gives you most of the benefit of fully stateless compression, without requiring any compression state in the chain's state tree.)",
        "created_at": "2023-12-04T08:28:13.794000+00:00",
        "attachments": []
    },
    {
        "author": "bridge-bot",
        "category": "general",
        "parent": "",
        "content": "\u003cthegaram33\u003e in zkEVMs, assuming sequencers and provers are (will be) different entities, this batch ECDSA would need to be computed by the sequencer, since the provers are not guaranteed to have access to the original signatures. (re @rbayardo: .... even without aggregatable signatures we could drop the signatures from the batch with a zk-proof of ECDSA signature verification (e.g. https://0xparc.org/blog/batch-ecdsa) if it weren't for the txhash concern.)",
        "created_at": "2023-12-04T08:30:59.721000+00:00",
        "attachments": []
    },
    {
        "author": "bridge-bot",
        "category": "general",
        "parent": "",
        "content": "\u003cvb271828\u003e Here's some quick theorycrafting from me:",
        "created_at": "2023-12-04T08:42:49.609000+00:00",
        "attachments": []
    },
    {
        "author": "bridge-bot",
        "category": "general",
        "parent": "",
        "content": "\u003cvb271828\u003e https://hackmd.io/@vbuterin/eip4844_compression_theorycrafting",
        "created_at": "2023-12-04T08:42:50.149000+00:00",
        "attachments": []
    },
    {
        "author": "bridge-bot",
        "category": "general",
        "parent": "",
        "content": "\u003cvb271828\u003e I would look but github is not opening for me right at this moment, will check later (re @dcposch: I'm experimenting with bundle compression. Avoids the \"rollups can't easily offer a discount for compressible calldata\" issue. The goal is cheaper 4337 on L2.\n\nTLDR; instead of calling EntryPoint directly, bundler calls via a proxy which inflates a compressed bundle.\n\nWrote a POC last night: https://github.com/daimo-eth/bulk\n\n(In this draftâ€”early, not yet deployed even on testnet-â€”apps can register their own inflator functions.)\n\nJust templating gets us from ~1600 bytes to ~400 bytes calldata for our common case = a singleton bundle containing a stablecoin transfer. I think we could go further.)",
        "created_at": "2023-12-04T08:43:09.198000+00:00",
        "attachments": []
    },
    {
        "author": "bridge-bot",
        "category": "general",
        "parent": "",
        "content": "\u003cvmihov\u003e this looks very interesting. do you include the storage of the SMTs in the data compression calcs? I suppose these 2 trees are provided with each batch, right? (re @krlosMata: sure !\nhere are the slides links:\n- ethCC â€”\u003e https://docs.google.com/presentation/d/1pZIhlN8rCKYvto6E1HgDWXtd71D0k4uUtlT2MI5nQc0/edit#slide=id.g255e5cb8e5e_0_7\n- evm summit â€”\u003e https://docs.google.com/presentation/d/1OeB0iV6qEobF6PxzH8vBiH4YdYN3keWEscFMZ_EDtYQ/edit#slide=id.g29a024febfd_0_61)",
        "created_at": "2023-12-04T08:51:39.391000+00:00",
        "attachments": []
    },
    {
        "author": "bridge-bot",
        "category": "general",
        "parent": "",
        "content": "\u003cdrortirosh\u003e We experimented with compressors.\n\nThe idea is that apps/users only deal with normal, uncompressed data.\nThe bundler creates a bundle, passes the encoded \"handleOps\" calldata into the off-chain compressor , and then call EPDecompressor(compressedData), which decompresses it on-chain and calls the entryPoint.\nIt requires no integration point with apps or even other bundlers.\nThe only downsize with current erc-4337, is that the eth_getUserOperation RPC call becomes more complex, as it has to decompress the data, instead of parse the transaction. e.g. it requires the above EPDecompressor contract to have a standardized view call to decompress a single UserOp for a bundle.\n\nAbout compression types:\nStateless compression works on a bundle level. It is only effective if bundle is large (no real redundant data within a UserOp, except maybe zeroes). This part is heuristic, and can't be easily shared with users (the bundler decides which ops to include, and ultimately, what can be compressed, or not)\n\nL2 compression (e.g Arbitrum's brotli) achieves just that.\n\nWe do have an experimental stateful compression, which compresses addresses down to 4-5 bytes. It is \"un-opinionated\", and thus doesn't try to have better compression for \"privileged\" addresses (it is not even 4337-related, but compresses any sequence of 20 bytes using the on-chain dictionary)\n\nThis compression is deterministic for each userop, and thus a bundler can report back to the app (and enforce) lower gas cost. The bundler is not incentivized directly to refund the users, but in a competitive market, the ones who do will attract more users.\n\nAs for numeric values, we could suggest apps to use that gas limits and prices with 8-bit worth of data. that adds 0.5% \"slack\", but reduce the nonzero footprint of those numbers to 1-2 bytes, instead of ~6-8 (assuming RLZ compresses all surrounding zeros) (re @vb271828: My understanding as to why is twofol \u003cclipped message\u003e",
        "created_at": "2023-12-04T09:00:18.133000+00:00",
        "attachments": []
    },
    {
        "author": "bridge-bot",
        "category": "general",
        "parent": "",
        "content": "\u003cvb271828\u003e I think the lowest-overhead way of doing this is to define a \"canonical dictionary\" for each field, and have a bitfield that specifies for each field whether you're using the \"full encoding\" (4-32 bytes) or the \"short encoding\" (1 byte). The short encoding would just be an enumeration of the 256 most commonly used values in that field",
        "created_at": "2023-12-04T09:19:01.031000+00:00",
        "attachments": []
    },
    {
        "author": "bridge-bot",
        "category": "general",
        "parent": "",
        "content": "\u003cvb271828\u003e this would generically cover transaction values, gas prices, token addresses, and lots of other stuff",
        "created_at": "2023-12-04T09:19:26.073000+00:00",
        "attachments": []
    },
    {
        "author": "bridge-bot",
        "category": "general",
        "parent": "",
        "content": "\u003cvb271828\u003e and of course you don't use RLP for the compressed form, because RLP is not byte-efficient",
        "created_at": "2023-12-04T09:19:42.136000+00:00",
        "attachments": []
    },
    {
        "author": "bridge-bot",
        "category": "general",
        "parent": "",
        "content": "\u003cvb271828\u003e if someone can give me a dump of all or a very huge number of 4337 ops that have been used on-chain, I can try to generate this automatically and see what the compression gains are",
        "created_at": "2023-12-04T09:22:44.148000+00:00",
        "attachments": []
    },
    {
        "author": "bridge-bot",
        "category": "general",
        "parent": "",
        "content": "\u003ckrlosMata\u003e The `addressTree` and the `dataTree` are known for each batch (set of txs) since they can be completely build from data availability (function `uncompressed address` \u0026 `uncompressed 32 bytes` to add leafs on the trees).\n\nStorage [`address \u003c\u003e index` or `32bytes \u003c\u003e index`] on those SMT will be done just only once. Then you can refer `address` or `32 bytes` to that `index`from now on. Therefore, the cost of adding is mitigated along the time for all txs referencing that `index` (re @vmihov: this looks very interesting. do you include the storage of the SMTs in the data compression calcs? I suppose these 2 trees are provided with each batch, right?)",
        "created_at": "2023-12-04T09:26:38.348000+00:00",
        "attachments": []
    },
    {
        "author": "bridge-bot",
        "category": "general",
        "parent": "",
        "content": "\u003cvb271828\u003e I do think that going from stateless -\u003e stateful compression should be a second stage",
        "created_at": "2023-12-04T09:27:18.401000+00:00",
        "attachments": []
    },
    {
        "author": "bridge-bot",
        "category": "general",
        "parent": "",
        "content": "\u003cvb271828\u003e As there's huge gains from stateless compression that are not yet captured",
        "created_at": "2023-12-04T09:27:26.308000+00:00",
        "attachments": []
    },
    {
        "author": "bridge-bot",
        "category": "general",
        "parent": "",
        "content": "\u003cvb271828\u003e Like that infamous 1600 byte ERC4337 op",
        "created_at": "2023-12-04T09:27:31.938000+00:00",
        "attachments": []
    },
    {
        "author": "bridge-bot",
        "category": "general",
        "parent": "",
        "content": "\u003cvb271828\u003e like, even statelessly you can compress that down to \u003c150 bytes",
        "created_at": "2023-12-04T09:27:39.889000+00:00",
        "attachments": []
    },
    {
        "author": "bridge-bot",
        "category": "general",
        "parent": "",
        "content": "\u003cdcposch\u003e 1600 bytes was about half the 4337 bundle transaction, half the single op inside\n\nGot it down to 353 bytes here. Could def go further. (this is the raw tx size on L2 \u003e L1 data after rollup compression should be smaller)\n\nhttps://docs.google.com/spreadsheets/d/1rf3AJMmm9BCkBsmQiRq4yP3Zhne9vIW-ib0Dp4QD2Tw/edit",
        "created_at": "2023-12-04T09:53:05.613000+00:00",
        "attachments": []
    },
    {
        "author": "bridge-bot",
        "category": "general",
        "parent": "",
        "content": "\u003cdcposch\u003e thanks @adietrichs for the original analysis",
        "created_at": "2023-12-04T09:55:55.362000+00:00",
        "attachments": []
    },
    {
        "author": "bridge-bot",
        "category": "general",
        "parent": "",
        "content": "\u003cvb271828\u003e 7b2274797065223a22776562617574686e2e676574222c226368616c6c656e6765223a22415141415a5650485830567a705463726d35665a6846505f566369545433584d57484832624e7a6a6435346531774e354d32696f222c226f726967696e223a226461696d6f2e636f6d227d sig.clientDataJSON  111 1776",
        "created_at": "2023-12-04T10:02:12.786000+00:00",
        "attachments": []
    },
    {
        "author": "bridge-bot",
        "category": "general",
        "parent": "",
        "content": "\u003cvb271828\u003e ok wtf is this",
        "created_at": "2023-12-04T10:02:15.639000+00:00",
        "attachments": []
    },
    {
        "author": "bridge-bot",
        "category": "general",
        "parent": "",
        "content": "\u003ckristofgazso\u003e i think thatâ€™s part of the passkey data",
        "created_at": "2023-12-04T10:03:07.468000+00:00",
        "attachments": []
    },
    {
        "author": "bridge-bot",
        "category": "general",
        "parent": "",
        "content": "\u003cvb271828\u003e ```\n\u003e\u003e\u003e bytes.fromhex('7b2274797065223a22776562617574686e2e676574222c226368616c6c656e6765223a22415141415a5650485830567a705463726d35665a6846505f566369545433584d57484832624e7a6a6435346531774e354d32696f222c226f726967696e223a226461696d6f2e636f6d227d')\nb'{\"type\":\"webauthn.get\",\"challenge\":\"AQAAZVPHX0VzpTcrm5fZhFP_VciTT3XMWHH2bNzjd54e1wN5M2io\",\"origin\":\"daimo.com\"}'```",
        "created_at": "2023-12-04T10:03:19.681000+00:00",
        "attachments": []
    },
    {
        "author": "bridge-bot",
        "category": "general",
        "parent": "",
        "content": "\u003cvb271828\u003e that is definitely an inefficient encoding...",
        "created_at": "2023-12-04T10:03:27.266000+00:00",
        "attachments": []
    },
    {
        "author": "bridge-bot",
        "category": "general",
        "parent": "",
        "content": "\u003cvb271828\u003e ok so that's 353 bytes including the 4337 wrapper tx?",
        "created_at": "2023-12-04T10:04:22.200000+00:00",
        "attachments": []
    },
    {
        "author": "bridge-bot",
        "category": "general",
        "parent": "",
        "content": "\u003cvb271828\u003e I think it's fair to not include the wrapper tx, because that's a fixed cost",
        "created_at": "2023-12-04T10:04:32.689000+00:00",
        "attachments": []
    },
    {
        "author": "bridge-bot",
        "category": "general",
        "parent": "",
        "content": "\u003cdrortirosh\u003e - defining fields means we compress only the header, not the content.\n- \"most commonly used\" values is biased. e.g. what paymaster values would you select? I believe the most useful one will be introduced a year from now, while all slots are already filled. making them editable requires some centralized authority on the list. (re @vb271828: I think the lowest-overhead way of doing this is to define a \"canonical dictionary\" for each field, and have a bitfield that specifies for each field whether you're using the \"full encoding\" (4-32 bytes) or the \"short encoding\" (1 byte). The short encoding would just be an enumeration of the 256 most commonly used values in that field)",
        "created_at": "2023-12-04T10:06:55.362000+00:00",
        "attachments": []
    },
    {
        "author": "bridge-bot",
        "category": "general",
        "parent": "",
        "content": "\u003cvb271828\u003e one way to do it is to just make a dynamic counter",
        "created_at": "2023-12-04T10:07:46.008000+00:00",
        "attachments": []
    },
    {
        "author": "bridge-bot",
        "category": "general",
        "parent": "",
        "content": "\u003cvb271828\u003e Another is an on-chain auction ðŸ˜‚",
        "created_at": "2023-12-04T10:08:01.331000+00:00",
        "attachments": []
    },
    {
        "author": "bridge-bot",
        "category": "general",
        "parent": "",
        "content": "\u003cvb271828\u003e But honestly I think in this case there is a simple credibly-neutral way to do it: *for now* just set it to be the most commonly used paymasters based on a fair count of whihc paymasters have been used on-chain so far",
        "created_at": "2023-12-04T10:08:33.766000+00:00",
        "attachments": []
    },
    {
        "author": "bridge-bot",
        "category": "general",
        "parent": "",
        "content": "\u003cvb271828\u003e And update it with something else later",
        "created_at": "2023-12-04T10:08:39.263000+00:00",
        "attachments": []
    },
    {
        "author": "bridge-bot",
        "category": "general",
        "parent": "",
        "content": "\u003ckristofgazso\u003e for this proxy contract, i was thinking of a completely unopinionated and extensible templating / expansion system\n\nthe proxy contract could just have 2 functions:\n\nhandleCompressedOps(template: address, compressedOps, bytes[])\nexpandCompressedOp(template: address, compressedOp: bytes)\n\nas part of the call, a remote contract would be responsible for expanding the data for the op\n\nthe bundler would individually choose which templates to trust and whitelist them\n\na new rpc method, eth_sendCompressedUserOperation would be added to the bundlers",
        "created_at": "2023-12-04T10:15:48.790000+00:00",
        "attachments": []
    },
    {
        "author": "bridge-bot",
        "category": "general",
        "parent": "",
        "content": "\u003cvb271828\u003e the problem is that the gas pricing needs to be opinionated",
        "created_at": "2023-12-04T10:16:37.951000+00:00",
        "attachments": []
    },
    {
        "author": "bridge-bot",
        "category": "general",
        "parent": "",
        "content": "\u003cvb271828\u003e when a user sends a tx, it should not be possible to charge them 6x more by pushing them through a different decompressor that's less efficient",
        "created_at": "2023-12-04T10:17:23.209000+00:00",
        "attachments": []
    },
    {
        "author": "bridge-bot",
        "category": "general",
        "parent": "",
        "content": "\u003ckristofgazso\u003e well the user specifies the preVerificationGas they're going to spend, so if the bundler chooses a super inefficient decompressor then the bundler is the one who suffers",
        "created_at": "2023-12-04T10:18:43.442000+00:00",
        "attachments": []
    },
    {
        "author": "bridge-bot",
        "category": "general",
        "parent": "",
        "content": "\u003cvb271828\u003e right but I mean the total data gas that gets charged for them",
        "created_at": "2023-12-04T10:19:03.777000+00:00",
        "attachments": []
    },
    {
        "author": "bridge-bot",
        "category": "general",
        "parent": "",
        "content": "\u003cvb271828\u003e unless the goal is that the user just provides the max data gas they're willing to pay as a number",
        "created_at": "2023-12-04T10:19:24.870000+00:00",
        "attachments": []
    },
    {
        "author": "bridge-bot",
        "category": "general",
        "parent": "",
        "content": "\u003cvb271828\u003e ?",
        "created_at": "2023-12-04T10:19:26.168000+00:00",
        "attachments": []
    },
    {
        "author": "bridge-bot",
        "category": "general",
        "parent": "",
        "content": "\u003cvb271828\u003e so if a decompressor exists that can compress the user's op down to that number, the bundler goes through them, otherwise the bundler has no choice but to ignore the op (or lose money)",
        "created_at": "2023-12-04T10:20:06.894000+00:00",
        "attachments": []
    },
    {
        "author": "bridge-bot",
        "category": "general",
        "parent": "",
        "content": "\u003ckristofgazso\u003e well i was imagining the user actually specifies the decompressor as part of the eth_sendCompressedUserOperation rpc call, so the bundler isn't responsible for picking it (re @vb271828: so if a decompressor exists that can compress the user's op down to that number, the bundler goes through them, otherwise the bundler has no choice but to ignore the op (or lose money))",
        "created_at": "2023-12-04T10:21:05.866000+00:00",
        "attachments": []
    },
    {
        "author": "bridge-bot",
        "category": "general",
        "parent": "",
        "content": "\u003ckristofgazso\u003e the bundler just checks if the decompressor is whitelisted for them, does some super basic validation and that's it",
        "created_at": "2023-12-04T10:21:57.916000+00:00",
        "attachments": []
    },
    {
        "author": "bridge-bot",
        "category": "general",
        "parent": "",
        "content": "\u003cvb271828\u003e right but I mean how the malicious case gets handled",
        "created_at": "2023-12-04T10:22:24.253000+00:00",
        "attachments": []
    },
    {
        "author": "bridge-bot",
        "category": "general",
        "parent": "",
        "content": "\u003cvb271828\u003e I think we'd need to add a `max_blob_gas` param alongside `max_fee_per_blob_gas`",
        "created_at": "2023-12-04T10:22:47.071000+00:00",
        "attachments": []
    },
    {
        "author": "bridge-bot",
        "category": "general",
        "parent": "",
        "content": "\u003ckristofgazso\u003e sorry what malicious case do you mean?\n\nas a bundler i'd personally audit the decompressor contract to make sure i can't be bamboozled (re @vb271828: right but I mean how the malicious case gets handled)",
        "created_at": "2023-12-04T10:23:56.351000+00:00",
        "attachments": []
    },
    {
        "author": "bridge-bot",
        "category": "general",
        "parent": "",
        "content": "\u003cdrortirosh\u003e It that \"1600 byte erc4337\":\n- RLZ compressed it down to half the gas.\n- Another 110 bytes are not \"outer 4337 tx\" but outer TRANSACTION, unrelated to 4337 \n- The protocol itself is quite heavy, as it carries a JSON inside.\nI don't think this TX is a good for any comparison, since it is based on protocol that is 4337-only. A better comparison would be for protocol that is used both with and without AA. (re @vb271828: Like that infamous 1600 byte ERC4337 op)",
        "created_at": "2023-12-04T10:25:31.442000+00:00",
        "attachments": []
    },
    {
        "author": "bridge-bot",
        "category": "general",
        "parent": "",
        "content": "\u003cvb271828\u003e the bundler puts the user's tx through a much worse decompressor than the decompressor that the user intended, and uses that to charge the user more gas (re @kristofgazso: sorry what malicious case do you mean?\n\nas a bundler i'd personally audit the decompressor contract to make sure i can't be bamboozled)",
        "created_at": "2023-12-04T10:28:19.033000+00:00",
        "attachments": []
    },
    {
        "author": "bridge-bot",
        "category": "general",
        "parent": "",
        "content": "\u003cdrortirosh\u003e The bundler accepts a UserOp based on the gas written in it.\nBundlers might refuse nonprofitable userops. but if the bundler knows the actual cost for itself (by compression), and the user knows this bundler is cheaper, then the user will switch to this bunder's RPC.\nI try not to involve the user with the compression: the interface is RPC: estimateUserOp to get the needed gas, and sendUserOp to send. the bundler performs all compression.",
        "created_at": "2023-12-04T10:30:43.094000+00:00",
        "attachments": []
    },
    {
        "author": "bridge-bot",
        "category": "general",
        "parent": "",
        "content": "\u003ckristofgazso\u003e hmm yeah i think we're thinking about two different things\n\ni was thinking of a system where the user itself specifies the decompressor that should be used and the bundler is super unlikely to which (because in all likelyhood the user is already picking the most efficient decompressor for their usecase). the bundler simply uses a proxy contract that the bundler makes the call to the entrypoint through that actually does the decompression, not modifying the current entrypoint at all\n\nso because of that, the decompressed useroperation struct that eventually gets submitted to the entrypoint is the same as it is right now. this means the gas the user would pay for the calldata cost, i.e. the preVerificationGas, is already predefined by the user from the get-go and there is nothing the bundler can do to increase or decrease the amount the user will pay for it\n\ni think what you guys are thinking of is a system where the interfaces for the user don't change and its the bundler's job to figure out how which contract they're going to use to be able to compress it as much as possible.\n\nam i understanding it correctly?",
        "created_at": "2023-12-04T10:34:23.210000+00:00",
        "attachments": []
    },
    {
        "author": "bridge-bot",
        "category": "general",
        "parent": "",
        "content": "\u003cvb271828\u003e Right now a user has a \"max fee per gas\" but it doesn't have a \"max bytes\" parameter",
        "created_at": "2023-12-04T10:35:04.520000+00:00",
        "attachments": []
    },
    {
        "author": "bridge-bot",
        "category": "general",
        "parent": "",
        "content": "\u003cvb271828\u003e What we want is, for a user to have to pay data gas based on the *compressed* UserOp size, and not the uncompressed size",
        "created_at": "2023-12-04T10:35:46.984000+00:00",
        "attachments": []
    },
    {
        "author": "bridge-bot",
        "category": "general",
        "parent": "",
        "content": "\u003cvb271828\u003e The challenge is: suppose my UserOp is 352 bytes uncompressed, 39 bytes compressed. I send it to a bundler expecting to pay `39 * data_gasprice` data gas. But the bundler instead sends it through a worse decompressor that just implements the identity function. And so I end up paying `352 * data_gasprice` data gas.",
        "created_at": "2023-12-04T10:36:46.618000+00:00",
        "attachments": []
    },
    {
        "author": "bridge-bot",
        "category": "general",
        "parent": "",
        "content": "\u003cvb271828\u003e So the user needs to either (i) specify the decompressor in the op, or (ii) specify the number 39 in the op",
        "created_at": "2023-12-04T10:37:09.860000+00:00",
        "attachments": []
    },
    {
        "author": "bridge-bot",
        "category": "general",
        "parent": "",
        "content": "\u003cvb271828\u003e Or of course (iii) we have one canonical decompressor across the ecosystem, but that seems more politically contentious and worse, I suppose",
        "created_at": "2023-12-04T10:37:36.972000+00:00",
        "attachments": []
    },
    {
        "author": "bridge-bot",
        "category": "general",
        "parent": "",
        "content": "\u003ckristofgazso\u003e sorry i still must be missing something â€”Â could you point out where my logic is going wrong?\n\nthe end user doesn't directly pay the cost for the data gas, the bundler does. the user only pays for the preVerificationGas * effective userop gas price, where the preVerificationGas is specified in advance.\n\ntherefore if for any reason the bundler uses an identity function to include it which baloons the call data cost then the only one they're hurting is themselves, it's the bundler who suffers, since the amount i pay is totally fixed in place by the preVerificationGas and can't vary at all",
        "created_at": "2023-12-04T10:45:35.621000+00:00",
        "attachments": []
    },
    {
        "author": "bridge-bot",
        "category": "general",
        "parent": "",
        "content": "\u003cdrortirosh\u003e You pay based on what you wrote in the userop itself.\nby accepting your userop, the bundler agrees to receive that amount, regardless if the bundler itself actually performs the compression (but he probably will, to be cash-positive)\nYou use a bundler service to estimate the gas (`eth_estimateUserOperation`). \nIf there is such a market (different bundlers with different compressions), then users will \"shop around\" for a bundler service with best gas (cost) estimations, and continue to use that. (re @vb271828: The challenge is: suppose my UserOp is 352 bytes uncompressed, 39 bytes compressed. I send it to a bundler expecting to pay 39 * data_gasprice data gas. But the bundler instead sends it through a worse decompressor that just implements the identity function. And so I end up paying 352 * data_gasprice data gas.)",
        "created_at": "2023-12-04T10:53:07.617000+00:00",
        "attachments": []
    },
    {
        "author": "bridge-bot",
        "category": "general",
        "parent": "",
        "content": "\u003cvb271828\u003e right but where do you write in the userop today how much you pay? (re @drortirosh: You pay based on what you wrote in the userop itself.\nby accepting your userop, the bundler agrees to receive that amount, regardless if the bundler itself actually performs the compression (but he probably will, to be cash-positive)\nYou use a bundler service to estimate the gas (eth_estimateUserOperation). \nIf there is such a market (different bundlers with different compressions), then users will \"shop around\" for a bundler service with best gas (cost) estimations, and continue to use that.)",
        "created_at": "2023-12-04T10:55:00.331000+00:00",
        "attachments": []
    },
    {
        "author": "bridge-bot",
        "category": "general",
        "parent": "",
        "content": "\u003cvb271828\u003e I only see per-gas price fields",
        "created_at": "2023-12-04T10:55:13.509000+00:00",
        "attachments": []
    },
    {
        "author": "bridge-bot",
        "category": "general",
        "parent": "",
        "content": "\u003ckristofgazso\u003e in the preVerificationGas (re @vb271828: right but where do you write in the userop today how much you pay?)",
        "created_at": "2023-12-04T10:55:13.612000+00:00",
        "attachments": []
    },
    {
        "author": "bridge-bot",
        "category": "general",
        "parent": "",
        "content": "\u003cdrortirosh\u003e Custom per-app compresions is possible, but:\n1. overhead on each on-chain userop with the compressor (unless the same compressor can be used for many ops in this bundle, e.g. \"compressor aggregation\"...\n2. integration with compression sdk for each app. while it is doable, I think it should be optional. (re @kristofgazso: hmm yeah i think we're thinking about two different things\n\ni was thinking of a system where the user itself specifies the decompressor that should be used and the bundler is super unlikely to which (because in all likelyhood the user is already picking the most efficient decompressor for their usecase). the bundler simply uses a proxy contract that the bundler makes the call to the entrypoint through that actually does the decompression, not modifying the current entrypoint at all\n\nso because of that, the decompressed useroperation struct that eventually gets submitted to the entrypoint is the same as it is right now. this means the gas the user would pay for the calldata cost, i.e. the preVerificationGas, is already predefined by the user from the get-go and there is nothing the bundler can do to increase or decrease the amount the user will pay for it\n\ni think what you guys are thinking of is a system where the interfaces for the user don't change and its the bundler's job to figure out how which contract they're going to use to be able to compress it as much as possible.\n\nam i understanding it correctly?)",
        "created_at": "2023-12-04T10:55:21.678000+00:00",
        "attachments": []
    },
    {
        "author": "bridge-bot",
        "category": "general",
        "parent": "",
        "content": "\u003cvb271828\u003e aaah so preVerificationGas is basically a synonym for data gas? (re @kristofgazso: in the preVerificationGas)",
        "created_at": "2023-12-04T10:55:51.210000+00:00",
        "attachments": []
    },
    {
        "author": "bridge-bot",
        "category": "general",
        "parent": "",
        "content": "\u003cvb271828\u003e (sorry I forget what that field was for suddenly)",
        "created_at": "2023-12-04T10:56:07.955000+00:00",
        "attachments": []
    },
    {
        "author": "bridge-bot",
        "category": "general",
        "parent": "",
        "content": "\u003ckristofgazso\u003e basically yeah :) (re @vb271828: aaah so preVerificationGas is basically a synonym for data gas?)",
        "created_at": "2023-12-04T10:56:08.110000+00:00",
        "attachments": []
    },
    {
        "author": "bridge-bot",
        "category": "general",
        "parent": "",
        "content": "\u003cvb271828\u003e aha",
        "created_at": "2023-12-04T10:56:14.799000+00:00",
        "attachments": []
    },
    {
        "author": "bridge-bot",
        "category": "general",
        "parent": "",
        "content": "\u003cdrortirosh\u003e yes. perVerificationGas is a fixed cost for anything you don't pay on-chain - e.g. calldata cost.\n(currently, it also doubles to pay for L2 costs, but it is bad at this, since L1-L2 costs vary over time, and thus you end up overpaying, just like with gasPrice pre-1559) (re @vb271828: aaah so preVerificationGas is basically a synonym for data gas?)",
        "created_at": "2023-12-04T10:57:00.837000+00:00",
        "attachments": []
    },
    {
        "author": "bridge-bot",
        "category": "general",
        "parent": "",
        "content": "\u003ckristofgazso\u003e yeah totally it should be optional, use should still be able to send uncompressed op structs\n\nyou could imagine making the proxy super flexible and allowing it to handle uncompressed ops too, so you would not need to segregate compressed and uncompressed ops during submission and could still bundle them together (re @drortirosh: Custom per-app compresions is possible, but:\n1. overhead on each on-chain userop with the compressor (unless the same compressor can be used for many ops in this bundle, e.g. \"compressor aggregation\"...\n2. integration with compression sdk for each app. while it is doable, I think it should be optional.)",
        "created_at": "2023-12-04T11:01:08.715000+00:00",
        "attachments": []
    },
    {
        "author": "bridge-bot",
        "category": "general",
        "parent": "",
        "content": "\u003cdrortirosh\u003e I think compression should not be part of the core EntryPoint, but a wrapper contract.\nas I said earlier, an EPDecompressor receives compressed data, and calls entryPoint.handleOps on-chain.\nThe decompressor is not a \"trusted entity\" by anyone: if it fails to decompress, the entryPoint would simply reject it on-chain.\nOriginally I was thinking about a generic decompressor, but a custom per-userop is also possible. \nThat is, a UserOp (uncompressed) is sent to the bundler, along with a \"hint\" on which compressor it prefers.\nIt means that the custom decompressor has to register with the above EPDecompressor. There is a question who does this registration - the bundler? the project? who defines which decompressors get \"privileged\" ids (1 byte) (re @kristofgazso: yeah totally it should be optional, use should still be able to send uncompressed op structs\n\nyou could imagine making the proxy super flexible and allowing it to handle uncompressed ops too, so you would not need to segregate compressed and uncompressed ops during submission and could still bundle them together)",
        "created_at": "2023-12-04T11:14:07.753000+00:00",
        "attachments": []
    },
    {
        "author": "bridge-bot",
        "category": "general",
        "parent": "",
        "content": "\u003ckristofgazso\u003e we're totally on the same page Dror\n\nthe one thing i think that could fix privilidge issue is making it so these privilidged ids are 4 bytes instead of 1 byte. 4,294,967,296 should be enough to allow people to register freely",
        "created_at": "2023-12-04T15:18:38.950000+00:00",
        "attachments": []
    },
    {
        "author": "bridge-bot",
        "category": "general",
        "parent": "",
        "content": "\u003cdrortirosh\u003e yes, using it with the same id as stateful address compression is great (though it reduces slightly the per-userop compression (re @kristofgazso: we're totally on the same page Dror\n\nthe one thing i think that could fix privilidge issue is making it so these privilidged ids are 4 bytes instead of 1 byte. 4,294,967,296 should be enough to allow people to register freely)",
        "created_at": "2023-12-04T15:36:17.700000+00:00",
        "attachments": []
    },
    {
        "author": "bridge-bot",
        "category": "general",
        "parent": "",
        "content": "\u003cdcposch\u003e Necessary for passkey support (websuthn). A big UX win, but unavoidably signs json.\n\nFortunately everything but the actual challenge is repeated and can be removed with (app-specific or stateful) compression.",
        "created_at": "2023-12-04T16:49:26.806000+00:00",
        "attachments": []
    },
    {
        "author": "bridge-bot",
        "category": "general",
        "parent": "",
        "content": "\u003cSamWilsn\u003e A (de)compression precompile might not be as contentious, especially if it can be updated to support new algorithms. (re @vb271828: Or of course (iii) we have one canonical decompressor across the ecosystem, but that seems more politically contentious and worse, I suppose)",
        "created_at": "2023-12-04T16:57:02.889000+00:00",
        "attachments": []
    },
    {
        "author": "bridge-bot",
        "category": "general",
        "parent": "",
        "content": "\u003cshemnon\u003e That kind of a precompile is a good candidate for progresive precompiles: https://ethereum-magicians.org/t/progressive-precompiles-via-create2-shadowing/14821/26 - That allows impls to optimize or not if an EVM form of the precompile logic already exists.",
        "created_at": "2023-12-04T17:07:34.824000+00:00",
        "attachments": []
    },
    {
        "author": "bridge-bot",
        "category": "general",
        "parent": "",
        "content": "\u003cshemnon\u003e Also allows for pre-deployment so it can be used prior to network upgrades, modulo gas.",
        "created_at": "2023-12-04T17:08:14.521000+00:00",
        "attachments": []
    },
    {
        "author": "bridge-bot",
        "category": "general",
        "parent": "",
        "content": "\u003cvb271828\u003e yeah this could work, though going up to 4 bytes has the downside that it would be a significant cost increase in the final compressed case (re @kristofgazso: we're totally on the same page Dror\n\nthe one thing i think that could fix privilidge issue is making it so these privilidged ids are 4 bytes instead of 1 byte. 4,294,967,296 should be enough to allow people to register freely)",
        "created_at": "2023-12-04T17:19:59.417000+00:00",
        "attachments": []
    },
    {
        "author": "bridge-bot",
        "category": "general",
        "parent": "",
        "content": "\u003cvb271828\u003e eg. take a uniswap trade, where you provide the uniswap address and the token address. With optimal compression, that could probably be reduced to ~30 bytes in almost all cases (as the uniswap address would be one of the 256 most popular, as would the token address almost all of the time). But if we do 4-byte compression, that would go up to 36 bytes",
        "created_at": "2023-12-04T17:21:30.429000+00:00",
        "attachments": []
    },
    {
        "author": "bridge-bot",
        "category": "general",
        "parent": "",
        "content": "\u003cvb271828\u003e there's a tradeoff between optimality and fairness",
        "created_at": "2023-12-04T17:21:39.458000+00:00",
        "attachments": []
    },
    {
        "author": "bridge-bot",
        "category": "general",
        "parent": "",
        "content": "\u003cvb271828\u003e though I think we can get credible neutrality by having an on-chain compressor that actually tracks how often a given contract is touched/used",
        "created_at": "2023-12-04T17:22:06.439000+00:00",
        "attachments": []
    },
    {
        "author": "bridge-bot",
        "category": "general",
        "parent": "",
        "content": "\u003cyoavw\u003e I wonder how much of the calldata is large round decimal numbers. Any user-provided value (gas fees, eth/token amounts, allowances...) tends to be a round decimal number shifted by at least 10**18. General purpose compression algorithms wouldn't compress it well, but a special-purpose compressor that replaces them with (base,exponent) before applying a general purpose compressor, might.",
        "created_at": "2023-12-04T17:52:35.670000+00:00",
        "attachments": []
    },
    {
        "author": "bridge-bot",
        "category": "general",
        "parent": "",
        "content": "\u003ckristofgazso\u003e instead of deciding globally how big to make these privilidged ids and all we could make it so there is just a standard interface for decompressors (a one function interface in all likelyhood) and they are deployed to different addresses. then its actually the bundler who maintains their own proxy contract that they send ops through, where the bundler themselves decides how to store the decompressor contracts in storage",
        "created_at": "2023-12-04T17:56:08.939000+00:00",
        "attachments": []
    }
]