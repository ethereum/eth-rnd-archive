[
    {
        "author": "axic3354",
        "category": "general",
        "parent": "",
        "content": "Wasn't there a \"binary tree\" channel under eth1x-research here?",
        "created_at": "2020-04-06T19:40:10.125000+00:00",
        "attachments": null
    },
    {
        "author": "Deleted User",
        "category": "general",
        "parent": "",
        "content": "we don't have a dedicated channel for that (yet). You can \"incubate\" it here to start with",
        "created_at": "2020-04-06T19:40:52.739000+00:00",
        "attachments": null
    },
    {
        "author": "axic3354",
        "category": "general",
        "parent": "",
        "content": "Ended up asking the question on the witnesses channel.",
        "created_at": "2020-04-06T19:45:11.555000+00:00",
        "attachments": null
    },
    {
        "author": "zkfloof",
        "category": "general",
        "parent": "",
        "content": "hey guys. Was wondering how hard it would be to modify geth or another client so that it can better take advantage of cloud pricing? For example since time to sync up a fresh node is constrained by IO, maybe some option for geth to do everything in RAM running on a high mem VM for a short time, and then switch over to a cheaper config once fully synced?",
        "created_at": "2020-04-06T20:29:54.902000+00:00",
        "attachments": null
    },
    {
        "author": "zkfloof",
        "category": "general",
        "parent": "",
        "content": "Another question: I would love to be able to run one instance of each popular ethereum client, like geth, open ethereum, besu, etc. However, as each client stores the state in its own different way, each one needs to have a seperate copy of the ethereum state. I guess there's no way to avoid this but wondering if once a chain is downloaded by one client if it can be transformed to the format expected by the other clients? And if that might be a project worth pursuing?",
        "created_at": "2020-04-06T20:37:54.209000+00:00",
        "attachments": null
    },
    {
        "author": "zkfloof",
        "category": "general",
        "parent": "",
        "content": "After we move to stateless none of these will matter ofc üòÑ",
        "created_at": "2020-04-06T20:44:56.385000+00:00",
        "attachments": null
    },
    {
        "author": "Deleted User",
        "category": "general",
        "parent": "",
        "content": "it will matter, of course",
        "created_at": "2020-04-06T20:45:11.341000+00:00",
        "attachments": null
    },
    {
        "author": "zkfloof",
        "category": "general",
        "parent": "",
        "content": "Archive nodes?",
        "created_at": "2020-04-06T20:45:54.144000+00:00",
        "attachments": null
    },
    {
        "author": "Deleted User",
        "category": "general",
        "parent": "",
        "content": "not only. In the Stateless Ethereum, there will still need to be nodes with the full state",
        "created_at": "2020-04-06T20:46:21.527000+00:00",
        "attachments": null
    },
    {
        "author": "Deleted User",
        "category": "general",
        "parent": "",
        "content": "but it will be possible to do validation and relay of blocks without having full state",
        "created_at": "2020-04-06T20:46:49.946000+00:00",
        "attachments": null
    },
    {
        "author": "Deleted User",
        "category": "general",
        "parent": "",
        "content": "to your question about taking advantage of cloud pricing - yes, it should be possible theoretically. You would need to know where the bottlenecks are exactly for your syncing configuration. is it read I/O, it is write I/O, or is it garbage collection, for example?",
        "created_at": "2020-04-06T20:48:41.450000+00:00",
        "attachments": null
    },
    {
        "author": "Deleted User",
        "category": "general",
        "parent": "",
        "content": "when experimenting with bottlenecks on turbo-geth, I noticed that if I sync it with history, bottleneck is usually in how fast I can write into the DB",
        "created_at": "2020-04-06T20:49:19.236000+00:00",
        "attachments": null
    },
    {
        "author": "Deleted User",
        "category": "general",
        "parent": "",
        "content": "but if I turn the history and most other things off, the bottleneck shifts and starts being spread between garbage collector and read I/O",
        "created_at": "2020-04-06T20:50:02.156000+00:00",
        "attachments": null
    },
    {
        "author": "afdudley",
        "category": "general",
        "parent": "",
        "content": "\u003e hey guys. Was wondering how hard it would be to modify geth or another client so that it can better take advantage of cloud pricing? For example since time to sync up a fresh node is constrained by IO, maybe some option for geth to do everything in RAM running on a high mem VM for a short time, and then switch over to a cheaper config once fully synced?\n\u003c@!387536747476549632\u003e The less efficient block witness system i'm working on will sort of have this property, it feels like it will be two months away at this point.",
        "created_at": "2020-04-06T20:50:52.698000+00:00",
        "attachments": null
    },
    {
        "author": "Deleted User",
        "category": "general",
        "parent": "",
        "content": "the project to transform DBs between clients - I do not see a lot of applications of that myself, but if you know it is useful for someone, why not",
        "created_at": "2020-04-06T20:51:18.607000+00:00",
        "attachments": null
    },
    {
        "author": "afdudley",
        "category": "general",
        "parent": "",
        "content": "\u003e Another question: I would love to be able to run one instance of each popular ethereum client, like geth, open ethereum, besu, etc. However, as each client stores the state in its own different way, each one needs to have a seperate copy of the ethereum state. I guess there's no way to avoid this but wondering if once a chain is downloaded by one client if it can be transformed to the format expected by the other clients? And if that might be a project worth pursuing?\n\u003c@!387536747476549632\u003e VulcanizeDB sort of does this now, it was part of the early vDB designs, but it's very low on the feature list at this point.",
        "created_at": "2020-04-06T20:52:18.694000+00:00",
        "attachments": null
    },
    {
        "author": "afdudley",
        "category": "general",
        "parent": "",
        "content": "this basically just happens during sync.",
        "created_at": "2020-04-06T20:53:47.726000+00:00",
        "attachments": null
    },
    {
        "author": "afdudley",
        "category": "general",
        "parent": "",
        "content": "in geth there is a db module that could be modified to support a more generic store, we looked into it, but it just never turned out to be useful. we will be using a collection of standard and custom nodes to inject state into our postgres-backed overlay network.",
        "created_at": "2020-04-06T20:54:43.420000+00:00",
        "attachments": null
    },
    {
        "author": "afdudley",
        "category": "general",
        "parent": "",
        "content": "sorry... that might be vague, when sync runs it transforms blockchain data from the wire format to whatever the database format is for that node. depending on your use-case you can modify the geth code as you see fit...",
        "created_at": "2020-04-06T20:56:44.754000+00:00",
        "attachments": null
    },
    {
        "author": "zkfloof",
        "category": "general",
        "parent": "",
        "content": "\u003e \u003c@!387536747476549632\u003e The less efficient block witness system i'm working on will sort of have this property, it feels like it will be two months away at this point.\n\u003c@!332923501079953409\u003e nice! üôÇ so it will utilize maximum available memory on the machine before going for the disk?",
        "created_at": "2020-04-06T21:01:57.644000+00:00",
        "attachments": null
    },
    {
        "author": "zkfloof",
        "category": "general",
        "parent": "",
        "content": "\u003e the project to transform DBs between clients - I do not see a lot of applications of that myself, but if you know it is useful for someone, why not\n\u003c@456226577798135808\u003e Sure. mainly just thinking in terms of reducing barrier to entry so as to encourage node count and node diversity..",
        "created_at": "2020-04-06T21:03:18.739000+00:00",
        "attachments": null
    },
    {
        "author": "Deleted User",
        "category": "general",
        "parent": "",
        "content": "one idea I had a long time ago (not implemented, but it might still be in the future) is to make the state trie representation in memory as close as possible (in terms of structure) to the database representation. Then, you put the database in a huge file (which is already the case for turbo-geth), do memory map on it, and voila üôÇ",
        "created_at": "2020-04-06T21:04:47.498000+00:00",
        "attachments": null
    },
    {
        "author": "Deleted User",
        "category": "general",
        "parent": "",
        "content": "operating system can figure out how to utilise the memory for you",
        "created_at": "2020-04-06T21:05:36.293000+00:00",
        "attachments": null
    },
    {
        "author": "zkfloof",
        "category": "general",
        "parent": "",
        "content": "\u003e in geth there is a db module that could be modified to support a more generic store, we looked into it, but it just never turned out to be useful. we will be using a collection of standard and custom nodes to inject state into our postgres-backed overlay network.\n\u003c@!332923501079953409\u003e yeah i was wondering that because as you say different clients need to do transformation over the wire, u could start with 1 synced client then have the second client sync from that one over a local network, and so on.. but that would not avoid hitting the SSD for the second, third, forth time..",
        "created_at": "2020-04-06T21:06:55.232000+00:00",
        "attachments": null
    },
    {
        "author": "zkfloof",
        "category": "general",
        "parent": "",
        "content": "google cloud has 3.75TB memory VM instances",
        "created_at": "2020-04-06T21:30:31.890000+00:00",
        "attachments": null
    },
    {
        "author": "afdudley",
        "category": "general",
        "parent": "",
        "content": "\u003e \u003c@!332923501079953409\u003e nice! üôÇ so it will utilize maximum available memory on the machine before going for the disk?\n\u003c@!387536747476549632\u003e I suppose you could do it that way, but we just won't have the IO bottleneck in the same way with vDB...  the RAM will effectively be a buffer... but you've asked for a fairly exotic set of features without defining a use-case so it's difficult to say much. üòÑ",
        "created_at": "2020-04-06T21:35:24.852000+00:00",
        "attachments": null
    },
    {
        "author": "afdudley",
        "category": "general",
        "parent": "",
        "content": "What do you think the benefits are of keeping the full state DB in RAM? when does the full state DB need to be accessed? syncing nodes this way doesn't really make  sense.",
        "created_at": "2020-04-06T21:36:26.362000+00:00",
        "attachments": null
    },
    {
        "author": "zkfloof",
        "category": "general",
        "parent": "",
        "content": "\u003e What do you think the benefits are of keeping the full state DB in RAM? when does the full state DB need to be accessed? syncing nodes this way doesn't really make  sense.\n\u003c@!332923501079953409\u003e use case is simply taking advantage of cloud services to sync in record time üòÑ",
        "created_at": "2020-04-06T21:38:58.804000+00:00",
        "attachments": null
    },
    {
        "author": "zkfloof",
        "category": "general",
        "parent": "",
        "content": "would be happy to pay $10/hour if it syncs in an hour or two",
        "created_at": "2020-04-06T21:39:17.541000+00:00",
        "attachments": null
    },
    {
        "author": "afdudley",
        "category": "general",
        "parent": "",
        "content": "that's just copying the disk image over from someone who already has it in your cloud infra.",
        "created_at": "2020-04-06T21:39:42.384000+00:00",
        "attachments": null
    },
    {
        "author": "afdudley",
        "category": "general",
        "parent": "",
        "content": "that doesn't really have anything to do with syncing to ram.",
        "created_at": "2020-04-06T21:39:50.631000+00:00",
        "attachments": null
    },
    {
        "author": "afdudley",
        "category": "general",
        "parent": "",
        "content": "we are just writing software that can serve arbitrary ranges of ethereum data... we get these sorts of features as a side effect, but they can't really be a design goal.",
        "created_at": "2020-04-06T21:41:02.735000+00:00",
        "attachments": null
    },
    {
        "author": "afdudley",
        "category": "general",
        "parent": "",
        "content": "it's pretty difficult to fully articulate why... because it's a bit tautological, but ultimately, if you want to write the data to disk, disk IO will be the bottleneck.",
        "created_at": "2020-04-06T21:41:35.453000+00:00",
        "attachments": null
    },
    {
        "author": "afdudley",
        "category": "general",
        "parent": "",
        "content": "if you want to snapshot _useful_ state quickly in cloud environments, vDB will help immensely with that.",
        "created_at": "2020-04-06T21:42:10+00:00",
        "attachments": null
    },
    {
        "author": "afdudley",
        "category": "general",
        "parent": "",
        "content": "the problem with archive nodes its 99.99% of the data it takes months to pull is junk for most applications, the archive node mode basically doesn't have a use-case. The use-case for it now is to use it as a basis to seed the network with nodes with more useful modes.",
        "created_at": "2020-04-06T21:42:52.943000+00:00",
        "attachments": null
    },
    {
        "author": "afdudley",
        "category": "general",
        "parent": "",
        "content": "It's junk or doesn't get properly verified by the end user.",
        "created_at": "2020-04-06T21:43:59.415000+00:00",
        "attachments": null
    },
    {
        "author": "afdudley",
        "category": "general",
        "parent": "",
        "content": "so the thing about geth today, is that it doesn't saturate disk throughput it saturates access attempts per second...",
        "created_at": "2020-04-06T21:46:17.670000+00:00",
        "attachments": null
    },
    {
        "author": "afdudley",
        "category": "general",
        "parent": "",
        "content": "the data you want needs to be serialized out the db which is the tricky part, but storing your local result from the query to ram doesn't solve that issue.",
        "created_at": "2020-04-06T21:46:59.603000+00:00",
        "attachments": null
    },
    {
        "author": "zkfloof",
        "category": "general",
        "parent": "",
        "content": "thanks for the insights. I was coming from the understanding that since disk IO is the bottleneck in syncing a new client, if u did all the IO heavy syncing in memory and then at the end write it out the processed files to SSD sequentally all at once that it would be faster instead of doing all the random read/writes",
        "created_at": "2020-04-06T21:47:52.412000+00:00",
        "attachments": null
    },
    {
        "author": "afdudley",
        "category": "general",
        "parent": "",
        "content": "that's just a write buffer and yes, a write buffer would help, but not enough because your requestor will be starved, there aren't enough nodes on the network to service you.",
        "created_at": "2020-04-06T21:49:31.193000+00:00",
        "attachments": null
    },
    {
        "author": "afdudley",
        "category": "general",
        "parent": "",
        "content": "the disk I/O bound is on the sender side, more so than the receiver. and there is a shortage of senders.",
        "created_at": "2020-04-06T21:50:06.331000+00:00",
        "attachments": null
    },
    {
        "author": "afdudley",
        "category": "general",
        "parent": "",
        "content": "stuff like beam sync should help in your case, but they won't need to use anywhere near that amount of RAM.",
        "created_at": "2020-04-06T21:52:19.500000+00:00",
        "attachments": null
    },
    {
        "author": "zkfloof",
        "category": "general",
        "parent": "",
        "content": "okay. thanks for the info üëçüèº",
        "created_at": "2020-04-06T21:58:02.547000+00:00",
        "attachments": null
    },
    {
        "author": "zkfloof",
        "category": "general",
        "parent": "",
        "content": "will check out vulcanizedb",
        "created_at": "2020-04-06T21:59:10.348000+00:00",
        "attachments": null
    },
    {
        "author": "zkfloof",
        "category": "general",
        "parent": "",
        "content": "and maybe run a benchmark on geth syncing with a ramdisk. just for fun üòÑ",
        "created_at": "2020-04-06T22:00:29.998000+00:00",
        "attachments": null
    }
]