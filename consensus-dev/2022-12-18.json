[
    {
        "author": "ajsutton",
        "category": "general",
        "parent": "",
        "content": "Youâ€™ve requested too much data too fast so the peer has decided your not worth having around and disconnected you.",
        "created_at": "2022-12-18T01:41:24.919000+00:00",
        "attachments": null
    },
    {
        "author": "potuz",
        "category": "general",
        "parent": "",
        "content": "I think it was \u003c@449019668296892420\u003e which has been saying for quite some time that we should simply throttle instead of disconnect such peers. I see value in that and wonder what do people like Adrian or Nishant think about this",
        "created_at": "2022-12-18T11:33:45.520000+00:00",
        "attachments": null
    },
    {
        "author": "funnygiulio",
        "category": "general",
        "parent": "",
        "content": "what is considered an okay amount of data? because it seems to me that requesting 10 blocks a second to a peer to be considered already too much",
        "created_at": "2022-12-18T14:58:47.880000+00:00",
        "attachments": null
    },
    {
        "author": "arnetheduck",
        "category": "general",
        "parent": "",
        "content": "this is a strategy that makes everyone happy: clients don't have to do anything except send requests and read responses, and servers control their uplink without pointless protocol - there's a bit of nuance, ie servers do well to use dual token bucket (one per-peer and one global, this is a very standard setup) which allows short bursts for good reader performance but keeps things under control and clients can do 2 \"in-flight\" requests if they want to avoid round-trip latency on the second request (one active, one \"queued\") - it's also nice for clients because they reuse the same logic as for generally slow or useless peers (which they already have to have code for), so no extra logic there either",
        "created_at": "2022-12-18T17:26:15.909000+00:00",
        "attachments": null
    },
    {
        "author": "arnetheduck",
        "category": "general",
        "parent": "",
        "content": "there are a few ways to do this: \n* complex protocol for negotiating it\n* server picks a random one and disconnects bad peers - useless because clients have to be conservative and magically \"know\" what each server picked - poor performance\n* there's an agreed-upon rate for everyone - poor performance\n* server throttles by inserting the necessary pauses - simple, efficient",
        "created_at": "2022-12-18T17:29:15.616000+00:00",
        "attachments": null
    },
    {
        "author": "funnygiulio",
        "category": "general",
        "parent": "",
        "content": "figured it out by myself, anyway it is curious that CLs are very much more sensible to ELs, probably because of  2x block sizes and compressing",
        "created_at": "2022-12-18T17:58:23.010000+00:00",
        "attachments": null
    },
    {
        "author": ".paulharris",
        "category": "general",
        "parent": "",
        "content": "Are we at a point where we can give EIP4844 a fork name? There's a bunch of changes on a PR for the beacon-apis using `eip4844` as the name, and a bunch of changes in teku code with `eip4844`, but it'd be much nicer if we could call it something more permanent like `Deneb` which is more in line with our naming strategy...\nA permanent name would reduce rework, and wouldn't exclude the possibility of delivering at the same time if we eventually go that way...",
        "created_at": "2022-12-18T19:48:43.646000+00:00",
        "attachments": null
    }
]