[
    {
        "author": "nishant0",
        "category": "general",
        "parent": "",
        "content": "I am a bit late to this but for 6110, eth1data voting would be pretty much disabled after all the deposits from the previous polling are included into the state, correct ? I don't see anything for this in the honest validator guide",
        "created_at": "2025-01-23T12:20:18.562000+00:00",
        "attachments": null
    },
    {
        "author": "m.kalinin",
        "category": "general",
        "parent": "",
        "content": "the idea is that after the transition to 6110 is done, clients can start removing eth1data voting from their codebases in uncoordinated fashion, tho it seems worth explicit mention in the validator guide",
        "created_at": "2025-01-23T14:44:44.746000+00:00",
        "attachments": null
    },
    {
        "author": "nishant0",
        "category": "general",
        "parent": "",
        "content": "Should we still be allowing a new eth1data to be voted in after the transition to electra ? The spec as of now would allow that",
        "created_at": "2025-01-23T14:46:07.677000+00:00",
        "attachments": null
    },
    {
        "author": "m.kalinin",
        "category": "general",
        "parent": "",
        "content": "yes, the old logic must work right after the fork to complete transition to the deposit requests",
        "created_at": "2025-01-23T14:47:12.198000+00:00",
        "attachments": null
    },
    {
        "author": "m.kalinin",
        "category": "general",
        "parent": "",
        "content": "the first deposit made after transition to Electra will give the estimation when it will be safe to remove eth1data voting, specifically, removing eth1data voting requires waiting till the block filling the gap between eth1 bridge and deposit requests gets finalized",
        "created_at": "2025-01-23T14:49:51.607000+00:00",
        "attachments": null
    },
    {
        "author": "kevaundray",
        "category": "general",
        "parent": "",
        "content": "Local block builders adjusting the number of tx/blobs based on bandwidth",
        "created_at": "2025-01-23T14:53:35.199000+00:00",
        "attachments": null
    },
    {
        "author": "nishant0",
        "category": "general",
        "parent": "",
        "content": "thanks for clarifying, in that case eth1data voting can only be removed once the gap is closed or full transition is done to the deposit requests.",
        "created_at": "2025-01-23T15:12:37.144000+00:00",
        "attachments": null
    },
    {
        "author": "m.kalinin",
        "category": "general",
        "parent": "",
        "content": "yes, exactly",
        "created_at": "2025-01-23T15:20:20.615000+00:00",
        "attachments": null
    },
    {
        "author": "potuz",
        "category": "general",
        "parent": "",
        "content": "I just hit this issue of the header in my RLNC branch now with blob sidecars. CC \u003c@520034910149410861\u003e we may want to implement this regardless of any RLNC implementation, it doesn't make sense to send the full signed header on each sidecar, specially with so many columns going around in PeerDAS.",
        "created_at": "2025-01-23T18:37:16.253000+00:00",
        "attachments": null
    },
    {
        "author": "pawandhananjay",
        "category": "general",
        "parent": "",
        "content": "Wondering how other clients are handling getting invalid execution requests from the builder. \nRight now, lighthouse only checks that the length limits are satisfied and it deserializes correctly, but its possible that we accept a builder payload and the execution requests fail block processing after we sign it. Is it an issue at all? \nthanks to james from prysm for bringing this up",
        "created_at": "2025-01-23T21:33:34.157000+00:00",
        "attachments": null
    },
    {
        "author": "jameshe5018",
        "category": "general",
        "parent": "",
        "content": "credit goes to terence, but i think we ended up not doing too much additional checks( deserializes correctly, checks max num of requests for each type, and that it's not nil)",
        "created_at": "2025-01-23T21:35:10.401000+00:00",
        "attachments": null
    },
    {
        "author": "pawandhananjay",
        "category": "general",
        "parent": "",
        "content": "going through `process_operations`, it doesn't seem like we return an error for anything that could be an invalid value in the execution requests, we just ignore the invalid requests. \nSo I don't think its an issue",
        "created_at": "2025-01-23T22:24:04.208000+00:00",
        "attachments": null
    },
    {
        "author": "terencechain",
        "category": "general",
        "parent": "",
        "content": "ya.. I raised the same issue on telegram, my only concern was validator index could go out of bound, but validator index isn't part of the request so we shoudl be safe there",
        "created_at": "2025-01-23T23:39:28.625000+00:00",
        "attachments": null
    }
]