[
    {
        "author": "potuz",
        "category": "general",
        "parent": "",
        "content": "Nope, I meant one that looked very similar to this one, but it was a bit older, and it was over a course of a few days instead of the quarter",
        "created_at": "2021-05-01T00:14:19.855000+00:00",
        "attachments": [
            {
                "type": "image/png",
                "origin_name": "teku.png",
                "content": "b9777c7e360cc6ca82e7187025d0900f9821facede0140d5aa47de7e4625fb7e"
            }
        ]
    },
    {
        "author": "potuz",
        "category": "general",
        "parent": "",
        "content": "but already this graph shows a few things: making it relative to Teku, and setting the 0 at 98% is perhaps the simplest way of making something that looks like an error bar appear as an actual discernible difference",
        "created_at": "2021-05-01T00:16:03.845000+00:00",
        "attachments": null
    },
    {
        "author": "potuz",
        "category": "general",
        "parent": "",
        "content": "This is how that looks still relative to Teku, I bet doing it with actual rewards client C also looks the same.",
        "created_at": "2021-05-01T00:29:06.927000+00:00",
        "attachments": [
            {
                "type": "image/jpeg",
                "origin_name": "fo.jpg",
                "content": "f49b4952e9421543d8378f71255b6f260494c80930edd314183d81cf8979f5db"
            }
        ]
    },
    {
        "author": "arnetheduck",
        "category": "general",
        "parent": "",
        "content": "I guess posting results based on undisclosed, and therefore irreproducible sources makes it difficult to assess the content, and the information quickly degrades into myth - it's an interesting claim to be making in an open source environment as well, given how each client learns from the others and improves over time (one of the great advantages of the development model) - there could certainly be a correlation - I'd be curious to here what is the causal link with respect to the software would be however, contrasting it for example to a correlation where where institutions might just as well be running on better infra. If anything, it would be really interesting to see how to use the method to improve the performance of all clients, and therefore the network as a whole.",
        "created_at": "2021-05-01T13:56:51.033000+00:00",
        "attachments": null
    },
    {
        "author": "benjaminion",
        "category": "general",
        "parent": "",
        "content": "It's a bit weird to say the data is from undisclosed or irreproducible sources. All the data is on-chain and publicly discoverable - the single piece of privileged info I have is the identity of the Codefi nodes; everything else (including the Teku data) is totally verifiable by anyone. Just detective work. I'd post the code, but I don't want to proactively dox anyone's validators. Nonetheless, the info is all there if you look for it.",
        "created_at": "2021-05-01T14:27:09.596000+00:00",
        "attachments": null
    },
    {
        "author": "arnetheduck",
        "category": "general",
        "parent": "",
        "content": "lol, well, a well timed and self-selected subset of the chain allows you to find exactly what you're looking for, most of the time üòâ of course, the block filter on beaconchain is a trivial way to discern some of this information, as is correlating with eth1 deposits etc - the point was more that any inefficiency in the rewards, regardless of the client and  - whichever kind of reward you choose - points to either an inefficiency for the network or a bug where it somehow failed to include all relevant attestations - whether that's down to software, setup, connectivity and so on is of course an open matter, but it might merit investigation in this case - numerous previous cases of poor performance have been a lot more complex than \"client X gives better rewards\", but rather \"client Y is slow at point A causing client Z to run suboptimally\"",
        "created_at": "2021-05-01T15:14:33.575000+00:00",
        "attachments": null
    },
    {
        "author": "benjaminion",
        "category": "general",
        "parent": "",
        "content": "These are \"nothing up my sleeve\" results - midnight to midnight UTC, taking the first 100 validators that were deposited for each client/service (that haven't been slashed). I'll share privately if you like - already shared some months ago with the LH crew. I'm slightly unhappy with the suggestion of bad faith. Imo data is good. It surfaces issues, like the ones you mention. That's why I collect it ü§∑‚Äç‚ôÇÔ∏è",
        "created_at": "2021-05-01T15:19:57.278000+00:00",
        "attachments": null
    },
    {
        "author": "arnetheduck",
        "category": "general",
        "parent": "",
        "content": "well, I was mostly curious what \u003c@!340345049063882753\u003e 's claim was based on since \"consistent\" sounds pretty strong, and potentially worrisome, given the structure of rewards which should basically never fail to be included, modulo poor network and/or client bugs - I've seen it repeated in a number of contexts and shapes with even less detail, so I mainly wanted to see what further action it warrants, and like you say, it's easy to find samples of particular clients, but I generally wouldn't equate that with running these clients in similar setups, which would be a necessary condition for any fair comparison of this sort",
        "created_at": "2021-05-01T15:25:12.581000+00:00",
        "attachments": null
    },
    {
        "author": "potuz",
        "category": "general",
        "parent": "",
        "content": "I myself do not think there was any bad faith and I don't doubt the data is good, I just disagree with the presentation and the interpretation. Without proper error bars I just read \"the 4 clients perform the same\". Attestation rewards on mainnet are influenced a lot by simply luck. A single bad head vote because your block proposer was late makes you lose over 1% with respect to other clients, and we are getting about 2/day/validator these days. So just a couple of bad attestations already skew this measurement a lot. Without really knowing what is statistically relevant of those measurements I would not have presented them in the way you did. Most people look at that graph and say \"oh Teku is much better than the other clients\". Regardless of what you write in the text right afterwards",
        "created_at": "2021-05-01T15:25:15.400000+00:00",
        "attachments": null
    },
    {
        "author": "pietjepuk",
        "category": "general",
        "parent": "",
        "content": "And if anything, the conclusion is more that \"the infrastructure of people running Teku is better than average\", and not really saying much about the client itself. Not very surprising, with it being more enterprisey-oriented.",
        "created_at": "2021-05-01T15:54:39.995000+00:00",
        "attachments": null
    },
    {
        "author": "benjaminion",
        "category": "general",
        "parent": "",
        "content": "The individual client data is for infra run by each client team. I assume we are all running our own clients as best we can, but it is definitely an assumption. As for staking services, you'd think they would provision the infrastructure well,  but some of them are quite woeful, irrespective of client.",
        "created_at": "2021-05-01T16:01:10.668000+00:00",
        "attachments": null
    },
    {
        "author": "potuz",
        "category": "general",
        "parent": "",
        "content": "There are some actual difference in client implementations that do result in better attestations, this experiment presumably was carried with large stakers: delaying your attestations when you produce a block does effectively increase your reward, even though it goes against what the specs say with regard to being an honest validator",
        "created_at": "2021-05-01T16:03:29.158000+00:00",
        "attachments": null
    },
    {
        "author": "potuz",
        "category": "general",
        "parent": "",
        "content": "conversely actually attesting as soon as you produce the block and publish it penalizes you, so it's an interesting thing to actually measure these differences",
        "created_at": "2021-05-01T16:04:12.617000+00:00",
        "attachments": null
    },
    {
        "author": "potuz",
        "category": "general",
        "parent": "",
        "content": "with controlled errors",
        "created_at": "2021-05-01T16:04:17.643000+00:00",
        "attachments": null
    },
    {
        "author": "arnetheduck",
        "category": "general",
        "parent": "",
        "content": "+1 on no assumption of bad faith, none intended, and I fully trust the data is accurate - it is of course invaluable that these things are being tracked in the community and presented, and I have no doubt larger deviations would have found their way to the right places, though simplified too far, they can also lead to premature conclusions, and this is something to avoid - I wouldn't read too much into some of the validator numbers for client teams, these double as canaries and testbeds as well as experimentation grounds for distribution across ISP's / the globe / different hardware etc",
        "created_at": "2021-05-01T16:21:20.363000+00:00",
        "attachments": null
    }
]