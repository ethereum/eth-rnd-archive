[
    {
        "author": "djrtwo",
        "category": "general",
        "parent": "",
        "content": "issuance from the beacon chain goes directly to the validator account.\npost merge, fees and revenues from the execution layer (EVM/transactions) go to an account on the excution layer (i.e. normal user account)",
        "created_at": "2022-08-12T12:23:39.523000+00:00",
        "attachments": null
    },
    {
        "author": "arnetheduck",
        "category": "general",
        "parent": "",
        "content": "hey \u003c@755590043632140352\u003e, for the fast hashtree library, off the top of your head, do you have a feel for how much improvement you would get from the padded length trick alone (ie without the parallel processing)?",
        "created_at": "2022-08-12T13:53:19.508000+00:00",
        "attachments": null
    },
    {
        "author": "potuz",
        "category": "general",
        "parent": "",
        "content": "So I think it's about 20% for the same algorithm to hardcode the padding block. I was benchmarking 30% against openSSL, but I had a better streamlined AVX1 code vs their SSE code. \u003c@792822129019584562\u003e implemented the same technique on lodestar with generics and I think they were benchmarking 11% initially but after some fixes they got to 20%, he can correct me",
        "created_at": "2022-08-12T14:10:37.751000+00:00",
        "attachments": null
    },
    {
        "author": "arnetheduck",
        "category": "general",
        "parent": "",
        "content": "huh, really? that's more than I expected .. I would have thought doing the rounds would take up more than the preparing the padding",
        "created_at": "2022-08-12T14:44:31.916000+00:00",
        "attachments": null
    },
    {
        "author": "potuz",
        "category": "general",
        "parent": "",
        "content": "Scheduling is just slightly less expensive than rounds in terms of computation. Another big advantage is that you save a memory access to  store the scheduled words",
        "created_at": "2022-08-12T14:49:27.700000+00:00",
        "attachments": null
    },
    {
        "author": "arnetheduck",
        "category": "general",
        "parent": "",
        "content": "I haven't looked at the assembly yet, but... do you then inline the precomputed padding in the first round as constants?",
        "created_at": "2022-08-12T14:50:38.096000+00:00",
        "attachments": null
    },
    {
        "author": "arnetheduck",
        "category": "general",
        "parent": "",
        "content": "or fill a memory buffer with precomputed values and use \"standard\" round 0?",
        "created_at": "2022-08-12T14:51:17.250000+00:00",
        "attachments": null
    },
    {
        "author": "potuz",
        "category": "general",
        "parent": "",
        "content": "I keep a memory buffer with the precomputed words, so the algorithm goes like this: \n1) Grab words from the input buffer to hash\n2) schedule words from these. \n3) Grab the initial digest from a memory buffer\n4) feed the scheduled words to the usual rounds. \n5) save the digest to later add\n6) grab hardcoded scheduled words for the padding block from a memory buffer\n7) feed them to the usual rounds. \n8) Add the diggest saved in 5 and output. \nSo the step that is saved in the 6--8 block is what happened in 2), we do not need to compute these scheduled words.",
        "created_at": "2022-08-12T14:55:07.605000+00:00",
        "attachments": null
    },
    {
        "author": "arnetheduck",
        "category": "general",
        "parent": "",
        "content": "very nice, thanks!",
        "created_at": "2022-08-12T15:00:14.526000+00:00",
        "attachments": null
    },
    {
        "author": "g11tech",
        "category": "general",
        "parent": "",
        "content": "yes correct! we were able to extract ~20% of the juice ðŸ™‚  thanks to \u003c@755590043632140352\u003e bringing the trick to our attention ðŸ™‚",
        "created_at": "2022-08-12T15:57:04.938000+00:00",
        "attachments": null
    }
]