[
    {
        "author": "arnetheduck",
        "category": "general",
        "parent": "",
        "content": "arrival times of aggregates and attestations cc \u003c@555483069038198827\u003e \u003c@755590043632140352\u003e \n```\n# HELP beacon_attestation_delay Time(s) between slot start and attestation reception\n# TYPE beacon_attestation_delay histogram\nbeacon_attestation_delay_sum 1439984500.361385\nbeacon_attestation_delay_count 348930364.0\nbeacon_attestation_delay_created 1684694965.0\nbeacon_attestation_delay_bucket{le=\"2.0\"} 26304030.0\nbeacon_attestation_delay_bucket{le=\"4.0\"} 125419664.0\nbeacon_attestation_delay_bucket{le=\"6.0\"} 327924668.0\nbeacon_attestation_delay_bucket{le=\"8.0\"} 347277541.0\nbeacon_attestation_delay_bucket{le=\"10.0\"} 348235076.0\nbeacon_attestation_delay_bucket{le=\"12.0\"} 348526697.0\nbeacon_attestation_delay_bucket{le=\"14.0\"} 348652289.0\nbeacon_attestation_delay_bucket{le=\"+Inf\"} 348930364.0\n# HELP beacon_aggregate_delay Time(s) between slot start and aggregate reception\n# TYPE beacon_aggregate_delay histogram\nbeacon_aggregate_delay_sum 196980906.9307191\nbeacon_aggregate_delay_count 23475554.0\nbeacon_aggregate_delay_created 1684694965.0\nbeacon_aggregate_delay_bucket{le=\"2.0\"} 247.0\nbeacon_aggregate_delay_bucket{le=\"4.0\"} 700.0\nbeacon_aggregate_delay_bucket{le=\"6.0\"} 2673.0\nbeacon_aggregate_delay_bucket{le=\"8.0\"} 72015.0\nbeacon_aggregate_delay_bucket{le=\"10.0\"} 23319966.0\nbeacon_aggregate_delay_bucket{le=\"12.0\"} 23414399.0\nbeacon_aggregate_delay_bucket{le=\"14.0\"} 23438978.0\nbeacon_aggregate_delay_bucket{le=\"+Inf\"} 23475554.0\n```",
        "created_at": "2023-06-15T15:25:23.009000+00:00",
        "attachments": [
            {
                "type": "image/png",
                "origin_name": "image.png",
                "content": "7a1a730f4a62b9fdf199f1567af6b19038ccb974a8c26361f955de45fa3784cc"
            }
        ]
    },
    {
        "author": "potuz",
        "category": "general",
        "parent": "",
        "content": "Ahh should probably move my post here",
        "created_at": "2023-06-15T15:26:52.272000+00:00",
        "attachments": null
    },
    {
        "author": "arnetheduck",
        "category": "general",
        "parent": "",
        "content": "these are times from \"slot start\" - it's _generally_ enough that one of 16 aggregators send out a good aggregate in time for block production\n\n(nimbus for example takes the best aggreagte and tops it up with single-attestions on block production)",
        "created_at": "2023-06-15T15:26:52.843000+00:00",
        "attachments": null
    },
    {
        "author": "arnetheduck",
        "category": "general",
        "parent": "",
        "content": "lol, just saw it",
        "created_at": "2023-06-15T15:27:04.283000+00:00",
        "attachments": null
    },
    {
        "author": "potuz",
        "category": "general",
        "parent": "",
        "content": "I think arrival time is orthogonal to what I am talking about",
        "created_at": "2023-06-15T15:27:06.582000+00:00",
        "attachments": null
    },
    {
        "author": "potuz",
        "category": "general",
        "parent": "",
        "content": "I want to leave here the numbers I mentioned during the call \u003c@555483069038198827\u003e  \u003c@449019668296892420\u003e these were taken with my NUC running at home with 100 peers. https://github.com/prysmaticlabs/prysm/pull/12350\nWe were seeing 2 seconds average to aggregate 1 bit attestations and dropped down to 780ms\nGitHub\nDon't use max cover on unaggregated atts nor check subgroup of vali...\nThis PR does two things\n\nIt removes the check for subgroup inclusion when getting a signature from bytes, since the signature were already verified.\nIt aggregates attestations directly when they ar...\nDon't use max cover on unaggregated atts nor check subgroup of vali...\nbut that's the average",
        "created_at": "2023-06-15T15:27:27.306000+00:00",
        "attachments": null
    },
    {
        "author": "arnetheduck",
        "category": "general",
        "parent": "",
        "content": "well, arrival time is strictly worse than production time",
        "created_at": "2023-06-15T15:27:28.371000+00:00",
        "attachments": null
    },
    {
        "author": "arnetheduck",
        "category": "general",
        "parent": "",
        "content": "so, the flow is more or less that 16 nodes aggregate and clients _typically_ will pick the best of those 16 (because outside of \"singles\", they cannot further be combined) - a few laggers won't materially affect this ..",
        "created_at": "2023-06-15T15:29:00.397000+00:00",
        "attachments": null
    },
    {
        "author": "arnetheduck",
        "category": "general",
        "parent": "",
        "content": "also, worth noting is https://github.com/ethereum/consensus-specs/pull/3312 in which the structure of the stability subnet subscriptions changes significantly and no longer scales with the number of validators",
        "created_at": "2023-06-15T15:30:24.597000+00:00",
        "attachments": null
    },
    {
        "author": "arnetheduck",
        "category": "general",
        "parent": "",
        "content": "basically, the more validators there are, the lower the chance you're selected as aggregator for a subnet _and_ you will be listening to fewer stability subnets in general",
        "created_at": "2023-06-15T15:30:58.606000+00:00",
        "attachments": null
    },
    {
        "author": "potuz",
        "category": "general",
        "parent": "",
        "content": "But again we are talking about different things. Aggregating those aggregates is of the order of milliseconds for us",
        "created_at": "2023-06-15T15:31:11.037000+00:00",
        "attachments": null
    },
    {
        "author": "potuz",
        "category": "general",
        "parent": "",
        "content": "the problem I see is in aggregating 1 bit attestations",
        "created_at": "2023-06-15T15:31:22.956000+00:00",
        "attachments": null
    },
    {
        "author": "arnetheduck",
        "category": "general",
        "parent": "",
        "content": "we typically can't aggregate aggregates since they typically overlap (except with singles to \"top them up\")\n\nfor aggregating 1-bit attestations, well, if you're an aggregator for a subnet, the number of bls aggregations is capped by the number of committee members which currently sits around 350 (increasing by 1 for every 2k validators added) so that's also a cap on the number of aggregations you would possibly have to make",
        "created_at": "2023-06-15T15:36:29.679000+00:00",
        "attachments": null
    },
    {
        "author": "arnetheduck",
        "category": "general",
        "parent": "",
        "content": "this is really irrespective of what's going on, on the network: ie the number of aggregation operations you will be performing every slot shouldn't change since attesters vote only once per epoch",
        "created_at": "2023-06-15T15:39:54.746000+00:00",
        "attachments": null
    },
    {
        "author": "potuz",
        "category": "general",
        "parent": "",
        "content": "I'm not arguing against that. L just pointing hard numbers on my personal node (which were better than our dev k8s)",
        "created_at": "2023-06-15T15:41:24.417000+00:00",
        "attachments": null
    },
    {
        "author": "potuz",
        "category": "general",
        "parent": "",
        "content": "So currently in prysm we are aggregating by default at 6.5 seconds whatever we have then",
        "created_at": "2023-06-15T15:41:46.736000+00:00",
        "attachments": null
    },
    {
        "author": "potuz",
        "category": "general",
        "parent": "",
        "content": "To make absolutely certain that 99% of validators have good aggregates ready at 8 seconds",
        "created_at": "2023-06-15T15:42:16.032000+00:00",
        "attachments": null
    },
    {
        "author": "potuz",
        "category": "general",
        "parent": "",
        "content": "On my personal computer running 3 vals I'm aggregating at 7.9 seconds",
        "created_at": "2023-06-15T15:43:08.849000+00:00",
        "attachments": null
    },
    {
        "author": "arnetheduck",
        "category": "general",
        "parent": "",
        "content": "yeah, I'm just curious where those numbers are coming from - an aggregation takes afair 1ms on typical hardware so the \"bls\" part of aggreation, per the above logic, should take no more than 350ms",
        "created_at": "2023-06-15T15:44:54.936000+00:00",
        "attachments": null
    },
    {
        "author": "arnetheduck",
        "category": "general",
        "parent": "",
        "content": "so, a recap:\n* correction from above: there are now 22:is aggregators per subnet\n* as an aggregator you get all the single-validator attestations and you basically add them together when it's time to aggregate\n* committee size is 350 (growing slowly, yes), but that's your upper computational bound - as correctly identified by the PR you link, there is no need to run max-cover or anything else so this should be all that you do\n* you can build the aggregate as the attestations start dropping in, though doing so risks creating an aggregate that you'll discard later (since you have to send your best aggregate based on which head they vote for)\n* the last point is important: if there are attestations that vote for some random blocks, you don't need to aggregate these: you only send the best aggregate",
        "created_at": "2023-06-15T15:52:37.643000+00:00",
        "attachments": null
    },
    {
        "author": "arnetheduck",
        "category": "general",
        "parent": "",
        "content": "my point with the graph is that an overwhelming majority of aggregates reach the network well before the 10s mark, so even if there are some stragglers, like your node sending the attestation at 7.9, this is far from typical",
        "created_at": "2023-06-15T15:54:49.809000+00:00",
        "attachments": null
    },
    {
        "author": "arnetheduck",
        "category": "general",
        "parent": "",
        "content": "fwiw, this is my 6-year-old laptop on a DSL so it's not exactly a powerhouse either: for example, it has to aggregate the pubkeys of the validators to validate the aggregates that drop in which it spends a lot of time on",
        "created_at": "2023-06-15T16:04:34.058000+00:00",
        "attachments": null
    },
    {
        "author": "potuz",
        "category": "general",
        "parent": "",
        "content": "aggregators need to send their aggregates at 8 seconds, that's the deadline, that means that they need to start aggregating before that cut. The question is when? and what should clients have as default. At prysm we computed that we need to have at the very least 1.5 seconds before the 8 seconds mark to be sure to have a good aggregate in the 99% of cases",
        "created_at": "2023-06-15T16:14:11.234000+00:00",
        "attachments": null
    },
    {
        "author": "arnetheduck",
        "category": "general",
        "parent": "",
        "content": "that sounds aggressive - ie you can continue aggregating singles until the very point where the validator client asks for an aggregate - I believe most clients simply make the request for an aggregate at the 8s mark then sign and send it",
        "created_at": "2023-06-15T16:21:04.146000+00:00",
        "attachments": null
    },
    {
        "author": "arnetheduck",
        "category": "general",
        "parent": "",
        "content": "ie we count the time to sign it as negligible",
        "created_at": "2023-06-15T16:21:30.679000+00:00",
        "attachments": null
    },
    {
        "author": "potuz",
        "category": "general",
        "parent": "",
        "content": "right this is an alternative, but I benchmarked that this turns out being worse for us: you get most attestations after 4 seconds, many blocks are being imported right then or you're doing epoch preprocessing and a bunch of other stuff. It's more performant for us to keep them unnagregated until 6.5 seconds (7.9 in a small staker) and just aggregate them then",
        "created_at": "2023-06-15T16:23:23.970000+00:00",
        "attachments": null
    },
    {
        "author": "arnetheduck",
        "category": "general",
        "parent": "",
        "content": "sure, but I'd suggest a hybrid strategy here: ie wait until 6.5s to do the first aggregation then top up with any stragglers after that - this gives you an optimal aggregate  without 4s bump",
        "created_at": "2023-06-15T16:24:28.957000+00:00",
        "attachments": null
    },
    {
        "author": "arnetheduck",
        "category": "general",
        "parent": "",
        "content": "this is related to my last point: you don't need to aggregate _all_ attestations you receive: only the ones that likely will lead to the \"best\" aggreagte",
        "created_at": "2023-06-15T16:25:04.490000+00:00",
        "attachments": null
    },
    {
        "author": "potuz",
        "category": "general",
        "parent": "",
        "content": "well at this stage you are arriving to my first observation: we can't really take that much from this part of the slot",
        "created_at": "2023-06-15T16:25:20.532000+00:00",
        "attachments": null
    },
    {
        "author": "arnetheduck",
        "category": "general",
        "parent": "",
        "content": "well, assume we give the block another 2s: 1s from pre-aggregation and 1s from pre-next-slot - that's already a 50% increase and still well within prysms operating bounds",
        "created_at": "2023-06-15T16:26:37.678000+00:00",
        "attachments": null
    },
    {
        "author": "arnetheduck",
        "category": "general",
        "parent": "",
        "content": "basically, what you're saying is that you only use 2.5s of attestation propagation time, and this is fine",
        "created_at": "2023-06-15T16:27:06.449000+00:00",
        "attachments": null
    },
    {
        "author": "arnetheduck",
        "category": "general",
        "parent": "",
        "content": "in fact, if prysm works the way that it stops considering new attestations for the aggregate at 6.5s and still produces decent aggregates, this is the large-scale experiment we need to conclude that removing 1s from the pre-aggregation time is fine",
        "created_at": "2023-06-15T16:28:17.403000+00:00",
        "attachments": null
    },
    {
        "author": "potuz",
        "category": "general",
        "parent": "",
        "content": "well, yeah, this is something we need to meassure indeed: the problem is that by having the way we have now, then it's safe to bet that most attestations are already seen by 6.5. If we remove 1 second and now they are sent at 5, then I'd like to know that this invariant stays the same",
        "created_at": "2023-06-15T16:30:42.479000+00:00",
        "attachments": null
    },
    {
        "author": "arnetheduck",
        "category": "general",
        "parent": "",
        "content": "this also plays into another point for how aggregation propagation happens: in fact, one could argue that if prysm stops accepting attestations at 6.5 is likely to cause some increased bandwidth consumption and cpu usage overall due to the rules of aggregate propagation..\n\nassuming that because prysm stops collecting attestations at 6.5s and is \"early\" to publish the aggregates, it's plausible that other clients that collect attestations for the full 4s will produce \"fuller\" aggregates than prysm - however, they are also likely to be slightly more delayed in their publishing due timing differences - if/when that happens, if prysm publishes \"first\" or earlier by some margin, the poorer aggregate will have time to spread on the network which is wasteful (the network only rebroadcasts contributing aggregates based on its local view, so if a \"rich\" aggregate is received first, the poorer aggregate will be dropped)",
        "created_at": "2023-06-15T16:35:22.727000+00:00",
        "attachments": null
    },
    {
        "author": "potuz",
        "category": "general",
        "parent": "",
        "content": "we do not stop accepting attestations at 6.5, we aggregate everything that comes after 6.5 later",
        "created_at": "2023-06-15T16:36:16.714000+00:00",
        "attachments": null
    },
    {
        "author": "potuz",
        "category": "general",
        "parent": "",
        "content": "and we keep these aggregates in the pool just in case (not only for forkchoice).",
        "created_at": "2023-06-15T16:36:36.867000+00:00",
        "attachments": null
    },
    {
        "author": "potuz",
        "category": "general",
        "parent": "",
        "content": "Dankrad asked why there are spikes so long from 700ms average to over 2-4 seconds at times, and reorgs do cause this cause you retake them from blocks in the pool again",
        "created_at": "2023-06-15T16:37:23.367000+00:00",
        "attachments": null
    },
    {
        "author": "arnetheduck",
        "category": "general",
        "parent": "",
        "content": "ah, the way I understood it, the aggregate you'd send out on the gossip would include only those from 6.5",
        "created_at": "2023-06-15T18:53:03.348000+00:00",
        "attachments": null
    },
    {
        "author": "arnetheduck",
        "category": "general",
        "parent": "",
        "content": "this might also be a difference - we expire by time only, and filter at block production so we don't see these spikes",
        "created_at": "2023-06-15T18:53:57.460000+00:00",
        "attachments": null
    },
    {
        "author": "potuz",
        "category": "general",
        "parent": "",
        "content": "this is correct, we will continue aggregating but only to keep them in the pool and doing aggregates of aggregates to send to forkchoice or reuse those in case they are useful later",
        "created_at": "2023-06-15T19:06:04.841000+00:00",
        "attachments": null
    },
    {
        "author": "potuz",
        "category": "general",
        "parent": "",
        "content": "when we import a block we do not add the attestations that are importing to a pool, we send them to forkchoice. So we don't necessarily have these attestations to include later if the block gets reorged. If we see a reorg, we go back and add every attestation in this block back to the pool",
        "created_at": "2023-06-15T19:07:57.166000+00:00",
        "attachments": null
    },
    {
        "author": "arnetheduck",
        "category": "general",
        "parent": "",
        "content": "I wrote down a quick PR here so as to summarise the discussion and collect the above concerns: https://github.com/ethereum/consensus-specs/pull/3433 - more eyeballs are needed",
        "created_at": "2023-06-15T20:08:26.679000+00:00",
        "attachments": null
    },
    {
        "author": "potuz",
        "category": "general",
        "parent": "",
        "content": "\u003c@144468805697929216\u003e (cc   \u003c@841217748942979072\u003e  who asked during the call) there's a reason to not send the attestations as soon as possible. This caused trouble on prysm in the past and we reverted to not recommend that flag to stakers. Perhaps is time to revisit this but the reason this was reverted originally was that clients that saw an attestation for a block that they didn't know at the time, would schedule this attestation and fail to include it in the next block. This hurt every large operator whenever they propose a block as all their validators attestating in that slot would be hurt and this carried to the first peers of these operators. Lighthouse has since fixed the issue on their side and I don't know about other clients so perhaps is now safe to send attestations early again",
        "created_at": "2023-06-15T22:31:42.330000+00:00",
        "attachments": null
    },
    {
        "author": "jgm",
        "category": "general",
        "parent": "",
        "content": "Is the fix that beacon nodes hold attestations for the current slot, even if they haven't seen the block yet?  If so, that seems like a reasonable fix to put in place for all beacon nodes along with attesting on receipt of the block.",
        "created_at": "2023-06-15T23:04:24.010000+00:00",
        "attachments": null
    },
    {
        "author": "potuz",
        "category": "general",
        "parent": "",
        "content": "We all kept the attestations, the issue is when they were processed",
        "created_at": "2023-06-15T23:04:59.546000+00:00",
        "attachments": null
    },
    {
        "author": "potuz",
        "category": "general",
        "parent": "",
        "content": "The spec is a little loose in this regard but everyone's reading is that you should process it as soon as you see the block, just that this is not trivial to implement. In general I believe that it's better to specify the minimum set of things, specially if there's no way to enforce them. No client team is up to exploit holes in the spec afaik, just that it's hard to coordinate around some edges. And having a loose spec leads to real client diversity which is what has saved us a couple of times",
        "created_at": "2023-06-15T23:08:07.916000+00:00",
        "attachments": null
    },
    {
        "author": "jgm",
        "category": "general",
        "parent": "",
        "content": "Would be interesting to hear what each beacon node does today with attestations for the current slot when they have yet to see a block for it.\n\nThe danger of the attestations being discarded if the block is not yet seen is that it then makes sense to not broadcast your attestations until past the 4 second mark, and that is going to lead to a massive surge of attestations all at the same time rather than having them relatively spread out over a few seconds as we have today.  Although I get the idea of having different implementations, there have to be some ground rules around (in this case) what happens to attestations if a validator client is attempting to help the network by broadcasting early (ideally resulting in them not being penalized).",
        "created_at": "2023-06-15T23:19:15.479000+00:00",
        "attachments": null
    },
    {
        "author": "sproul",
        "category": "general",
        "parent": "",
        "content": "Lighthouse queues attestations for unknown blocks until the block shows up, to a limit (the limit is roughly the number of attestations per slot, but we might need to bump it)",
        "created_at": "2023-06-15T23:21:27.072000+00:00",
        "attachments": null
    }
]