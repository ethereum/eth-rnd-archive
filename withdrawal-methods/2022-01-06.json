[
    {
        "author": "potuz",
        "category": "Consensus R\u0026D",
        "parent": "",
        "content": "Hi \u003c@!291925846556540928\u003e, putting in this channel as it is vaguely tangential and I remembered it because of this question by \u003c@!273808422753796097\u003e \u003chttps://github.com/ethereum/consensus-specs/pull/2759#discussion_r774583960\u003e. Hashing the validator registry is one of the largest chunks of hashing the entire Beacon State (It accounts for about 70% of the time needed in our benchmarks). We are testing the hasher that uses vectorization to paralelize this to potentially 1/10th of the time. It was noticed by \u003c@!476250636548308992\u003e  that there is a simple trick because the number of fields in the validator structure is a power of 2 (8 in this case) so one can lay out a Merkle tree with all the field roots as leaves instead of the validator roots, and the third level of this tree consists of the validator roots. Hashing it this way instead of the naive way of computing each validator root and laying it out as a list (as the spec dictates) dramatically reduced CPU time. I am only pointing to this here cause it's a subtle edge case but it does have useful implications, this will of course not be possible without doubling the initial list, if the `epoch_withdrawn`  field is added as in the current proposal. I'm not advocating against it, just saying that if there are design choices that allow for a power of two number of fields on containers vs some that don't, this is a reason to keep in mind when making those decisions.",
        "created_at": "2022-01-06T11:00:36.728000+00:00",
        "attachments": null
    }
]