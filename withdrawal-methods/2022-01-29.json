[
    {
        "author": ".vbuterin",
        "category": "Consensus R\u0026D",
        "parent": "",
        "content": "But if the number of fields is not a power of two, in hashing it just gets padded to a power of two, no?",
        "created_at": "2022-01-29T20:18:35.665000+00:00",
        "attachments": null
    },
    {
        "author": ".vbuterin",
        "category": "Consensus R\u0026D",
        "parent": "",
        "content": "Oooh I see, you mean making a tree that splits by field at the top and validator ID at the bottom instead of the reverse",
        "created_at": "2022-01-29T20:19:15.782000+00:00",
        "attachments": null
    },
    {
        "author": ".vbuterin",
        "category": "Consensus R\u0026D",
        "parent": "",
        "content": "So basically applying the validator balances approach to all the fields",
        "created_at": "2022-01-29T20:19:35.204000+00:00",
        "attachments": null
    },
    {
        "author": ".vbuterin",
        "category": "Consensus R\u0026D",
        "parent": "",
        "content": "It's an interesting stategy!",
        "created_at": "2022-01-29T20:19:46.087000+00:00",
        "attachments": null
    },
    {
        "author": ".vbuterin",
        "category": "Consensus R\u0026D",
        "parent": "",
        "content": "Though would be significant complexity to rearchitect the state that way",
        "created_at": "2022-01-29T20:20:14.323000+00:00",
        "attachments": null
    },
    {
        "author": "potuz",
        "category": "Consensus R\u0026D",
        "parent": "",
        "content": "So for the validator registry in our case (prysm) this comes at no cost. The complexity comes because clients tend to cache the whole hash tree so that you only recompute the needed branches. We haven't yet readjusted the cache to this design as it's not clear if it's worth it cause it's dependant on the fixed number of fields per validator structure",
        "created_at": "2022-01-29T20:30:44.304000+00:00",
        "attachments": null
    }
]