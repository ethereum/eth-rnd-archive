[
    {
        "author": "notnotstorm",
        "category": "Consensus R\u0026D",
        "parent": "",
        "content": "what is the right way to think about blobcount bottlenecks under peerdas? what will be the specific constraints that limit blobcount per block? with full 2d peerdas horizontal scaling, what might prevent us getting to 100+ or 1000+ blobs per block?",
        "created_at": "2024-12-20T02:01:29.350000+00:00",
        "attachments": []
    },
    {
        "author": "leobago",
        "category": "Consensus R\u0026D",
        "parent": "",
        "content": "One of the main constraints is network bandwidth. How fast can the block builder disseminate the entire block over the p2p network, how fast can validators and full nodes download parts of it. And then how fast can they sample the other parts of the data to verify if the block is indeed available or not. There is also some computational work related to erasure coding and KZG proofs and verification.",
        "created_at": "2024-12-20T10:45:24.029000+00:00",
        "attachments": []
    },
    {
        "author": "cskiraly",
        "category": "Consensus R\u0026D",
        "parent": "",
        "content": "\u003c@716119813675548694\u003e So with PeerDAS, and SubnetDAS, and any 1D structure, where both the sharding and the sampling is done at the column level, you bandwidth requirements scale linearly with blob count. More or less the same holds for CPU requirements, which to some extent also transforms into delay, although some parts of the processing can be parallelised to multiple cores (assuming your cores are not busy doing other things, but they ofter are busy).\n\nIn the 2D case we are trying to move away from these linear scaling properties. Still we need:\n- Enough custody rows and columns for statistical coverage on the DA side.\n- A networking stack that can handle the amount of row/column “topics” we deal with.\n\nMaybe even more importantly, we need the builders to be able to push out the data needed, with the required level of redundancy. There are a few proposals around this on the table (e.g. distributed block building), but if you assume a single home builder doing this, it is easy to see that bandwidth is a clear bottleneck.",
        "created_at": "2024-12-20T15:11:41.758000+00:00",
        "attachments": []
    },
    {
        "author": "notnotstorm",
        "category": "Consensus R\u0026D",
        "parent": "",
        "content": "does a builder need all of the 2D peerdas'd blobs in order to build the block? or just the hashes of blobs?",
        "created_at": "2024-12-20T17:59:47.535000+00:00",
        "attachments": []
    }
]