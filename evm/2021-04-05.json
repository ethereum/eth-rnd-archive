[
    {
        "author": ".vbuterin",
        "category": "Execution R\u0026D",
        "parent": "",
        "content": "What do people here *really* think about the current quadratic memory pricing?",
        "created_at": "2021-04-05T17:02:30.555000+00:00",
        "attachments": null
    },
    {
        "author": ".vbuterin",
        "category": "Execution R\u0026D",
        "parent": "",
        "content": "As opposed to simpler-and-dumber alternatives like some kind of hard memory size limit",
        "created_at": "2021-04-05T17:12:00.704000+00:00",
        "attachments": null
    },
    {
        "author": "pauld.9606",
        "category": "Execution R\u0026D",
        "parent": "",
        "content": "A goal of memory pricing is to prevent hardware bottleneck attacks on memory.",
        "created_at": "2021-04-05T17:17:19.835000+00:00",
        "attachments": null
    },
    {
        "author": "pauld.9606",
        "category": "Execution R\u0026D",
        "parent": "",
        "content": "Quadratic memory pricing seems effective at this.",
        "created_at": "2021-04-05T17:17:30.910000+00:00",
        "attachments": null
    },
    {
        "author": "pauld.9606",
        "category": "Execution R\u0026D",
        "parent": "",
        "content": "Quadratic pricing does not reflect actual hardware, which has slowdown jumps to access each higher level of cache heirarchy, memory, etc.",
        "created_at": "2021-04-05T17:19:09.936000+00:00",
        "attachments": null
    },
    {
        "author": "pauld.9606",
        "category": "Execution R\u0026D",
        "parent": "",
        "content": "I don't see a critical problem with quadratic pricing. I am open to alternatives.",
        "created_at": "2021-04-05T17:20:52.379000+00:00",
        "attachments": null
    },
    {
        "author": "lightclient",
        "category": "Execution R\u0026D",
        "parent": "",
        "content": "do you think a conservative hard cap on memory is also effective at preventing bottleneck attacks?",
        "created_at": "2021-04-05T17:20:59.370000+00:00",
        "attachments": null
    },
    {
        "author": ".vbuterin",
        "category": "Execution R\u0026D",
        "parent": "",
        "content": "The issue I see with memory is that the way it works in practice is that the node has some memory, and there isn't really a benefit to using less than you have, especially if with every transaction there's a risk you have to jump up to using the maximum amount",
        "created_at": "2021-04-05T17:21:40.255000+00:00",
        "attachments": null
    },
    {
        "author": ".vbuterin",
        "category": "Execution R\u0026D",
        "parent": "",
        "content": "And it's kinda hard to calculate the theoretical max memory consumption at the moment; it's something like \"use half the gas to make 100 call frames and the other half of the gas to fill the call frames, using decreasing amounts in each one\"",
        "created_at": "2021-04-05T17:22:59.995000+00:00",
        "attachments": null
    },
    {
        "author": "pauld.9606",
        "category": "Execution R\u0026D",
        "parent": "",
        "content": "A hard-cap of 4MB might be useful, since most cpus have \u003e=4MB of cache. But this is complicated to limit across calls. Plus stacks, bytecode, etc take up some cache too. Anyway, I think that current gas limits allow around 3MB of memory.",
        "created_at": "2021-04-05T17:26:37.482000+00:00",
        "attachments": null
    },
    {
        "author": ".vbuterin",
        "category": "Execution R\u0026D",
        "parent": "",
        "content": "\u003e Anyway, I think that current gas limits allow around 3MB of memory.",
        "created_at": "2021-04-05T17:26:55.750000+00:00",
        "attachments": null
    },
    {
        "author": ".vbuterin",
        "category": "Execution R\u0026D",
        "parent": "",
        "content": "This is within a single call frame",
        "created_at": "2021-04-05T17:27:00.751000+00:00",
        "attachments": null
    },
    {
        "author": ".vbuterin",
        "category": "Execution R\u0026D",
        "parent": "",
        "content": "If you split across many call frames, I think it can go up to something like 30-80 MB",
        "created_at": "2021-04-05T17:27:12.257000+00:00",
        "attachments": null
    },
    {
        "author": "pauld.9606",
        "category": "Execution R\u0026D",
        "parent": "",
        "content": "Oh yeah, correct.",
        "created_at": "2021-04-05T17:27:22.564000+00:00",
        "attachments": null
    },
    {
        "author": ".vbuterin",
        "category": "Execution R\u0026D",
        "parent": "",
        "content": "btw this matters because if in the long run we want the EVM to be ZK-SNARKable I think we want tougher restrictions on memory footprint",
        "created_at": "2021-04-05T17:27:32.818000+00:00",
        "attachments": null
    },
    {
        "author": "pauld.9606",
        "category": "Execution R\u0026D",
        "parent": "",
        "content": "I think that the most economical way to create cache pressure is to fill the EVM stack, then recurse.",
        "created_at": "2021-04-05T17:32:23.769000+00:00",
        "attachments": null
    },
    {
        "author": "pauld.9606",
        "category": "Execution R\u0026D",
        "parent": "",
        "content": "I was wondering if we can give each call a free 32kb or 64kb of memory. And the heavy users of memory can pay more. I'm not sure what meets ZK-SNARKablility restrictions.",
        "created_at": "2021-04-05T17:35:25.393000+00:00",
        "attachments": null
    },
    {
        "author": ".vbuterin",
        "category": "Execution R\u0026D",
        "parent": "",
        "content": "Zk snarkability is better the lower a global hard cap we can guarantee",
        "created_at": "2021-04-05T17:49:27.218000+00:00",
        "attachments": null
    },
    {
        "author": "gcolvin",
        "category": "Execution R\u0026D",
        "parent": "",
        "content": "3mb of mem will pretty much fit in level 2 cache, depending on other pressure, and the cost of overflow isn't quadratic, it more like a step function. An exponential topping out at an empirically good number seems right.",
        "created_at": "2021-04-05T18:49:02.482000+00:00",
        "attachments": null
    },
    {
        "author": ".vbuterin",
        "category": "Execution R\u0026D",
        "parent": "",
        "content": "I guess the bigger problem is the still really high call stack depth limit",
        "created_at": "2021-04-05T18:49:30.761000+00:00",
        "attachments": null
    },
    {
        "author": ".vbuterin",
        "category": "Execution R\u0026D",
        "parent": "",
        "content": "The 63/64 rule makes it de-facto 300 or something like that",
        "created_at": "2021-04-05T18:49:38.415000+00:00",
        "attachments": null
    },
    {
        "author": ".vbuterin",
        "category": "Execution R\u0026D",
        "parent": "",
        "content": "But I doubt we really *need* more than 16",
        "created_at": "2021-04-05T18:49:47.091000+00:00",
        "attachments": null
    },
    {
        "author": "gcolvin",
        "category": "Execution R\u0026D",
        "parent": "",
        "content": "We can traverse the chain to find out",
        "created_at": "2021-04-05T18:52:25.402000+00:00",
        "attachments": null
    },
    {
        "author": ".vbuterin",
        "category": "Execution R\u0026D",
        "parent": "",
        "content": "true!",
        "created_at": "2021-04-05T18:52:29.104000+00:00",
        "attachments": null
    },
    {
        "author": ".vbuterin",
        "category": "Execution R\u0026D",
        "parent": "",
        "content": "Though I feel like I've already been putting enough traversing tasks on people's plates ðŸ˜†",
        "created_at": "2021-04-05T18:52:45.432000+00:00",
        "attachments": null
    },
    {
        "author": ".vbuterin",
        "category": "Execution R\u0026D",
        "parent": "",
        "content": "(asking \u003c@!211091239112671234\u003e  for a breakdown of gas usage between different categories, so we better understand what's actually critical to optimize)",
        "created_at": "2021-04-05T18:53:26.505000+00:00",
        "attachments": null
    }
]