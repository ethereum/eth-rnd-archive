[
    {
        "author": "shamatar",
        "category": "Execution R\u0026D",
        "parent": "",
        "content": "The article compares state of the art wm engines versus homemade ewasm engines that were heavily butchered to add gas counters and storage interfaces. Is there a reason to add any gas counter to WASM engine at all and not just count cycles instead? Modulo storage ops",
        "created_at": "2021-03-23T12:13:18.933000+00:00",
        "attachments": null
    },
    {
        "author": "sky.cactus",
        "category": "Execution R\u0026D",
        "parent": "",
        "content": "Modulo storage operations, memory operations, etc.",
        "created_at": "2021-03-23T12:15:33.176000+00:00",
        "attachments": null
    },
    {
        "author": "sky.cactus",
        "category": "Execution R\u0026D",
        "parent": "",
        "content": "The problem is that list gets kinda long I believe.  üôÇ",
        "created_at": "2021-03-23T12:15:40.548000+00:00",
        "attachments": null
    },
    {
        "author": "sky.cactus",
        "category": "Execution R\u0026D",
        "parent": "",
        "content": "Also, cycle count may differ by implementation and underlying hardware.",
        "created_at": "2021-03-23T12:16:07.572000+00:00",
        "attachments": null
    },
    {
        "author": "shamatar",
        "category": "Execution R\u0026D",
        "parent": "",
        "content": "Well, one can bound memory to 2gb and panic on larger allocations. Or any other number",
        "created_at": "2021-03-23T12:16:48.993000+00:00",
        "attachments": null
    },
    {
        "author": "shamatar",
        "category": "Execution R\u0026D",
        "parent": "",
        "content": "By cycles I mean assembly lines largely, naively assuming that interpreter runs line by line üôÇ",
        "created_at": "2021-03-23T12:17:41.043000+00:00",
        "attachments": null
    },
    {
        "author": "sky.cactus",
        "category": "Execution R\u0026D",
        "parent": "",
        "content": "Most assembly lines are not equally costly.",
        "created_at": "2021-03-23T12:18:08.244000+00:00",
        "attachments": null
    },
    {
        "author": "sky.cactus",
        "category": "Execution R\u0026D",
        "parent": "",
        "content": "We would have to use the most expensive as the cost for *every* line.",
        "created_at": "2021-03-23T12:18:27.359000+00:00",
        "attachments": null
    },
    {
        "author": "sky.cactus",
        "category": "Execution R\u0026D",
        "parent": "",
        "content": "Also, we would still need to count the lines we iterated over, at which point we basically have gas accounting implemented again.",
        "created_at": "2021-03-23T12:18:44.328000+00:00",
        "attachments": null
    },
    {
        "author": "shamatar",
        "category": "Execution R\u0026D",
        "parent": "",
        "content": "For non-jit does an interpreter overhead dominate execution time or not?",
        "created_at": "2021-03-23T12:18:49.524000+00:00",
        "attachments": null
    },
    {
        "author": "shamatar",
        "category": "Execution R\u0026D",
        "parent": "",
        "content": "I mean one can count every global execution ‚Äúcycle‚Äù that takes some wasm instruction and interprets it. There is 90% + overhead at the moment and even if one takes all instructions to be as expensive as the most expensive one it may still help overall",
        "created_at": "2021-03-23T12:20:45.480000+00:00",
        "attachments": null
    },
    {
        "author": "shamatar",
        "category": "Execution R\u0026D",
        "parent": "",
        "content": "One step further - count everything but divisions, and divisions separately üôÇ if memory buffer is preallocated and can not be grown everything else is most likely as slow as an arbitrary memory read/write without cache hit",
        "created_at": "2021-03-23T12:22:12.764000+00:00",
        "attachments": null
    },
    {
        "author": "sky.cactus",
        "category": "Execution R\u0026D",
        "parent": "",
        "content": "At the moment state growth is by far the limiting factor, so I think people just don't care much at the moment.  üôÇ",
        "created_at": "2021-03-23T12:22:24.748000+00:00",
        "attachments": null
    },
    {
        "author": "shamatar",
        "category": "Execution R\u0026D",
        "parent": "",
        "content": "I‚Äôm just a little sad about the fact that one can not benefit from state of the art wasm engines and current engine pays 20x inefficiency cost",
        "created_at": "2021-03-23T12:23:43.827000+00:00",
        "attachments": null
    },
    {
        "author": "sky.cactus",
        "category": "Execution R\u0026D",
        "parent": "",
        "content": "It would be great if we could solve the state problem so our bottleneck was EVM processing speed.  üòÑ",
        "created_at": "2021-03-23T12:24:24.460000+00:00",
        "attachments": null
    },
    {
        "author": "shamatar",
        "category": "Execution R\u0026D",
        "parent": "",
        "content": "I was trying to ask about the particular reason not to optimize for mining machines with full state in memory and 10x + block processing margin for other nodes, but it was lost in another chat",
        "created_at": "2021-03-23T12:25:28.738000+00:00",
        "attachments": null
    },
    {
        "author": "sky.cactus",
        "category": "Execution R\u0026D",
        "parent": "",
        "content": "Because we want *users* to be able to utilize Ethereum trustlessly.",
        "created_at": "2021-03-23T12:29:30.114000+00:00",
        "attachments": null
    },
    {
        "author": "shamatar",
        "category": "Execution R\u0026D",
        "parent": "",
        "content": "But they still can do it. If performance is IO bound then mining nodes (or whoever assembles a new block before mining on a nonce) can do it fast with state in memory, but all other nodes can apply a valid block 10x slower and still be ok with it",
        "created_at": "2021-03-23T12:30:59.682000+00:00",
        "attachments": null
    },
    {
        "author": "shamatar",
        "category": "Execution R\u0026D",
        "parent": "",
        "content": "I assume that end-user (consumer) machines never mine and assemble a block themselves, but join the managed pools",
        "created_at": "2021-03-23T12:32:13.368000+00:00",
        "attachments": null
    },
    {
        "author": "shamatar",
        "category": "Execution R\u0026D",
        "parent": "",
        "content": "And if Geth/OE/Nethemind/Besu would have an option to keep a state in memory then you have an open source implementation to base a new mining pool on it",
        "created_at": "2021-03-23T12:33:11.897000+00:00",
        "attachments": null
    },
    {
        "author": "shamatar",
        "category": "Execution R\u0026D",
        "parent": "",
        "content": "At the moment block is assembled during around 300-400 ms on a ‚Äúnormal‚Äù machine, so it‚Äôs still a huge margin compared to time between blocks",
        "created_at": "2021-03-23T12:33:57.887000+00:00",
        "attachments": null
    },
    {
        "author": "sky.cactus",
        "category": "Execution R\u0026D",
        "parent": "",
        "content": "Everyone has to execute the block, not only miners.  Also, new participants in the network currently have to re-execute *all blocks in history* in order to fully validate the chain.",
        "created_at": "2021-03-23T12:41:52.775000+00:00",
        "attachments": null
    },
    {
        "author": "sky.cactus",
        "category": "Execution R\u0026D",
        "parent": "",
        "content": "We could, in theory, bypass that with something like regenesis or state snapshots, but even then someone who turns their node off for a while needs to \"catch up\".",
        "created_at": "2021-03-23T12:42:20.977000+00:00",
        "attachments": null
    },
    {
        "author": "sky.cactus",
        "category": "Execution R\u0026D",
        "parent": "",
        "content": "So if it takes 10 seconds to validate a block, you will catch up *very* slowly.",
        "created_at": "2021-03-23T12:42:30.413000+00:00",
        "attachments": null
    },
    {
        "author": "gcolvin",
        "category": "Execution R\u0026D",
        "parent": "",
        "content": "The EVM engines they compare were not state-of-the art.  \u003c@!211091239112671234\u003e has improved the geth interpreter they tested a lot since then, and  \u003c@!425274498732916736\u003e's evmone is much faster.  I'm working with Martin now to get the turbo-geth engine even better.  If it's worth it those changes can be ported back to geth.  In turbo-geth right now contract execution is about half of the time spent syncing up.  But a lot of that time looks to be in SLOAD, so state access might still dominate.  I say \"looks to be\" because we are so early in working on this.\n\nA guy on the Near team told me a year ago that even with a highly-optimized wasm engine they were seeing gas counting overheads of up to 1000X.  Not sure how much better they are doing now,  but gas counting is just plain \"evil\".  The more fine-grained your opcodes and the shorter your basic blocks the worse it gets.",
        "created_at": "2021-03-23T13:25:41.047000+00:00",
        "attachments": null
    },
    {
        "author": "shamatar",
        "category": "Execution R\u0026D",
        "parent": "",
        "content": "My argument was only about wasm/ewasm as I‚Äôm not familiar with EVM interpreters landscape, but 1000x overhead in gas counting is insane. Do they have any updates on it?",
        "created_at": "2021-03-23T13:32:13.867000+00:00",
        "attachments": null
    },
    {
        "author": "gcolvin",
        "category": "Execution R\u0026D",
        "parent": "",
        "content": "\u003c@!381789485777682434\u003e 1000X was a worst case.  I'd think they have done better by now, but not sure how much.  There is some discussion of their approach here -- https://nomicon.io/RuntimeSpec/FunctionCall.html -- which looks to be not much different than evmone's - inject gas counting statements at the block level rather than the instruction level.  I haven't found anything more informative, but haven't time to look any deeper.  Their blog seems not to have anything past 2019.",
        "created_at": "2021-03-23T14:24:20.393000+00:00",
        "attachments": null
    },
    {
        "author": "gcolvin",
        "category": "Execution R\u0026D",
        "parent": "",
        "content": "I didn't notice this discussion until yesterday -- EIP-2315 was pushed past London for lack of \"use-cases\" - apparently defined as whether the Solidity team intended to use JUMPSUB anytime soon, so I stopped paying attention for a while and got to work improving the current turbo-geth interpreter.\n\nYou asked \"What would happen if we restricted it further, and instead of JUMPSUB taking a variable, we forced it to take an immediate?\"\n\nThe answer is that restricting JUMPSUB opcodes to constant arguments means virtual functions and such would need JUMPI chains.  That might be OK, but EIP-615 introduced a separate JUMPSUBV for the purposes.  (And JUMPV for jump tables.) \n\nI did add some very preliminary analysis to the current draft of EIP-2315 (https://github.com/ethereum/EIPs/blob/master/EIPS/eip-2315.md)  to show that *if all* the JUMP* opcodes were restricted to a constant argument (semantically equivalent to an immediate) then safety and amenability to static analysis comparable to EIP-615 can be had without further restrictions -- for that use case restricting _only_ JUMPSUB won't do.  I didn't consider other use cases.",
        "created_at": "2021-03-23T16:01:51.231000+00:00",
        "attachments": null
    },
    {
        "author": "gcolvin",
        "category": "Execution R\u0026D",
        "parent": "",
        "content": "As for immediates, EIP-615 required immediate arguments, which required versioning, which at the time seemed difficult-to-impossible to do. Maybe we know better now, but the EVM seems to actively resist immediate data - it wants to see arguments on the stack.  Ugly, but so are some of the tricks above.  (I haven't had time to think about whether the tricks work.)",
        "created_at": "2021-03-23T16:03:28.978000+00:00",
        "attachments": null
    },
    {
        "author": "gcolvin",
        "category": "Execution R\u0026D",
        "parent": "",
        "content": "So if I may ask, do your use cases require that _all_ contracts after some point be restricted?  If not, a linear scan of the code can tell whether all arguments to an opcode are preceded by the push of a constant.",
        "created_at": "2021-03-23T16:08:50.600000+00:00",
        "attachments": null
    },
    {
        "author": ".vbuterin",
        "category": "Execution R\u0026D",
        "parent": "",
        "content": "\u003e they were seeing gas counting overheads of up to 1000X.\n\nThat's..... really surprising and I have heard answers to the question that are very different",
        "created_at": "2021-03-23T22:13:58.413000+00:00",
        "attachments": null
    },
    {
        "author": ".vbuterin",
        "category": "Execution R\u0026D",
        "parent": "",
        "content": "All you need for gas counting is a code transformation that puts `memory[unused_address] -= X` before every jump, where `X` can be computed once as part of the code transformation",
        "created_at": "2021-03-23T22:14:29.918000+00:00",
        "attachments": null
    },
    {
        "author": ".vbuterin",
        "category": "Execution R\u0026D",
        "parent": "",
        "content": "I can't imagine a memory update being much more expensive than a jump....",
        "created_at": "2021-03-23T22:15:28.142000+00:00",
        "attachments": null
    },
    {
        "author": ".vbuterin",
        "category": "Execution R\u0026D",
        "parent": "",
        "content": "But yeah, at the moment our bottleneck is not the EVM, and even if we \"solve storage\" I expect the bulk of the VM overhead to be bigint math, and for that we have precompiles (and will have more precompiles)",
        "created_at": "2021-03-23T22:16:26.382000+00:00",
        "attachments": null
    }
]