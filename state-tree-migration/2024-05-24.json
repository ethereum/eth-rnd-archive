[
    {
        "author": "gakonst",
        "category": "Execution R\u0026D",
        "parent": "",
        "content": "Super interesting would love to hear more",
        "created_at": "2024-05-24T01:48:28.974000+00:00",
        "attachments": null
    },
    {
        "author": "rudolf6",
        "category": "Execution R\u0026D",
        "parent": "",
        "content": "\u003c@184616430996684800\u003e thanks for sharing! Happy to take a look if you have further analysis anywhere! As you may already know, it's really all about the witness size: https://ihagopian.com/posts/anatomy-of-a-verkle-proof\n\nDiscussed a bit around this topic with \u003c@774033563732541451\u003e recently. It's possible i'm misunderstanding what you are presenting, but one thing to keep in mind is that close-together values are in the same leaf, so they actually share all the branch which should help keep witness size down. Taking *random* key values otoh is actually more measuring the worst-case scenario.\n\nThe best way to form a more clear picture of witness size will be to track in a mainnet shadowfork, to get the correct access patterns. This is something we will be running in the coming weeks (replaying of more recent block history) ðŸ¤ž",
        "created_at": "2024-05-24T05:01:09.581000+00:00",
        "attachments": null
    },
    {
        "author": "_shemnon",
        "category": "Execution R\u0026D",
        "parent": "",
        "content": "\u003e Taking random key values otoh is actually more measuring the worst-case scenario.\n\nIf there is anything the shanghai attacks proved, it is that someone will do it just to troll us.  Putting a \"lid\" on worst case scenarios is helpful.  Is it feasable to run this analysis out to 10^9 and 10*12?  Or are we comfortable extrapolating those out to cira 9k and 12k for a 100 value spread?",
        "created_at": "2024-05-24T13:23:12.612000+00:00",
        "attachments": null
    },
    {
        "author": "jsign",
        "category": "Execution R\u0026D",
        "parent": "",
        "content": "Probably this \"worst-case\" mentioning was a bit confusing. The point I tried to tell Josh was mostly around accessed-keys cost depend on the access pattern due to the grouping.\nInstead of thinking about # of accessed keys which have this \"pattern dependency\", I'd think more about gas limit. The biggest witness size comes from any access pattern you are allowed to do withing the gas limit, and probably built it from there.",
        "created_at": "2024-05-24T13:34:45.755000+00:00",
        "attachments": null
    },
    {
        "author": "hiasr",
        "category": "Execution R\u0026D",
        "parent": "",
        "content": "To give some context to what I am doing, I am analyzing the possibility of a network where the state storage is distributed over all the nodes. It can best be described as a combination of the portal network and stateless clients. Currently, I only discuss the case of Merkle proofs, but I am expanding to Verkle Trees due to the gains regarding the proof size. I attached an excerpt of the relevant pieces, mainly the results of the Merkle experiments might be interesting (page 36, Figure 5.6 and 5.7). The case where a node has no storage or cache, is the same as a stateless client. That's why it could also be interesting for this purpose.\n\nI took the access patterns into account by requesting the prestate of blocks over a window of ~2 weeks. This made it possible to take both the access patterns of accounts and slots into consideration.\n\nThe switch to a unified tree  makes it more difficult to do a direct mapping from the current Merkle analysis to Verkle. My  plan is to work in two steps. First, create a larger tree (I hope to get at least to 10^9) to see if the relation between proof size and amount of entries hold and create a regression for this relation. Second, analyze the effects of locality in accounts, create a few accounts in this large tree organized as per the EIP with varying amount of used slots. \n\nThe combination of these two should be able to provide a decent approximation. Taking out the locality factor will be an indication of worst-case performance.\nLet me know if you have suggestions to improve the accuracy!",
        "created_at": "2024-05-24T16:17:46.113000+00:00",
        "attachments": [
            {
                "type": "application/pdf",
                "origin_name": "verkle_excerpt_organized.pdf",
                "content": "0caf7f0ce151ad4f5a9ac9d19a6255c145cd256e4eb0115040f111c00a1aa917"
            }
        ]
    },
    {
        "author": "pipermerriam",
        "category": "Execution R\u0026D",
        "parent": "",
        "content": "My teams will likely be performing live experiments for clients of this type in our state network which is going live over the next few months.  We're developing verkle support in parallel but it's unclear when we'll a live version of that to play with.",
        "created_at": "2024-05-24T20:44:10.641000+00:00",
        "attachments": null
    }
]