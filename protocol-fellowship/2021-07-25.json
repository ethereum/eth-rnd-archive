[
    {
        "author": "arnetheduck",
        "category": "general",
        "parent": "",
        "content": "ooh, this is very nice - what made it tick? ie fancy multiblock hash vs other tricks?",
        "created_at": "2021-07-25T21:20:36.835000+00:00",
        "attachments": []
    },
    {
        "author": "arnetheduck",
        "category": "general",
        "parent": "",
        "content": "we're a bit picky about the compiler version since many of them have corner cases that nimbus as a project runs into, so we tend to avoid the system versions - `make update` then `./env.sh bash` to enter a shell in which the supplied compiler is in the PATH and all deps are lined up nicely",
        "created_at": "2021-07-25T21:21:58.697000+00:00",
        "attachments": []
    },
    {
        "author": "arnetheduck",
        "category": "general",
        "parent": "",
        "content": "https://gist.github.com/arnetheduck/7e57c22626e2c6effb4898e7e8bf03d2",
        "created_at": "2021-07-25T21:28:21.982000+00:00",
        "attachments": []
    },
    {
        "author": "arnetheduck",
        "category": "general",
        "parent": "",
        "content": "I didn't do timers, just counts",
        "created_at": "2021-07-25T21:28:35.306000+00:00",
        "attachments": []
    },
    {
        "author": "potuz",
        "category": "general",
        "parent": "",
        "content": "something very simple, I'll post as an \"update\" for the apprenticeship program. But it's something that I suppose it's not being used by default on prysm and certainly not on openssl. When you need to hash a big buffer of a few blocks of 64bytes, you add a last block with fixed content that is the padding block. Most implementations of sha256 are the same essentially and they are one way or another a copy of the intel implementations using the diverse CPU extensions. The point is that they are optimized for large buffers: hashing several blocks in different lanes, mixing the last result, etc.",
        "created_at": "2021-07-25T21:38:36.282000+00:00",
        "attachments": []
    },
    {
        "author": "arnetheduck",
        "category": "general",
        "parent": "",
        "content": "adding timers is trivial though, there's a bunch of `withTimer` calls in ncli already that should be copy-pastable: https://github.com/status-im/nimbus-eth2/blob/07a1c5716b707e7244eb312bed68c92c1fb9508d/ncli/ncli.nim#L120",
        "created_at": "2021-07-25T21:38:37.389000+00:00",
        "attachments": []
    },
    {
        "author": "potuz",
        "category": "general",
        "parent": "",
        "content": "the last padding block is just one extra block so is no biggy",
        "created_at": "2021-07-25T21:38:50.841000+00:00",
        "attachments": []
    },
    {
        "author": "potuz",
        "category": "general",
        "parent": "",
        "content": "however, for merkle trees the situation is completely different: you need to hash thousands for separate buffers of 64 blocks",
        "created_at": "2021-07-25T21:39:11.708000+00:00",
        "attachments": []
    },
    {
        "author": "potuz",
        "category": "general",
        "parent": "",
        "content": "so the padding block takes as much time as the data block",
        "created_at": "2021-07-25T21:39:28.234000+00:00",
        "attachments": []
    },
    {
        "author": "potuz",
        "category": "general",
        "parent": "",
        "content": "and if you hardcode the padding block into the algo, you realize that you can actually save more than half of the time in hashing that one cause you do not need any of the scheduling part of the sha algorithm",
        "created_at": "2021-07-25T21:40:16.559000+00:00",
        "attachments": []
    },
    {
        "author": "potuz",
        "category": "general",
        "parent": "",
        "content": "so all I did is hardcode the scheduled words for that block in intel's assembly, and voilÃ¡: I went from 270ms to 190ms, and then implementing two blocks at a time reusing some registers got me to 160ms",
        "created_at": "2021-07-25T21:41:26.600000+00:00",
        "attachments": []
    },
    {
        "author": "potuz",
        "category": "general",
        "parent": "",
        "content": "It is a lot of improvement.",
        "created_at": "2021-07-25T21:41:45.102000+00:00",
        "attachments": []
    },
    {
        "author": "potuz",
        "category": "general",
        "parent": "",
        "content": "thanks! I'll try copying that tomorrow and I'll cry for help if I can't",
        "created_at": "2021-07-25T21:44:15.610000+00:00",
        "attachments": []
    },
    {
        "author": "arnetheduck",
        "category": "general",
        "parent": "",
        "content": "gg, nice deep dive - thanks for confirming that we're not twice as slow as well ðŸ™‚",
        "created_at": "2021-07-25T21:44:28.320000+00:00",
        "attachments": []
    },
    {
        "author": "potuz",
        "category": "general",
        "parent": "",
        "content": "already asked Adrian to help me with Teku, and will hopefully manage to benchmark LH, If I get a better performance against all I'll post it and perhaps implement the AVX2 and AVX512 versions of the assembly",
        "created_at": "2021-07-25T21:45:34.694000+00:00",
        "attachments": []
    },
    {
        "author": "arnetheduck",
        "category": "general",
        "parent": "",
        "content": "now you need a name for it though, ie we're \"standard slow\" at 271 minus some noise, fastssz is 290",
        "created_at": "2021-07-25T21:45:39.757000+00:00",
        "attachments": []
    },
    {
        "author": "potuz",
        "category": "general",
        "parent": "",
        "content": "I found this done in the bitcoind's code, but not anywhere else, and certainly not in the intel's library that ultimately is what fastssz is based upon.",
        "created_at": "2021-07-25T21:46:40.501000+00:00",
        "attachments": []
    },
    {
        "author": "potuz",
        "category": "general",
        "parent": "",
        "content": "it could also be very particular about the CPU: very few Intel's support SHAni extensions, but AMD's do, and I code in one, so that's the first assembly I wrote (in about 30 years), perhaps on AVX512 fastssz is faster, I can't really test that. But I have a laptop that supports AVX2 so I'll implement that and test as well",
        "created_at": "2021-07-25T21:49:01.506000+00:00",
        "attachments": []
    }
]